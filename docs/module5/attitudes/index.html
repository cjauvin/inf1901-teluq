<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Les grandes attitudes contemporaines à l’égard de l’IA# L’attitude libérale# La vision libérale conçoit l’intelligence artificielle comme un outil de progrès techniques et économie au service de l’individu et du marché. Elle s’appuie sur des valeurs héritées du libéralisme classique (liberté individuelle, innovation, responsabilité) et du néolibéralisme (primauté du marché, dérégulation, entrepreneuriat). Cette vision est incarnée par les grandes entreprises technologiques (Big Tech) telles Google, Amazon, Microsoft ou OpenAI qui promeuvent l’IA comme un moyen de générer de nouveaux marchés. Cette vision libérale est présentée dans le documentaire L’intelligence artificielle décodée (Radio-Canada, 2023), qui insiste sur la régulation et l’équilibre entre innovation et contrôle. Ce documentaire est relativement long (2 heures), mais il est divisé en sections. Deux sections couvrent davantage les aspects critiques et éthiques. Ce sont Défis éthiques et sociaux qui abordent des questions liées à la vie privée, à la sécurité et aux inégalités (1 : 00 : 40) ainsi que Furturs possibles qui discute des scénarios optimistes et pessimistes concernant l’impact de l’IA sur la société (1 : 23 ; 01).
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Attitudes à l'égard de l'IA"><meta property="og:description" content="Les grandes attitudes contemporaines à l’égard de l’IA# L’attitude libérale# La vision libérale conçoit l’intelligence artificielle comme un outil de progrès techniques et économie au service de l’individu et du marché. Elle s’appuie sur des valeurs héritées du libéralisme classique (liberté individuelle, innovation, responsabilité) et du néolibéralisme (primauté du marché, dérégulation, entrepreneuriat). Cette vision est incarnée par les grandes entreprises technologiques (Big Tech) telles Google, Amazon, Microsoft ou OpenAI qui promeuvent l’IA comme un moyen de générer de nouveaux marchés. Cette vision libérale est présentée dans le documentaire L’intelligence artificielle décodée (Radio-Canada, 2023), qui insiste sur la régulation et l’équilibre entre innovation et contrôle. Ce documentaire est relativement long (2 heures), mais il est divisé en sections. Deux sections couvrent davantage les aspects critiques et éthiques. Ce sont Défis éthiques et sociaux qui abordent des questions liées à la vie privée, à la sécurité et aux inégalités (1 : 00 : 40) ainsi que Furturs possibles qui discute des scénarios optimistes et pessimistes concernant l’impact de l’IA sur la société (1 : 23 ; 01)."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta itemprop=name content="Attitudes à l'égard de l'IA"><meta itemprop=description content="Les grandes attitudes contemporaines à l’égard de l’IA# L’attitude libérale# La vision libérale conçoit l’intelligence artificielle comme un outil de progrès techniques et économie au service de l’individu et du marché. Elle s’appuie sur des valeurs héritées du libéralisme classique (liberté individuelle, innovation, responsabilité) et du néolibéralisme (primauté du marché, dérégulation, entrepreneuriat). Cette vision est incarnée par les grandes entreprises technologiques (Big Tech) telles Google, Amazon, Microsoft ou OpenAI qui promeuvent l’IA comme un moyen de générer de nouveaux marchés. Cette vision libérale est présentée dans le documentaire L’intelligence artificielle décodée (Radio-Canada, 2023), qui insiste sur la régulation et l’équilibre entre innovation et contrôle. Ce documentaire est relativement long (2 heures), mais il est divisé en sections. Deux sections couvrent davantage les aspects critiques et éthiques. Ce sont Défis éthiques et sociaux qui abordent des questions liées à la vie privée, à la sécurité et aux inégalités (1 : 00 : 40) ainsi que Furturs possibles qui discute des scénarios optimistes et pessimistes concernant l’impact de l’IA sur la société (1 : 23 ; 01)."><meta itemprop=wordCount content="1063"><title>Attitudes à l'égard de l'IA | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.9f533add4c447a961b609e13ee02076c6d5baa3e0173d1a8f0c006e584b123e7.css integrity="sha256-n1M63UxEepYbYJ4T7gIHbG1bqj4Bc9Go8MAG5YSxI+c=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/css/applet.css></head><body dir=ltr class="book-kind-page book-type-docs"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><img src=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png alt=Logo><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Approche pédagogique du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/feuille-de-route/>Feuille de route</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/changelog/>Évolution du cours (venez voir de temps en temps!)</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/discord/>Serveur Discord</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/>Module 1 - Intelligence artificielle</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/>Module 2 - Apprentissage automatique</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/>Un scénario pour se faire une idée</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/diff%C3%A9rence-avec-x/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/algo-le-plus-simple/>L'algorithme le plus simple</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/similarit%C3%A9/>Le concept de similarité</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/mod%C3%A8les/>Qu'est-ce qu'un modèle?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/>Les paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/>Apprentissage supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/>Apprentissage non supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/>Module 3 - Réseaux de neurones et apprentissage profond</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/architectures-avanc%C3%A9es/>Architectures avancées</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/aa-adverse/>Apprentissage automatique adverse</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/>Module 4 - IA générative et grands modèles de langage</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle checked>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/>Module 5 - Autour de l'IA</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/ class=active>Attitudes à l'égard de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/icons/menu.svg class=book-icon alt=Menu></label><h3>Attitudes à l'égard de l'IA</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#lattitude-libérale>L&rsquo;attitude libérale</a></li><li><a href=#lattitude-défaitiste-ou-fataliste>L&rsquo;attitude défaitiste (ou fataliste)</a></li><li><a href=#lattitude-optimiste-ou-accélérationniste>L&rsquo;attitude optimiste (ou accélérationniste)</a></li><li><a href=#le-transhumanisme>Le transhumanisme</a></li><li><a href=#tableau-comparatif>Tableau comparatif</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=les-grandes-attitudes-contemporaines-à-légard-de-lia>Les grandes attitudes contemporaines à l&rsquo;égard de l&rsquo;IA<a class=anchor href=#les-grandes-attitudes-contemporaines-%c3%a0-l%c3%a9gard-de-lia>#</a></h1><h2 id=lattitude-libérale>L&rsquo;attitude libérale<a class=anchor href=#lattitude-lib%c3%a9rale>#</a></h2><p>La vision libérale conçoit l&rsquo;intelligence artificielle comme un outil de progrès
techniques et économie au service de l&rsquo;individu et du marché. Elle s&rsquo;appuie sur
des valeurs héritées du libéralisme classique (liberté individuelle, innovation,
responsabilité) et du néolibéralisme (primauté du marché, dérégulation,
entrepreneuriat). Cette vision est incarnée par les grandes entreprises
technologiques (Big Tech) telles Google, Amazon, Microsoft ou OpenAI qui
promeuvent l&rsquo;IA comme un moyen de générer de nouveaux marchés. Cette vision
libérale est présentée dans le documentaire L&rsquo;intelligence artificielle décodée
(Radio-Canada, 2023), qui insiste sur la régulation et l&rsquo;équilibre entre
innovation et contrôle. Ce documentaire est relativement long (2 heures), mais
il est divisé en sections. Deux sections couvrent davantage les aspects
critiques et éthiques. Ce sont Défis éthiques et sociaux qui abordent des
questions liées à la vie privée, à la sécurité et aux inégalités (1 : 00 : 40)
ainsi que Furturs possibles qui discute des scénarios optimistes et pessimistes
concernant l&rsquo;impact de l&rsquo;IA sur la société (1 : 23 ; 01).</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/QFKHd2k_RNE?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>On ajoute ici <a href=https://droit.cairn.info/article/RAI_077_0067>La Déclaration de Montréal pour un développement responsable de
l&rsquo;IA</a>, que vous pourriez
consulter pour enrichir votre connaissance.</p><h2 id=lattitude-défaitiste-ou-fataliste>L&rsquo;attitude défaitiste (ou fataliste)<a class=anchor href=#lattitude-d%c3%a9faitiste-ou-fataliste>#</a></h2><p>L&rsquo;attitude défaitiste (par exemple celle plus extrême des
<a href=https://fr.wikipedia.org/wiki/Doomer>&ldquo;doomers&rdquo;</a>) envisage l&rsquo;IA comme une
menace existentielle pour l&rsquo;humanité. Elle repose sur l&rsquo;idée que le
développement non maîtrisé d&rsquo;une intelligence artificielle générale ou d&rsquo;IA
superintelligentes conduira tôt ou tard, à une perte de contrôle par les humains
de la technologie, de dérives incontrôlables et, à long terme, à une extinction
possible de l&rsquo;espèce humaine. Elon Musk, Geoffrey Hinton et Yoshua Bengio sont
des acteurs-clés qui expriment leurs craintes quant au risques existentiel de
l&rsquo;IA. L&rsquo;entrevue avec Yoshua Bengio &ldquo;Les dangers de l&rsquo;intelligence artificielle&rdquo;
(Radio-Canada Info, 25 juillet 2023) où le chercheur lance un avertissement sur
les dérives potentielles de l&rsquo;intelligence artificielle dans son discours devant
la sous-commission du Sénat américain sur la vie privée, la technologie et le
droit.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/VYrcXTckP2s?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>L&rsquo;attitude défaitiste considère l&rsquo;IA comme une menace existentielle. L&rsquo;article de
Martin Lapouille, (25 juin 2025) <a href=https://usbeketrica.com/fr/article/servir-l-ia-jusqu-a-disparaitre-la-religion-secrete-des-milliardaires-de-la-tech-qui-menace-notre-humanite>Servir l&rsquo;IA jusqu&rsquo;à faire disparaître
l&rsquo;humanité : la religion secrète des patrons de la
tech</a>,
dans Usbek &amp;Rica discute la problématique de l&rsquo;extinction de l&rsquo;espèce humaine
comme une opportunité pour engendrer un descendant plus sophistiqué :
l&rsquo;intelligence artificielle.</p><h2 id=lattitude-optimiste-ou-accélérationniste>L&rsquo;attitude optimiste (ou accélérationniste)<a class=anchor href=#lattitude-optimiste-ou-acc%c3%a9l%c3%a9rationniste>#</a></h2><p>La vision optimiste (ou
<a href=https://fr.wikipedia.org/wiki/Acc%C3%A9l%C3%A9rationnisme>accélérationniste</a>)
conçoit l&rsquo;intelligence artificielle comme un moteur de progrès exponentiel.
Selon cette perspective, il faut accélérer le développement technologique,
notamment celui de l&rsquo;IA, pour résoudre les grands défis de l&rsquo;humanité. L&rsquo;idée
centrale réside dans l&rsquo;hypothèse que plus vite nous irons vers une
superintelligence contrôlée et alignée, plus vite nous pourrons accroître nos
connaissances, améliorer nos conditions de vie et dépasser les limites
biologiques de l&rsquo;espèce humaine. Citons <a href=https://fr.wikipedia.org/wiki/Raymond_Kurzweil>Ray
Kurzweil</a>, auteur du livre
L&rsquo;Humanité 2.0 : La bible du changement (2005) (en anglais The Singularity is
Near) où il décrit sa vision de la <a href=https://fr.wikipedia.org/wiki/Singularit%C3%A9_technologique>singularité
technologique</a>, à
travers la combinaison de trois sciences principales : la génétique, les
nanotechnologies, et la robotique, dont l&rsquo;intelligence artificielle.</p><p>La vision optimiste ou accélérationniste voit l&rsquo;IA comme un moteur
d&rsquo;accélération de la transformation humaine et sociétale. Le billet de Stéphane
Le Calme (18 octobre 2023), intitulé <a href=https://intelligence-artificielle.developpez.com/actu/349680/-C-est-une-secte-le-mouvement-pro-IA-baptise-accelerationnisme-efficace-gagne-du-terrain-a-la-Silicon-Valley-Ses-adeptes-pronent-une-croissance-technologique-sans-limites/>« C&rsquo;est une secte » : le mouvement pro-IA
baptisé « accélérationnisme efficace » gagne du terrain à la Silicon
Valley</a>
introduit bien ce mouvement qui prône une croissance technologique sans limites,
même au prix d&rsquo;un bouleversement radical de l&rsquo;ordre social actuel.</p><h2 id=le-transhumanisme>Le transhumanisme<a class=anchor href=#le-transhumanisme>#</a></h2><p>La vision transhumaniste promeut l&rsquo;Idée que l&rsquo;humain peut et doit dépasser ses
limites biologiques grâce aux technologies NBIC (Nanotechnologies,
Biotechnologies, Informatique, Sciences cognitives. Elle repose sur une croyance
forte dans la perfectibilité de l&rsquo;humain grâce à la convergence technologique et
l&rsquo;IA est à la fois un outil, un catalyseur et une fin en soir pour atteindre
l&rsquo;étape posthumain. Il est difficile d&rsquo;aborder le transhumanisme sans
s&rsquo;intéresser à <a href=https://usbeketrica.com/fr/article/un-ingenieur-de-google-suspendu-apres-avoir-affirme-qu-une-ia-etait-douee-de-sensibilite>Blake
Lemoine</a>,
un ingénieur chez Google, et l&rsquo;affaire LaMDA (Language Model for Dialogue
Application, soit d&rsquo;un robot conversationnel (chatbot) de Google qui présentait
des signes de sentience , c&rsquo;est-à-dire une capacité, à l&rsquo;instar d&rsquo;un être
humain, de ressentir des émotions, de la douleur, du bien-être, et de percevoir
subjectivement son environnement et ses expériences de vie » (Google). basée sur
la question de la conscience non biologique, Blake Lemoine établit ainsi un lien
avec le transhumanisme bien qu&rsquo;il ne l&rsquo;exprime pas ainsi. Nous vous proposons
l&rsquo;écoute du balado LaMDA de Google : <a href=https://ici.radio-canada.ca/ohdio/premiere/emissions/moteur-de-recherche/segments/chronique/413723/science-fiction-blake-lemoine-ai>Quand l&rsquo;intelligence artificielle devient
consciente</a>,
produit par Radio-Canada Ohdio (6 septembre 2022) qui résume bien ce cas ou la
lecture d&rsquo;un article d&rsquo;Aïda Elamrani, (10 septembre 2022). <a href=https://www.latribune.fr/opinions/tribunes/blake-lemoine-l-homme-qui-s-est-fait-berner-par-l-intelligence-artificielle-de-google-927289.html>Blake Lemoine,
l&rsquo;homme qui s&rsquo;est fait berner par l&rsquo;intelligence artificielle de
Google</a>
(La Tribune).</p><p>La vision transhumaniste qui perçoit l&rsquo;IA comme un outil pour dépasser les
limites biologiques de l&rsquo;humain. Nous complétons la documentation portant sur
cette quatrième vision par l&rsquo;article de Damour, F. (2018), <a href="https://shs.cairn.info/article/VING_138_0143?tab=texte-integral">Le mouvement
transhumaniste</a>. Vingtième Siècle. Revue d&rsquo;histoire, 138(2), 143-156 et par le cours ouvert en ligne &ldquo;5min pour comprendre transhumanisme&rdquo;.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/t423l0MAit8?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><h2 id=tableau-comparatif>Tableau comparatif<a class=anchor href=#tableau-comparatif>#</a></h2><table><thead><tr><th>Critères</th><th>Attitude libérale</th><th>Attitude optimiste / accélérationniste</th><th>Attitude défaitiste / doomers</th><th>Vision transhumaniste</th></tr></thead><tbody><tr><td><strong>Idée centrale</strong></td><td>L’IA est un outil puissant au service de l’humain, à encadrer par des lois, normes et valeurs démocratiques.</td><td>L’IA est un levier de progrès exponentiel pour l’humanité. Elle accélère le développement humain vers de nouvelles capacités.</td><td>L’IA est une menace potentielle, voire existentielle, si elle échappe à notre contrôle.</td><td>L’IA est un vecteur pour dépasser les limites biologiques de l’humain, vers une coévolution humain-machine.</td></tr><tr><td><strong>Valeurs associées</strong></td><td>Régulation, responsabilité, gouvernance éthique, contrôle démocratique.</td><td>Innovation, progrès, croissance technologique illimitée, confiance dans la science.</td><td>Précaution, prudence, alerte sur les dérives, contrôle strict ou limitation.</td><td>Dépassement de l’humain, augmentation, immortalité numérique, fusion bio-techno.</td></tr><tr><td><strong>Risques perçus</strong></td><td>Contrôle insuffisant, biais algorithmiques, inégalités si la régulation est faible.</td><td>Déshumanisation, fracture sociale si l’accélération n’est pas partagée.</td><td>Perte de contrôle, extinction de l’espèce humaine par une IA superintelligente.</td><td>Perte d’identité humaine, éthique floue sur l’augmentation ou la modification du vivant.</td></tr><tr><td><strong>Figures ou exemples</strong></td><td>UE : Charte éthique IA, L. Floridi, documentaire <em>IA Décodée</em>.</td><td>Ray Kurzweil, Elon Musk (phase techno-optimiste), Singularité.</td><td>Nick Bostrom, Yudkowsky, mouvements « extinction risk ».</td><td>More & Vita-More, <em>Homo Digitalis</em> (ARTE), débats sur l’« homme augmenté ».</td></tr><tr><td><strong>Questions clés</strong></td><td>Comment encadrer l’IA pour protéger l’intérêt commun ?</td><td>Comment exploiter l’IA pour accélérer le progrès humain ?</td><td>Comment prévenir un risque existentiel lié à une IA autonome ?</td><td>Jusqu’où voulons-nous aller dans le dépassement des limites humaines ?</td></tr></tbody></table></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class="flex align-center book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title="Module 5 - Autour de l'IA">
<span>Module 5 - Autour de l'IA</span>
</a></span><span><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/ class="flex align-center book-icon"><span>Conversation synoptique autour de l'IA</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Conversation synoptique autour de l'IA"></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#lattitude-libérale>L&rsquo;attitude libérale</a></li><li><a href=#lattitude-défaitiste-ou-fataliste>L&rsquo;attitude défaitiste (ou fataliste)</a></li><li><a href=#lattitude-optimiste-ou-accélérationniste>L&rsquo;attitude optimiste (ou accélérationniste)</a></li><li><a href=#le-transhumanisme>Le transhumanisme</a></li><li><a href=#tableau-comparatif>Tableau comparatif</a></li></ul></nav></div></aside></main></body></html>