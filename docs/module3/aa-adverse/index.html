<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Apprentissage automatique adverse
  #

Il existe un sous-domaine fascinant de l&rsquo;apprentissage automatique, qui consiste
à comprendre et étudier une de ses faiblesses étonnantes, les attaques
adverses.
Voici tout d&rsquo;abord un exemple fameux, provenant d&rsquo;un article séminal de
2014 :

Dans certains cas pathologiques, il est donc possible pour un modèle de faire
une erreur qui apparaît difficilement concevable pour un humain, à savoir
classifier deux images pratiquement identiques, de manière complètement
différente. Voyons comment ceci est possible."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module3/aa-adverse/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Apprentissage automatique adverse"><meta property="og:description" content="Apprentissage automatique adverse # Il existe un sous-domaine fascinant de l’apprentissage automatique, qui consiste à comprendre et étudier une de ses faiblesses étonnantes, les attaques adverses.
Voici tout d’abord un exemple fameux, provenant d’un article séminal de 2014 :
Dans certains cas pathologiques, il est donc possible pour un modèle de faire une erreur qui apparaît difficilement concevable pour un humain, à savoir classifier deux images pratiquement identiques, de manière complètement différente. Voyons comment ceci est possible."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Apprentissage automatique adverse | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module3/aa-adverse/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.97898183dc29e99dd0d8e5c58bc35164ef42b34cfa3992d69b27fc92f94774a9.css integrity="sha256-l4mBg9wp6Z3Q2OXFi8NRZO9Cs0z6OZLWmyf8kvlHdKk=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/css/applet.css></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><img src=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png alt=Logo class=book-icon><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Approche pédagogique du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/feuille-de-route/>Feuille de route</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/changelog/>Évolution du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/discord/>Serveur Discord</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/ class=flex-auto>Module 1 - Intelligence artificielle</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/ class=flex-auto>Module 2 - Apprentissage automatique</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/>Un scénario pour se faire une idée</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/diff%C3%A9rence-avec-x/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/algo-le-plus-simple/>L'algorithme le plus simple</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/similarit%C3%A9/>Le concept de similarité</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/mod%C3%A8les/>Qu'est-ce qu'un modèle?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/>Les paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/>Apprentissage supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/>Apprentissage non supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle checked>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/ class=flex-auto>Module 3 - Réseaux de neurones et apprentissage profond</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/architectures-avanc%C3%A9es/>Architectures avancées</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/aa-adverse/ class=active>Apprentissage automatique adverse</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/ class=flex-auto>Module 4 - IA générative et grands modèles de langage</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class=flex-auto>Module 5 - Autour de l'IA</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/>Attitudes à l'égard de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/menu.svg class=book-icon alt=Menu></label><h3>Apprentissage automatique adverse</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><h1 id=apprentissage-automatique-adverse>Apprentissage automatique adverse
<a class=anchor href=#apprentissage-automatique-adverse>#</a></h1><p>Il existe un sous-domaine fascinant de l&rsquo;apprentissage automatique, qui consiste
à comprendre et étudier une de ses faiblesses étonnantes, les <strong>attaques
adverses</strong>.</p><p>Voici tout d&rsquo;abord un exemple fameux, provenant d&rsquo;un <a href=https://arxiv.org/pdf/1412.6572>article séminal de
2014</a> :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module3/panda-vs-gibbon2.png alt></p><p>Dans certains cas pathologiques, il est donc possible pour un modèle de faire
une erreur qui apparaît difficilement concevable pour un humain, à savoir
classifier deux images pratiquement identiques, de manière complètement
différente. Voyons comment ceci est possible.</p><p>Nous avons déjà expliqué au deuxième module que le calcul effectué par un
algorithme de classification consiste d&rsquo;abord à trouver la direction dans
laquelle les paramètres pourraient évoluer pour faire diminuer l&rsquo;erreur (de
classification) de la manière la plus significative (la direction du gradient).
Une fois cette direction calculée, on modifie les paramètres du modèle (ses
poids) afin de les orienter dans cette direction. Ce faisant, on améliore la
performance du modèle, qui devient plus efficace pour déterminer si une image
est celle d&rsquo;un <code>panda</code> ou d&rsquo;un <code>gibbon</code> dans notre exemple. Même si la
correction se fait sur une erreur particulière, après une série de corrections
diverses (provenant de plusieurs images différentes), notre modèle devrait
pouvoir, idéalement, <em>généraliser</em> à la classification de nouvelles images.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module3/panda-ml.png alt></p><p>Imaginons maintenant que nous avons un modèle déjà entraîné. Pour produire une
image adverse, par exemple celle d&rsquo;un panda qui sera classifiée en tant que
gibbon, on peut calculer le gradient dans la direction <em>contraire</em> de celle
utilisée à l’entraînement, soit la direction où l&rsquo;erreur <em>augmenterait</em>. Mais
étant donné que le modèle est déjà entraîné, il n&rsquo;est pas question de modifier
ses paramètres, qui sont désormais fixés. La seule chose qui reste possible est
de changer les pixels de l&rsquo;image de départ, afin de créer une <em>nouvelle</em> image.
Cette nouvelle image est modifiée en fonction du gradient, de manière à ce
qu&rsquo;elle se &ldquo;déplace&rdquo; dans la direction où l&rsquo;erreur de classification sera
augmentée. Et, de façon cruciale, nous voulons obtenir une image dont la
perturbation sera minimale (c.-à-d. que les pixels seront modifiés de la manière
la plus discrète possible), afin qu&rsquo;elle continue de ressembler à un panda (tout
en étant incorrectement classifiée en tant que gibbon).</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module3/panda-adverse.png alt></p><p>Il est même possible d&rsquo;aller encore plus loin, et de créer une image adverse
encore plus proche de l&rsquo;originale (dont la différence est donc encore moins
facilement discernable), qui diffère seulement par un pixel :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module3/panda-vs-gibbon.png alt></p><p>Le fait que ceci soit possible devrait vous rendre perplexe et aussi légèrement
inquiet. Cette perplexité est avant tout de nature scientifique et
philosophique : comment se fait-il qu&rsquo;une intelligence, même artificielle,
puisse être trompée aussi facilement, par une simple différence de quelques
pixels ? Du point de vue du jugement humain, cela paraît déconcertant. Ceci
semble presque carrément contredire la notion même d&rsquo;intelligence : si
l&rsquo;algorithme a réellement <em>compris</em> ce qu&rsquo;est, de manière générale, un panda, ne
devrait-il pas se montrer plus robuste, et ne pas se laisser berner aussi
aisément? Pourtant, si on y réfléchit, l&rsquo;esprit humain est lui aussi facilement
abusé par de simples illusions d&rsquo;optique :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module3/duck-rabbit.png alt></p><p>Et finalement, pourquoi devrait-on être inquiet ? Eh bien, parce qu&rsquo;il est
possible d&rsquo;utiliser des attaques adverses de ce genre sur des applications
réelles d&rsquo;IA, pour créer des effets néfastes. Il est par exemple possible de
modifier légèrement un panneau routier, afin de tromper l&rsquo;IA qui pilote un
véhicule :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module3/stop-adverse.png alt></p><p>Cette étrange faille de l&rsquo;apprentissage automatique ne se limite pas à la
classification d&rsquo;images. Elle concerne tous les types d&rsquo;IA, y compris les grands
modèles de langage, comme nous le verrons dans le prochain module. Elle
constitue une source d&rsquo;étonnement scientifique et philosophique, car elle montre
clairement à quel point une intelligence artificielle est différente de son
analogue humaine.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><div class="flex flex-wrap justify-between"><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/architectures-avanc%C3%A9es/ class="flex align-center float-left book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title="Architectures avancées">
<span>Architectures avancées</span>
</a><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/ class="flex align-center float-right book-icon"><span>Travail noté 3</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Travail noté 3"></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>