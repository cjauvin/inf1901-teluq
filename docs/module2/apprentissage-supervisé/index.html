<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Apprentissage supervisé
  #

L&rsquo;apprentissage supervisé fonctionne à partir de données pour lesquelles la
&ldquo;bonne réponse&rdquo; (i.e. celle qu&rsquo;on aimerait que l&rsquo;algorithme fournisse
systématiquement, une fois entraîné) est fournie, en tant que donnée
d’entraînement. L&rsquo;apprentissage supervisé correspond à la notion intuitive qu&rsquo;on
a de l&rsquo;enseignement et de l&rsquo;apprentissage : un enseignant qui pose une question
à un étudiant  est en mesure de le corriger en lui indiquant si sa réponse est
correcte ou non (car l&rsquo;enseignant connaît, à priori, la &ldquo;bonne réponse&rdquo; à sa
propre question)."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Apprentissage supervisé"><meta property="og:description" content="Apprentissage supervisé # L’apprentissage supervisé fonctionne à partir de données pour lesquelles la “bonne réponse” (i.e. celle qu’on aimerait que l’algorithme fournisse systématiquement, une fois entraîné) est fournie, en tant que donnée d’entraînement. L’apprentissage supervisé correspond à la notion intuitive qu’on a de l’enseignement et de l’apprentissage : un enseignant qui pose une question à un étudiant est en mesure de le corriger en lui indiquant si sa réponse est correcte ou non (car l’enseignant connaît, à priori, la “bonne réponse” à sa propre question)."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Apprentissage supervisé | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.97898183dc29e99dd0d8e5c58bc35164ef42b34cfa3992d69b27fc92f94774a9.css integrity="sha256-l4mBg9wp6Z3Q2OXFi8NRZO9Cs0z6OZLWmyf8kvlHdKk=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><img src=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png alt=Logo class=book-icon><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Approche pédagogique du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/feuille-de-route/>Feuille de route</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/ class=flex-auto>Module 1 - Intelligence artificielle</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle checked>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/ class=flex-auto>Module 2 - Apprentissage automatique</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/>Un scénario réaliste</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/diff%C3%A9rence-avec-x/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/mod%C3%A8les/>Qu'est-ce qu'un modèle?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/>Les paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/ class=active>Apprentissage supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/>Apprentissage non supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/ class=flex-auto>Module 3 - Réseaux de neurones et apprentissage profond</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/architectures-avanc%C3%A9es/>Architectures avancées</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/ class=flex-auto>Module 4 - IA générative et grands modèles de langage</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class=flex-auto>Module 5 - Autour de l'IA</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/>Attitudes à l'égard de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/menu.svg class=book-icon alt=Menu></label><h3>Apprentissage supervisé</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#classification>Classification</a><ul><li><a href=#la-régression-logistique>La régression logistique</a></li><li><a href=#classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)</a></li><li><a href=#classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)</a><ul><li><a href=#représenter-un-courriel-comme-un-vecteur>Représenter un courriel comme un vecteur</a></li><li><a href=#le-modèle-probabiliste--multinomial>Le modèle probabiliste : multinomial</a></li><li><a href=#rappel--hypothèse-de-naïveté>Rappel : hypothèse de naïveté</a></li><li><a href=#décision-du-classificateur>Décision du classificateur</a></li></ul></li><li><a href=#autres-algorithmes-de-classification>Autres algorithmes de classification</a></li></ul></li><li><a href=#régression>Régression</a><ul><li><a href=#régression-linéaire>Régression linéaire</a><ul><li><a href=#la-fonction-derreur--mesurer-limperfection>La fonction d&rsquo;erreur : mesurer l&rsquo;imperfection</a></li><li><a href=#minimiser-lerreur--deux-approches-principales>Minimiser l&rsquo;erreur : deux approches principales</a></li></ul></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=apprentissage-supervisé>Apprentissage supervisé
<a class=anchor href=#apprentissage-supervis%c3%a9>#</a></h1><p>L&rsquo;apprentissage supervisé fonctionne à partir de données pour lesquelles la
&ldquo;bonne réponse&rdquo; (i.e. celle qu&rsquo;on aimerait que l&rsquo;algorithme fournisse
systématiquement, une fois entraîné) est fournie, en tant que donnée
d’entraînement. L&rsquo;apprentissage supervisé correspond à la notion intuitive qu&rsquo;on
a de l&rsquo;enseignement et de l&rsquo;apprentissage : un enseignant qui pose une question
à un étudiant est en mesure de le corriger en lui indiquant si sa réponse est
correcte ou non (car l&rsquo;enseignant connaît, à priori, la &ldquo;bonne réponse&rdquo; à sa
propre question).</p><h2 id=classification>Classification
<a class=anchor href=#classification>#</a></h2><p>La famille d&rsquo;algorithmes d&rsquo;apprentissage supervisé la plus facile à comprendre
est celle des modèles de classification. Un algorithme de classification est une
fonction mathématique qui associe des &ldquo;objets&rdquo; (donc des points dans un
<a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/#niveau-de-lapprentissage-automatique-et-des-mathématiques>espace vectoriel</a>) vers une série prédéfinie d&rsquo;étiquettes, qu&rsquo;on appelle souvent des &ldquo;classes&rdquo;.</p><h3 id=la-régression-logistique>La régression logistique
<a class=anchor href=#la-r%c3%a9gression-logistique>#</a></h3><p>Considérons tout d&rsquo;abord un petit exemple interactif où vous jouerez vous-même
le rôle d&rsquo;un modèle de classification particulier : la <strong>régression
logistique</strong>. Les données d&rsquo;entraînement ont deux classes possibles : <code>bleue</code> ou
<code>rouge</code>, ainsi que deux valeurs (nombres, ou <em>paramètres</em>) pour les décrire :
$x$ et $y$ (puisqu&rsquo;il s&rsquo;agit d&rsquo;un graphe en deux dimensions). La tâche du modèle
est de séparer (c-à-d classifier) les deux groupes. La ligne pointillée constitue la
&ldquo;fonction de décision&rdquo; du modèle : les deux classes se situent de part et
d&rsquo;autre de la ligne. Comme il s&rsquo;agit d&rsquo;une fonction en deux dimensions, on peut
la représenter par la formule simple :</p>$$f(x) \le mx + b$$<p>où $m$ représente la pente et $b$ l&rsquo;ordonnée à l&rsquo;origine. Remarquez un détail
important : il s&rsquo;agit d&rsquo;une fonction d&rsquo;inégalité (inéquation), et non d&rsquo;égalité,
ce qui veut dire qu&rsquo;on peut l&rsquo;interpréter en tant que <em>fonction binaire</em> (deux
valeurs possibles) : <code>rouge</code> si $f(x) \le mx + b$ et <code>bleue</code> si $f(x) \gt mx +
b$ (ou vice versa, arbitrairement). Quand vous déplacez cette ligne de décision
vous-même (en utilisant la souris), vous modifiez les paramètres $m$ et $b$
dynamiquement. Ces paramètres constituent le <strong>modèle</strong>. La situation idéale est
quand cette ligne de décision sépare parfaitement les points rouges des points
bleus, ce qui correspond à une valeur de 0% pour la fonction d&rsquo;erreur (elle-même
représentée par la barre à droite, et distincte de la fonction de décision). Ce
n&rsquo;est pas toujours possible ! Notez qu&rsquo;il est possible d&rsquo;ajouter ou d&rsquo;enlever
des points, et de les déplacer, en utilisant la souris.</p><iframe src=https://cjauvin.github.io/inf1901-teluq/html/applets/logistic-regression.html id=applet-1762360291707726549 class=applet-iframe width=100% style=zgotmplz loading=lazy data-iresize=true></iframe><p>Remarquez un détail important : quoiqu&rsquo;on fasse, l&rsquo;erreur ne peut jamais
dépasser 50%. Quand on y pense, c&rsquo;est logique, car même si on place la ligne de
décision à un endroit extrême, qui fait en sorte que TOUS les points se trouvent
d&rsquo;un côté, il reste que 50% de ceux-ci sont tout de même correctement
classifiés. Et si on place la ligne dans une configuration plus pathologique,
qui ferait en sorte par exemple que 75% des points seraient incorrectement
classifiés, la chose logique à faire (ce que l&rsquo;applet interactive fait en fait)
est d&rsquo;inverser le schéma de classification (les points <code>bleus</code> deviennent
<code>rouges</code>, et vice versa), ce qui fait en sorte que l&rsquo;erreur est réduite à 25%.</p><p>La tâche de l&rsquo;algorithme de régression logistique est de trouver les &ldquo;meilleures&rdquo;
valeurs pour les paramètres pour la fonction de décision (donc $m$ et $b$),
celles qui font en sorte que la valeur de la fonction d&rsquo;erreur est la plus
petite possible (idéalement <em>zéro</em>).</p><blockquote class="book-hint info"><p>Matière à réflexion : pourquoi ce n&rsquo;est pas toujours possible de séparer
parfaitement les points? Dans quelles conditions est-ce le cas? Qu&rsquo;est-ce qui
permettrait de faire en sorte que ça devienne possible?</p></blockquote><details><summary>Les mathématiques de la régression logistique (un sujet optionnel, plus complexe)</summary><div class=markdown-inner><p>Bien que nous en ayons parlé en termes purement géométriques jusqu&rsquo;ici, la
régression logistique est en fait une méthode probabiliste : un point est
considéré <code>bleu</code> si le modèle calcule que la probabilité qu&rsquo;il le soit est $\ge
50\%$ (et évidemment vice versa pour <code>rouge</code>). Une probabilité est une valeur
nécessairement entre 0 et 1. Pour transformer une fonction arbitraire en une
fonction de probabilité, on peut utiliser la fonction sigmoïde (aussi appelée
fonction logistique), qui &ldquo;force&rdquo; une valeur à être dans la plage 0 et 1 :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/Logistic-curve-02.png alt></p><p>Nous allons à partir d&rsquo;ici changer un peu la notation que nous avons utilisée
jusqu&rsquo;ici, pour la rendre plus générale :</p>$$\mathbf{x} = [x_1, x_2]$$<p></p>$$y \in \{0, 1\}$$<p>Cette notation classique en apprentissage automatique utilise donc $\mathbf{x}$
pour dénoter les points en 2D sous forme vectorielle ($x_1$ et $x_2$
correspondent aux $x$ et $y$ de la représentation 2D classique, et $\mathbf{x}$
est donc un <em>vecteur</em>, dont les 2 valeurs correspondent aux &ldquo;caractéristiques&rdquo;
d&rsquo;un point, sa description numérique). La variable scalaire (donc une valeur
numérique simple, par opposition à un vecteur) $y$ est utilisée pour dénoter la
<em>vraie</em> classe d&rsquo;un point (0 ou 1, correspondant arbitrairement à <code>bleu</code> ou
<code>rouge</code>). Les paramètres seront représentés par le vecteur $\mathbf{w} = [w_1,
w2]$. Il est maintenant possible de réécrire notre fonction de décision à l&rsquo;aide
de cette nouvelle notation vectorielle :</p>$$z = \mathbf{w}^\top \mathbf{x} + b.$$<p>($\mathbf{w}^\top \mathbf{x}$ est le produit vectoriel de $\mathbf{w}$ et
$\mathbf{x}$). Notons tout d&rsquo;abord qu&rsquo;il y maintenant 3 paramètres ($w1$, $w2$
et $b$), alors que dans l&rsquo;exemple ci-haut seulement 2 sont mentionnés : $m$ et
$b$. On introduit aussi une nouvelle variable $z$ : que veut-elle dire? Pour
comprendre cela, on doit faire un peu d&rsquo;algèbre. Il suffit de noter que notre
équation de départ :</p>$$y = mx + b$$<p>est en fait équivalente à :</p>$$x_2 = mx_1 + b$$<p>ce qu&rsquo;on peut réécrire aisément :</p>$$mx_1 - x_2 + b = 0.$$<p>En choisissant ensuite $m = -w_1/w_2$ et $b = -b/w_2$, on peut réécrire :</p>$$\frac{-w_1 x_1}{w_2} - x_2 - \frac{b}{w_2} = 0$$<p>En multipliant les deux membres de l&rsquo;équation par $-w_2$, on arrive à :</p>$$w_1 x_1 + w_2 x_2 + b = 0$$<p>ce qui constitue la forme générale d&rsquo;une équation en 2D. Étant donné que ce qui
nous intéresse se passe de part et d&rsquo;autre de la ligne de décision (car il
s&rsquo;agit comme nous l&rsquo;avons vu d&rsquo;une inéquation), on introduit le score $z$, pour
quantifier la distance à laquelle un point se trouve, de cette ligne de
séparation :</p>$$z = w_1 x_1 + w_2 x_2 + b$$<p>En utilisant la fonction logistique que nous avons introduite ci-haut pour
transformer ce score (une valeur arbitraire) en une probabilité (donc une valeur
contrainte entre 0 et 1), on peut maintenant introduire l&rsquo;équation de la
régression logistique :</p>$$P(y) = \hat{y} = \frac{1}{1 + e^{-z}}$$<p>avec laquelle il est bien important de comprendre que $\hat{y}$ représente une
probabilité (donc que $\hat{y} \in [0, 1]$), tandis que $y$ représente une vraie
classe (donc que $y \in {0, 1}$). La régression logistique transforme donc la
distance entre un point et la ligne de décision, en une mesure de probabilité.
L&rsquo;algorithme de classification utilisera donc la probabilité calculée pour chaque
point de la manière suivante :</p>$$
\text{classification}(x_1, x_2) =
\left\{
\begin{array}{ll}
\mathtt{bleu} \text{ si } \hat{y} \ge 0.5 & \\
\mathtt{rouge} \text{ si } \hat{y} < 0.5 & \\
\end{array}
\right.
$$<p>Notre but est maintenant de trouver les valeurs optimales pour les paramètres
$\mathbf{w}$ (donc deux nombres précis, $w_1$ et $w_2$), celles qui vont faire en
sorte de minimiser l&rsquo;erreur de classification. Nous avons donc besoin de définir
tout d&rsquo;abord cette erreur en tant que fonction précise :</p>$$E(y, \hat{y}) = -[y \log(\hat{y}) + (1 - y)\log(1 - \hat{y})]$$<p>Pour bien comprendre le fonctionnement de cette équation, examinons les différents
cas de figure :</p><ol><li>Un point est en réalité <code>bleu</code> (donc $y = 1$) et la confiance du modèle en ce fait est élevée ($\hat{y} = 0.9$) : $E(y, \hat{y}) = -\log(0.9) \approx 0.1$ (l&rsquo;erreur est basse).</li><li>Un point est en réalité <code>bleu</code> (donc $y = 1$) mais la confiance du modèle en ce fait est basse ($\hat{y} = 0.1$) : $E(y, \hat{y}) = -\log(0.1) \approx 2.3$ (l&rsquo;erreur est élevée).</li><li>Un point est en réalité <code>rouge</code> (donc $y = 0$) et la confiance du modèle en ce fait est élevée ($\hat{y} = 0.1$) : $E(y, \hat{y}) = -\log(0.9) \approx 0.1$ (l&rsquo;erreur est basse).</li><li>Un point est en réalité <code>rouge</code> (donc $y = 0$) mais la confiance du modèle en ce fait est basse ($\hat{y} = 0.9$) : $E(y, \hat{y}) = -\log(0.1) \approx 2.3$ (l&rsquo;erreur est élevée).</li></ol><p>La fonction d&rsquo;erreur $E$ que nous avons s&rsquo;applique à un seul point. Nous avons
besoin de la généraliser à l&rsquo;ensemble des $n$ points que nous avons, en en
faisant simplement la somme. Ceci est une nouvelle fonction nommée $J$, qui
utilise des indices $(i)$ pour dénoter les valeurs associées aux points
particuliers de notre ensemble d’entraînement :</p>$$J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} E(y^{(i)}, \hat{y}^{(i)})$$<p></p>$$J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} \left[ y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)}) \right]$$<p>Vous pouvez remarquer qu&rsquo;on spécifie cette fois les paramètres $\mathbf{w}$ et
$b$ pour la fonction $J$ : la raison est que nous voulons maintenant <em>optimiser</em>
la fonction $J$, c&rsquo;est-à-dire trouver les valeurs de ses paramètres
($\mathbf{w}$ et $b$) qui vont faire en sorte de la minimiser (c-à-d que sa
valeur soit la plus petite possible, quand on considère l&rsquo;ensemble de toutes ses
valeurs possibles, donc indirectement via l&rsquo;ensemble de toutes les valeurs
possibles pour ses paramètres $\mathbf{w}$ et $b$). Cette opération
d&rsquo;optimisation est l&rsquo;essence même de l&rsquo;apprentissage automatique. Apprendre,
c&rsquo;est optimiser une fonction d&rsquo;erreur, de manière à la rendre la plus petite
possible. On fait cela à l&rsquo;aide de la technique de la <strong>descente de gradient</strong>,
qui consiste à déterminer tout d&rsquo;abord la &ldquo;direction&rdquo; (c-à-d le vecteur) dans
laquelle la valeur de la fonction change le plus, à un point donné. Si on
utilise la métaphore d&rsquo;un terrain montagneux pour représenter une fonction
d&rsquo;erreur en 3 dimensions, l&rsquo;altitude d&rsquo;un point à un endroit particulier
représente la valeur de la fonction, tant que les coordonnées géographiques du
point (<code>x</code> et <code>y</code>, ou lat/lon si on utilise un GPS), représentent les
paramètres. Le gradient, dans cette métaphore, représente la direction dans
laquelle le changement d&rsquo;altitude sera le plus abrupt.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/mountain_gradient.jpg alt></p>$$\frac{\partial J}{\partial \mathbf{w}} = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)}) \mathbf{x}^{(i)}$$<p></p>$$\frac{\partial J}{\partial b} = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)})$$<p>Le symbole $\partial$ peut faire un peu peur à priori, mais sa signification
devient claire quand on le traduit en mots : le gradient de la fonction $J$ par
rapport au paramètre $w$ (ou $b$). Et son calcul, dans le cas de la régression
logistique, est très simple : pour chaque point, on considère :</p><ol><li>La différence entre la probabilité produite par le modèle et la vraie étiquette : $\hat{y}^{(i)} - y^{(i)}$</li><li>Le produit de cette différence et du vecteur d&rsquo;entrée : $(\hat{y}^{(i)} - y^{(i)}) \mathbf{x}^{(i)}$ (rappelons que $\mathbf{x} = [x_1, x_2]$ est un vecteur
à deux dimensions, donc ce produit sera également bi-dimensionnel, tout comme l&rsquo;est également $\mathbf{w}$)</li><li>On veut la moyenne de ces produits (donc la somme et une division)</li></ol><p>Nos règles de mise à jour (la mise à jour, qui est un concept généralement plus
associé à la programmation qu&rsquo;aux mathématiques, est représentée ici par le
symbole $\leftarrow$) pour les paramètres sont donc :</p>$$\mathbf{w} \leftarrow \mathbf{w} - \alpha \cdot \frac{\partial J}{\partial \mathbf{w}}, \quad b \leftarrow b - \alpha \cdot \frac{\partial J}{\partial b}$$<p>L&rsquo;algorithme d&rsquo;optimisation (apprentissage) de la régression logistique consiste
donc en l&rsquo;application itérative (répétée) de ces règles de mise à jour des
paramètres, qui feront en sorte de changer graduellement les valeurs de
$\mathbf{w}$ et $\mathbf{b}$, tout en diminuant également progressivement la
valeur de l&rsquo;erreur cumulée, c&rsquo;est-à-dire la valeur de la fonction $J$. $\alpha$
est le <em>taux d&rsquo;apprentissage</em> (une simple valeur numérique), qui fait en sorte
de limiter la taille des &ldquo;pas&rdquo; qu&rsquo;on prend dans la direction du gradient, à
chaque itération. Pour le distinguer des paramètres ($\mathbf{w}$ et
$\mathbf{b}$), on appelle $\alpha$ un <em>hyper-paramètre</em>.</p></div></details><br><details><summary>La programmation de la régression logistique (un sujet optionnel, plus technique)</summary><div class=markdown-inner><p>Si cela vous intéresse, voici du code Python qui met en oeuvre la régression
logistique que nous venons d&rsquo;étudier. Le code est délibérément détaillé et assez
&ldquo;bas niveau&rdquo;, car il utilise seulement
<a href=https://fr.wikipedia.org/wiki/NumPy>numpy</a>, une librairie pour faire des
opérations basées sur l&rsquo;algèbre linéaire (ainsi que
<a href=https://fr.wikipedia.org/wiki/Matplotlib>Matplotlib</a> pour faire les
visualisations). Si on utilisait une librairie d&rsquo;apprentissage automatique
spécialisée, comme <a href=https://fr.wikipedia.org/wiki/Scikit-learn>Scikit-learn</a>
par exemple, le code serait plus simple et compact, étant donné que le niveau
d&rsquo;abstraction serait plus élevé (bien qu&rsquo;il s&rsquo;agirait toujours de Python, le
code serait de plus &ldquo;haut niveau&rdquo;). Il n&rsquo;est pas nécessaire de comprendre ce
code dans les détails, mais il peut s&rsquo;avérer intéressant d&rsquo;en avoir un aperçu,
car il est très représentatif de ce qui se fait dans de vrais environnements de
programmation.</p><iframe src=https://cjauvin.github.io/inf1901-teluq/html/notebooks/module2/reglog.html width=100% height=800px></iframe></div></details><h3 id=classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)
<a class=anchor href=#classification-bay%c3%a9sienne-naive-gaussienne>#</a></h3><p>Examinons maintenant un autre algorithme de classification que nous pourrions
utiliser sur nos données en deux dimensions.</p><p>La régression logistique est un algorithme d&rsquo;apprentissage <strong>discriminatif</strong> :
elle tente de modéliser la probabilité qu&rsquo;un exemple appartienne directement à
une classe (<code>bleue</code> ou <code>rouge</code>) directement à partir des caractéristiques de cet
exemples ($x_1$ et $x_2$). En contraste, la classification naive bayésienne est
un algorithme <strong>génératif</strong>, qui tente tout d&rsquo;abord de modéliser la distribution
statistiques des classes, avant d&rsquo;utiliser ces modèles (un modèle pour la classe
<code>bleue</code> et un pour la classe <code>rouge</code>) pour déterminer si un point particulier a
plus de chance d&rsquo;avoir été <em>généré</em> par un modèle particulier (disons <code>rouge</code>)
plutôt qu&rsquo;un autre. Cette &ldquo;inversion&rdquo; qui permet à un modèle discriminatif d&rsquo;être construit
en fonction d&rsquo;un modèle génératif sous-jacent, est effectuée à l&rsquo;aide d&rsquo;un résultat fondamental
en probabilité : le <a href=https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Bayes>théorème de Bayes</a>.</p><details><summary>Les mathématiques de la classification bayésienne naive (optionnel)</summary><div class=markdown-inner><p>Chaque couple <strong>dimension + classe</strong> sera modélisé par une gaussienne à une
dimension (donc 4 modèles en tout : un pour la classe <code>rouge</code> sur la dimension
$x$, un pour la classe <code>bleue</code> aussi sur $x_1$, et la même chose pour la
dimension $x_2$). Une gaussienne (aussi appelée distribution normale) est la
fameuse &ldquo;courbe en cloche&rdquo;, qui détermine comment la &ldquo;masse de probabilité&rdquo; est
répartie autour d&rsquo;une valeur centrale (qu&rsquo;on appelle la moyenne) :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/gaussian.png alt></p><p>La gaussienne est une fonction continue 1D car elle n&rsquo;a qu&rsquo;une seule valeur
dépendante (l&rsquo;axe horizontal). L&rsquo;axe vertical, la valeur de la fonction,
correspond à la masse de la probabilité. Remarquez un aspect important : la
valeur de la fonction à un point précis donné sur l&rsquo;axe horizontal (par exemple
la moyenne) ne correspond PAS à la probabilité de ce point, malgré ce que
l&rsquo;intuition voudrait croire. Étant donné que la masse de probabilité est une
fonction continue, pour obtenir une probabilité donnée il faut calculer
l&rsquo;intégrale de la fonction entre deux points donnés. Étant donné que la totalité
de la masse (l&rsquo;aire sous la courbe) est 1, on peut dire que la probabilité qu&rsquo;un
événement soit plus petit que la moyenne (ou plus grand) est de 50% (c-à-d que
l&rsquo;aire sous la courbe, ou l&rsquo;intégrale, de la partie à droite ou à gauche de la
barre verticale de la moyenne totalise 0.5).</p><p>Mais donc que veut-on dire par la modélisation par une gaussienne?</p><p>La première étape consiste à projeter les points sur l&rsquo;axe $x_1$, ce qui les
rend uni-dimensionnels.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x1_proj.png alt></p><p>Une fois les points projetés, on peut modéliser (c-à-d <em>décrire
mathématiquement</em>) les classes de points à l&rsquo;aide de gaussiennes, dont
l&rsquo;épaisseur correspondra à la densité (ou quantité) de points projetés sur
l&rsquo;axe, pour chaque classe.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x1_gauss.png alt></p><p>On répète la procédure pour les deux classes, sur l&rsquo;axe $x_2$.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x2_proj.png alt></p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x2_gauss.png alt></p><p>À ce stade, nous avons donc quatre modèles :</p>$$p(x_1 \mid \text{rouge}) = \mathcal{N}(x_1; \mu_{1,\text{rouge}}, \sigma_{1,\text{rouge}}^2)$$<p></p>$$p(x_2 \mid \text{rouge}) = \mathcal{N}(x_2; \mu_{2,\text{rouge}}, \sigma_{2,\text{rouge}}^2)$$<p></p>$$p(x_1 \mid \text{bleue}) = \mathcal{N}(x_1; \mu_{1,\text{bleue}}, \sigma_{1,\text{bleue}}^2)$$<p></p>$$p(x_2 \mid \text{bleue}) = \mathcal{N}(x_2; \mu_{2,\text{bleue}}, \sigma_{2,\text{bleue}}^2)$$<p>où $\mathcal{N}$ représente la gaussienne, et $\mu$ et $\sigma$ représentent ses
paramètres (qui déterminent sa forme particulière). L&rsquo;apprentissage d&rsquo;un modèle
de classification naive bayésienne constitue donc le calcul des valeurs
optimales pour ces différents paramètres, que l&rsquo;on peut faire directement dans
ce contexte (en contraste de la méthode itérative que nous avons utilisée pour
l&rsquo;apprentissage des paramètres de la régression logistique) :</p>$$\hat\mu_{1,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}} x_{i1},\quad$$<p></p>$$\hat\mu_{2,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}} x_{i2},$$<p></p>$$\hat\mu_{1,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}} x_{i1},\quad$$<p></p>$$\hat\mu_{2,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}} x_{i2},$$<p></p>$$\hat\sigma^2_{1,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}}(x_{i1}-\hat\mu_{1,\text{rouge}})^2,\quad$$<p></p>$$\hat\sigma^2_{2,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}}(x_{i2}-\hat\mu_{2,\text{rouge}})^2,$$<p></p>$$\hat\sigma^2_{1,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}}(x_{i1}-\hat\mu_{1,\text{bleue}})^2,\quad$$<p></p>$$\hat\sigma^2_{2,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}}(x_{i2}-\hat\mu_{2,\text{bleue}})^2.$$<p>On peut combiner les modèles :</p>$$p(x_1, x_2 \mid \text{rouge}) \;=\; p(x_1 \mid \text{rouge}) \cdot p(x_2 \mid \text{rouge})$$<p></p>$$p(x_1, x_2 \mid \text{bleue}) \;=\; p(x_1 \mid \text{bleue}) \cdot p(x_2 \mid \text{bleue})$$<p>ou encore, pour simplifier :</p>$$P(\mathbf{x} \mid y)$$<p>Notez qu&rsquo;on change ici la notation de $p$ à $P$, pour mettre l&rsquo;emphase sur le
fait que nous passons d&rsquo;une fonction de densité à une fonction de probabilité.
Ce modèle est <em>génératif</em>, car il génère un point $\mathbf{x}$ (donc ses
coordonnées $x_1$ et $x_2$), à partir d&rsquo;une classe donnée $y$ (<code>rouge</code> ou
<code>bleue</code>). On dit aussi que ce que ce modèle est la probabilité de $\mathbf{x}$
<em>conditionnelle</em> à $y$.</p><p>Mais ce qui nous intéresse, dans un contexte de classification, est l&rsquo;équivalent
de ce que nous avons calculé pour le modèle de régression logistique, soit :</p>$$P(y \mid \mathbf{x})$$<p>Il semble donc que notre modèle génératif soit le contraire de ce qu&rsquo;on l&rsquo;on
veut. Est-il possible de &ldquo;l&rsquo;inverser&rdquo;, pour obtenir le modèle que l&rsquo;on souhaite,
soit la probabilité d&rsquo;une classe étant donné un point?</p><p>Il est possible de faire cela à l&rsquo;aide du <a href=https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Bayes>théorème de
Bayes</a> (ce qui
explique donc le nom de l&rsquo;algorithme), qui stipule que :</p>$$P(y \mid \mathbf{x}) \;=\; \frac{P(\mathbf{x} \mid y) \, P(y)}{P(\mathbf{x})}$$<p>Nous connaissons déjà évidemment $P(\mathbf{x} \mid y)$, que nous avons calculé
ci-haut, et $P(y)$ est simple à calculer : il s&rsquo;agit simplement de la
probabilité à priori (sans aucune autre connaissance) que les points soient
<code>rouges</code> ou <code>bleus</code> (ce qui est possiblement 50%, équiprobable, si notre
ensemble d’entraînement est balancé, moitié <code>rouge</code> moitié <code>bleu</code>).
$P(\mathbf{x})$ est moins clair (la probabilité à priori des données?), mais
étant donné que cette valeur ne dépend pas de $y$, on peut simplement l&rsquo;ignorer
pour obtenir un algorithme de classification final :</p>$$
\text{classification}(\mathbf{x}) =
\left\{
\begin{array}{ll}
\mathtt{rouge} \text{ si } P(\mathbf{x} \mid \text{rouge}) P(\text{rouge}) \ge P(\mathbf{x} \mid \text{bleu}) P(\text{bleu}) & \\
\mathtt{bleu} \text{ sinon } & \\
\end{array}
\right.
$$<p>Tout comme la régression logistique que nous avons étudiée, cet algorithme
produit une décision linéaire, pour des raisons mathématiques que nous n&rsquo;allons
pas explorer plus à fond.</p><blockquote class="book-hint info"><p>Question intéressante à se poser : pourquoi la décision est une ligne?</p></blockquote></div></details><h3 id=classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)
<a class=anchor href=#classification-bay%c3%a9sienne-naive-multinomiale>#</a></h3><p>Nous avons vu jusqu’à présent deux exemples de classificateurs supervisés en
deux dimensions : la régression logistique et le naïf bayésien gaussien. Ces
modèles travaillaient directement dans l’espace des variables réelles, où chaque
donnée est représentée par un point dans le plan.</p><p>Nous allons maintenant changer de domaine d’application et considérer un
problème plus concret : la détection de courriels indésirables (pourriels, ou
spam en anglais). Ce sera aussi le sujet de votre <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>travail noté 2</a>.</p><h4 id=représenter-un-courriel-comme-un-vecteur>Représenter un courriel comme un vecteur
<a class=anchor href=#repr%c3%a9senter-un-courriel-comme-un-vecteur>#</a></h4><p>Comme nous l’avons expliqué dans le chapitre sur <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/#les-mots-et-leur-sens>les données</a>, un texte peut être
représenté par un vecteur dans l’« espace des mots ». Dans ce modèle vectoriel,
chaque dimension correspond à un mot du vocabulaire, et la valeur dans cette
dimension correspond au nombre de fois que le mot apparaît dans le document.</p><p>Ainsi, un courriel devient un vecteur en très haute dimension :</p>$$\mathbf{x} = (n_{1}, n_{2}, \ldots, n_{V})$$<p>où $n_{i}$ est le nombre d’occurrences du mot $i$ dans le courriel, et $V$ est
la taille du vocabulaire.</p><p>Il est utile de faire l&rsquo;effort de se représenter l&rsquo;analogie entre le
$\mathbf{x}$ de nos exemples 2D précédents, et ce $\mathbf{x}$ qui vit dans un
espace de beaucoup plus grande dimension, et composé de valeurs entières au lieu
de valeurs continues (les comptes pour chaque dimension / mot), mais tout de
même un vecteur de même nature.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/courriel_hyperplan.png alt></p><details><summary>Les mathématiques de la classification naive multinomiale (optionnel)</summary><div class=markdown-inner><h4 id=le-modèle-probabiliste--multinomial>Le modèle probabiliste : multinomial
<a class=anchor href=#le-mod%c3%a8le-probabiliste--multinomial>#</a></h4><p>Dans le cas du classificateur naïf bayésien pour les données en deux dimensions,
nous avions supposé que chaque classe (par exemple <code>bleu</code> et <code>rouge</code>) était
associée à une distribution gaussienne. Autrement dit, nous modélisions la
distribution des variables continues $x_1$ et $x_2$ à l’aide d’une loi normale.
Ce modèle est <em>génératif</em> dans le sens où il génère les données d&rsquo;une classe
(vecteurs 2D pour les classes <code>bleu</code> ou <code>rouge</code>, et vecteurs en dimension $|V|$
pour les classes <code>pourriel</code> ou <code>courriel</code>).</p><p>Dans le cas du texte d&rsquo;un courriel, la situation est différente. Les variables
$n_i$ sont des comptes de mots, et il est naturel de les modéliser par une
distribution multinomiale. Si on lance un dé à 6 faces 1000 fois, la
distribution multinomiale permet de calculer la probabilité d&rsquo;obtenir $X_1$ fois
la face, $X_2$ fois la face 2, et ainsi de suite. Il s&rsquo;agit donc d&rsquo;une
distribution qui modélise des événements <em>discrets</em> (des comptes entiers) par
opposition à la distribution normale qui modélise des valeurs <em>continues</em>.</p><p>Si un courriel appartient à la classe <code>pourriel</code>, alors la probabilité
d’observer un vecteur $\mathbf{x}$ de comptes de mots est :</p>$$P(\mathbf{x} \mid \text{pourriel}) = \frac{N!}{n_{1}! \, n_{2}! \, \cdots \, n_{V}!} \, \prod_{i=1}^{V} p_{i}^{\,n_{i}}$$<p>où :</p><ul><li>$N = \sum_{i=1}^{V} n_i$ est le nombre total de mots du courriel,</li><li>$p_i$ est la probabilité à priori qu’un mot de classe <code>pourriel</code> soit le mot $i$ (cette probabilité à priori est probablement plus grande pour le mot &ldquo;prix&rdquo; que pour le mot &ldquo;parent&rdquo;, par exemple).</li></ul><p>De la même façon, on définit un modèle multinomial pour la classe <code>courriel</code>.</p><h4 id=rappel--hypothèse-de-naïveté>Rappel : hypothèse de naïveté
<a class=anchor href=#rappel--hypoth%c3%a8se-de-na%c3%afvet%c3%a9>#</a></h4><p>Comme dans le modèle gaussien naïf bayésien, nous faisons l’hypothèse que les
mots sont générés indépendamment les uns des autres. Cette hypothèse est
évidemment fausse (certains mots apparaissent souvent ensemble), mais elle rend
le modèle beaucoup plus simple et efficace en pratique.</p><h4 id=décision-du-classificateur>Décision du classificateur
<a class=anchor href=#d%c3%a9cision-du-classificateur>#</a></h4><p>Pour classer un courriel, nous utilisons la règle de Bayes :</p>$$P(\text{pourriel} \mid \mathbf{x}) = \frac{P(x \mid \text{pourriel}) \, P(\text{pourriel})}{P(\mathbf{x})}$$$$P(\text{courriel} \mid \mathbf{x}) = \frac{P(\mathbf{x} \mid \text{courriel}) \, P(\text{courriel})}{P(\mathbf{x})}$$<p>ce qui permet, en ignorant $P(\mathbf{x})$ pour la même raison que celle
expliquée ci-haut, d&rsquo;obtenir un algorithme de classification similaire à celui
que nous avons déjà vu :</p>$$
\text{classification}(\mathbf{x}) =
\left\{
\begin{array}{ll}
\mathtt{pourriel} \text{ si } P(\mathbf{x} \mid \text{pourriel}) P(\text{pourriel}) \ge P(\mathbf{x} \mid \text{courriel}) P(\text{courriel}) & \\
\mathtt{courriel} \text{ sinon } & \\
\end{array}
\right.
$$<p>Cela montre que la décision finale est une combinaison linéaire pondérée des
fréquences de mots, ce qui fait le lien avec la régression logistique étudiée
précédemment.</p></div></details><h3 id=autres-algorithmes-de-classification>Autres algorithmes de classification
<a class=anchor href=#autres-algorithmes-de-classification>#</a></h3><p>Le monde des algorithmes de classification supervisé est extrêmement riche et créatif, et il en existe de très nombreux exemples, dont les principes et modes de fonctionnement sont complètement différents de ce que nous avons vu (<a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/#apprentissage-paramétrique-versus-non-paramétrique>paramétriques, non-paramétriques, inductifs, etc.</a>). Parmi les plus connus, on retrouve :</p><ul><li><a href=https://fr.wikipedia.org/wiki/M%C3%A9thode_des_k_plus_proches_voisins>k-NN</a></li><li><a href=https://fr.wikipedia.org/wiki/Machine_%C3%A0_vecteurs_de_support>SVM</a></li><li><a href=https://fr.wikipedia.org/wiki/Arbre_de_d%C3%A9cision>Arbre de décision</a></li><li><a href=https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_artificiels>Réseau de neurones</a></li></ul><h2 id=régression>Régression
<a class=anchor href=#r%c3%a9gression>#</a></h2><p>Comme nous l&rsquo;avons vu, les algorithmes de classification permettent de trouver les paramètres optimaux
d&rsquo;une fonction qui détermine à quelle classe, ou étiquette, un exemple
appartient (par ex. est-ce que cette image est un chat ou un chien, est-ce que ceci est un
pourriel ou un courriel?). Nous avons expliqué également en quoi il s&rsquo;agit d&rsquo;apprentissage automatique <em>supervisé</em>,
car l&rsquo;entraînement se fait à l&rsquo;aide de la &ldquo;bonne&rdquo; étiquette (ou classe), qu&rsquo;on connaît, qui est donnée à
priori.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/classif.png alt></p><p>Nous allons voir maintenant que les régressions sont une autre famille d&rsquo;algorithmes d&rsquo;apprentissage supervisé
où on cherche plutôt à trouver les paramètres optimaux d&rsquo;une fonction au sens
général, qui va fournir une valeur <em>distincte</em> pour chaque exemple. Par exemple,
je pourrais vouloir avoir une fonction qui me fournit l&rsquo;estimé du prix d&rsquo;une
maison, à partir de ses dimensions, de son année de construction et de son lieu
géographique. Ou encore, une fonction pour estimer le temps de vol, à partir du
lieu de départ, la destination, et la grosseur de l&rsquo;avion utilisé.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/regression.png alt></p><p>Une fonction de classification a un nombre restreint de valeurs possibles,
tandis qu&rsquo;une fonction de régression a une infinité de valeurs possibles. Dans
les deux cas il s&rsquo;agit d&rsquo;apprentissage supervisé, car dans les deux cas, on
possède la &ldquo;bonne réponse&rdquo; (soit sous la forme d&rsquo;une catégorie connue d&rsquo;avance,
ou de valeur d&rsquo;une fonction connue d&rsquo;avance) pour faire l’entraînement du
modèle, c&rsquo;est-à-dire trouver les paramètres optimaux, ceux qui font en sorte de
minimiser l&rsquo;erreur de classification ou de régression.</p><blockquote class="book-hint warning"><p>Attention à la confusion possible avec le fait que la régression logistique est
un algorithme de classification, en dépit de son nom.</p></blockquote><h3 id=régression-linéaire>Régression linéaire
<a class=anchor href=#r%c3%a9gression-lin%c3%a9aire>#</a></h3><p>Il existe de nombreux algorithmes de régression, mais nous allons nous contenter
d&rsquo;étudier le plus simple et le plus classique : la <em>régression linéaire</em>. Il
s&rsquo;agit d&rsquo;un algorithme particulièrement vénérable en fait, qui a des <a href=https://fr.wikipedia.org/wiki/R%C3%A9gression_lin%C3%A9aire#Histoire>origines historiques profondes</a>, qui datent de bien avant l&rsquo;informatique moderne.</p><blockquote class="book-hint info"><p>Les gens sont souvent un peu surpris et même incrédules d&rsquo;apprendre que la
modeste régression linéaire est une forme d&rsquo;intelligence artificielle&mldr; Ils se
demandent quel peut bien être le rapport entre trouver les coefficients d&rsquo;une
fonction linéaire et ChatGPT? C&rsquo;est bel et bien le cas pourtant, et ceci
illustre bien le fait qu&rsquo;il y a des liens profonds entre les statistiques (le
domaine auquel la régression linéaire est classiquement associé) et l&rsquo;IA au sens
moderne (qui est surtout centrée sur l&rsquo;apprentissage automatique, qui est une
forme de statistiques sur les stéroïdes, qui combine la puissance des
mathématiques et des ordinateurs modernes).</p></blockquote><p>Voici tout d&rsquo;abord un petit exemple interactif de régression linéaire, pour vous
faire une idée intuitive de son fonctionnement. Les points sont tout d&rsquo;abord
distribués de manière semi-aléatoire, c&rsquo;est à dire qu&rsquo;ils suivent grossièrement
la forme d&rsquo;une fonction linéaire implicite, dont les paramètres exacts sont connus de
l&rsquo;applet interactive, mais non de vous. Votre tâche est d&rsquo;ajuster la fonction
(donc ses paramètres) de manière à minimiser la fonction d&rsquo;erreur. Notez que la fonction
de séparation ne peut être <em>que</em> linéaire, c&rsquo;est une contrainte fondamentale de cet algorithme, qui évidemment explique aussi son nom.</p><iframe src=https://cjauvin.github.io/inf1901-teluq/html/applets/linear-regression.html id=applet-1762360291707868624 class=applet-iframe width=100% style=zgotmplz loading=lazy data-iresize=true></iframe><p>Comme vous avez pu le constater dans l&rsquo;exemple interactif ci-dessus, la
régression linéaire vise à trouver la ligne droite qui &ldquo;colle&rdquo; le mieux à un
ensemble de points dispersés. Contrairement à la classification, où l&rsquo;on sépare
des groupes en catégories discrètes (comme bleu ou rouge), ici on cherche à
prédire une valeur continue pour chaque point d&rsquo;entrée. Imaginez que les points
représentent des maisons : l&rsquo;axe x pourrait être la superficie en mètres carrés,
et l&rsquo;axe y le prix de vente. La ligne que vous ajustez deviendrait alors une
fonction qui estime le prix d&rsquo;une maison en fonction de sa taille – une
prédiction numérique précise, plutôt qu&rsquo;une simple étiquette. Le principe de
base est simple : on suppose que la relation entre les variables est linéaire,
c&rsquo;est-à-dire qu&rsquo;elle peut être décrite par l&rsquo;équation classique d&rsquo;une droite :</p>$$y = mx + b$$<p>où :</p><ul><li>$y$ est la valeur prédite (par exemple, le prix de la maison),</li><li>$x$ est la variable d&rsquo;entrée (par exemple, la superficie),</li><li>$m$ est la pente (qui indique comment $y$ change quand $x$ augmente),</li><li>$b$ est l&rsquo;ordonnée à l&rsquo;origine (la valeur de $y$ quand $x = 0$).</li></ul><p>Bien sûr, dans la réalité, les données ne tombent pas parfaitement sur une ligne
droite – il y a du bruit, des variations imprévues. C&rsquo;est là que la notion
d&rsquo;erreur entre en jeu : l&rsquo;algorithme mesure à quel point la ligne prédite
s&rsquo;éloigne des points réels, et ajuste $m$ et $b$ pour minimiser cette erreur
globale.</p><blockquote class="book-hint info"><p>Matière à réflexion : pourquoi assume-t-on une relation linéaire ? Dans quels
cas cela pourrait-il ne pas suffire, et que faire alors ? (Indice : pensez à des
extensions comme la régression polynomiale.)</p></blockquote><h4 id=la-fonction-derreur--mesurer-limperfection>La fonction d&rsquo;erreur : mesurer l&rsquo;imperfection
<a class=anchor href=#la-fonction-derreur--mesurer-limperfection>#</a></h4><p>Pour quantifier &ldquo;à quel point c&rsquo;est mauvais&rdquo;, on utilise une fonction d&rsquo;erreur
(aussi appelée fonction de perte ou de coût). Dans la régression linéaire, la
plus courante est l&rsquo;erreur quadratique moyenne (Mean Squared Error, ou MSE en
anglais). Pour chaque point de données, on calcule la différence entre la valeur
réelle $y_i$ et la valeur prédite $\hat{y}_i = m x_i + b$, on met cette
différence au carré (pour éviter que les erreurs positives et négatives
s&rsquo;annulent, et pour pénaliser plus les grosses erreurs), puis on fait la moyenne
sur tous les points.</p><p>Géométriquement, la régression linéaire cherche la droite qui minimise la somme
des distances verticales (et non perpendiculaires) entre chaque point et la
ligne. Ces distances verticales correspondent exactement aux résidus dont nous
parlions. Si vous imaginez que chaque point est relié à la ligne par un ressort
vertical, la position d&rsquo;équilibre de la ligne correspondrait exactement à la
solution de la régression linéaire. Vous développerez probablement une meilleure
intuition pour ce processus en manipulant l&rsquo;application interactive suivante :</p><iframe src=https://cjauvin.github.io/inf1901-teluq/html/applets/linear-regression-with-springs.html id=applet-1762360291707901906 class=applet-iframe width=100% style=zgotmplz loading=lazy data-iresize=true></iframe><details><summary>Les mathématiques de la régression linéaire (optionnel)</summary><div class=markdown-inner><p>Mathématiquement, pour $n$ points de données :</p>$$J(m, b) = \frac{1}{n} \sum_{i=1}^{n} (y_i - (m x_i + b))^2$$<p>Cette fonction $J$ est comme une &ldquo;carte topographique&rdquo; de l&rsquo;erreur : pour chaque
paire de valeurs $(m, b)$, elle donne une hauteur représentant le niveau
d&rsquo;erreur. L&rsquo;objectif est de trouver le point le plus bas de cette carte – les
valeurs optimales de $m$ et $b$ qui minimisent $J$. Dans l&rsquo;exemple interactif,
quand vous déplacez la ligne avec la souris, vous modifiez $m$ et $b$
manuellement, et vous voyez l&rsquo;erreur diminuer (ou augmenter) en temps réel. Mais
un algorithme fait ça automatiquement, de manière systématique.</p><h4 id=minimiser-lerreur--deux-approches-principales>Minimiser l&rsquo;erreur : deux approches principales
<a class=anchor href=#minimiser-lerreur--deux-approches-principales>#</a></h4><p>Il existe deux façons classiques de trouver ces paramètres optimaux : une
méthode analytique (exacte et rapide pour des cas simples) et une méthode
itérative (plus générale, surtout utile pour des problèmes complexes ou en haute
dimension).</p><h5 id=1-la-méthode-des-moindres-carrés-analytique>1. La méthode des moindres carrés (analytique)
<a class=anchor href=#1-la-m%c3%a9thode-des-moindres-carr%c3%a9s-analytique>#</a></h5><p>C&rsquo;est la plus traditionnelle, inventée par Gauss au 19e siècle. L&rsquo;idée est de
résoudre directement l&rsquo;équation qui met les dérivées partielles de $J$ à zéro
(les points où la pente de la &ldquo;carte topographique&rdquo; est nulle, donc un minimum).
Pour notre cas simple en une dimension :</p>$$ \frac{\partial J}{\partial m} = 0 \quad \text{et} \quad \frac{\partial J}{\partial b} = 0 $$<p>En résolvant ces équations, on obtient des formules fermées pour $m$ et $b$ :</p>$$m = \frac{n \sum (x_i y_i) - \sum x_i \sum y_i}{n \sum x_i^2 - (\sum x_i)^2}$$<p></p>$$b = \frac{\sum y_i - m \sum x_i}{n}$$<p>C&rsquo;est comme appuyer sur un bouton &ldquo;calculer&rdquo; : pas d&rsquo;itérations, juste un
résultat exact. Ça marche super bien pour des données pas trop volumineuses, et
c&rsquo;est ce que font la plupart des tableurs comme Excel quand vous ajoutez une
&ldquo;tendance linéaire&rdquo; à un graphique.</p><h5 id=2-la-descente-de-gradient-itérative>2. La descente de gradient (itérative)
<a class=anchor href=#2-la-descente-de-gradient-it%c3%a9rative>#</a></h5><p>C&rsquo;est la même technique que nous avons vue pour la régression logistique ! On
imagine $J(m, b)$ comme une vallée montagneuse en 3D (avec $m$ et $b$ comme
coordonnées x et y, et l&rsquo;erreur comme altitude). On commence avec des valeurs
aléatoires pour $m$ et $b$, puis on calcule le gradient (la direction de la
pente la plus raide vers le bas) et on fait un petit pas dans cette direction.
On répète jusqu&rsquo;à ce que l&rsquo;erreur ne diminue plus beaucoup.</p><p>Les règles de mise à jour sont :</p>$$ m \leftarrow m - \alpha \cdot \frac{\partial J}{\partial m} $$<p></p>$$ b \leftarrow b - \alpha \cdot \frac{\partial J}{\partial b} $$<p>Où $\alpha$ est le taux d&rsquo;apprentissage (un hyper-paramètre que l&rsquo;on ajuste :
trop grand, et on risque de &ldquo;sauter&rdquo; par-dessus le minimum ; trop petit, et ça
prend une éternité). Les dérivées partielles sont :</p>$$ \frac{\partial J}{\partial m} = -\frac{2}{n} \sum_{i=1}^{n} x_i (y_i - (m x_i + b)) $$<p></p>$$ \frac{\partial J}{\partial b} = -\frac{2}{n} \sum_{i=1}^{n} (y_i - (m x_i + b)) $$<p>Cette méthode est puissante car elle s&rsquo;étend facilement à plus de dimensions
(par exemple, prédire le prix d&rsquo;une maison avec superficie, âge, et nombre de
chambres – on aurait alors $y = w_1 x_1 + w_2 x_2 + w_3 x_3 + b$, avec un
vecteur de poids $\mathbf{w}$). C&rsquo;est aussi la base de l&rsquo;entraînement des
réseaux de neurones modernes.</p></div></details><blockquote class="book-hint info"><p>Une fois qu&rsquo;on a fait des efforts pour comprendre le fonctionnement de certains
algorithmes de base en apprentissage automatique, il peut être intéressant de
considérer, <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/#en-quoi-est-ce-que-ceci-constitue-de-lintelligence>à nouveau</a>, notre question d&rsquo;ordre philosophique (ou linguistique) : en quoi, au
juste, est-ce que cela constitue de l&rsquo;intelligence, <em>artificielle</em> ou non? Nous
allons voir par la suite en quoi les idées relativement simples et peu
puissantes que nous avons développées dans ce module vont évoluer vers les
systèmes beaucoup plus impressionnants qui jouent un rôle de plus en plus
important dans notre vie moderne.</p></blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><div class="flex flex-wrap justify-between"><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/ class="flex align-center float-left book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title="Les paradigmes de l'AA">
<span>Les paradigmes de l'AA</span>
</a><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/ class="flex align-center float-right book-icon"><span>Apprentissage non supervisé</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Apprentissage non supervisé"></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#classification>Classification</a><ul><li><a href=#la-régression-logistique>La régression logistique</a></li><li><a href=#classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)</a></li><li><a href=#classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)</a><ul><li><a href=#représenter-un-courriel-comme-un-vecteur>Représenter un courriel comme un vecteur</a></li><li><a href=#le-modèle-probabiliste--multinomial>Le modèle probabiliste : multinomial</a></li><li><a href=#rappel--hypothèse-de-naïveté>Rappel : hypothèse de naïveté</a></li><li><a href=#décision-du-classificateur>Décision du classificateur</a></li></ul></li><li><a href=#autres-algorithmes-de-classification>Autres algorithmes de classification</a></li></ul></li><li><a href=#régression>Régression</a><ul><li><a href=#régression-linéaire>Régression linéaire</a><ul><li><a href=#la-fonction-derreur--mesurer-limperfection>La fonction d&rsquo;erreur : mesurer l&rsquo;imperfection</a></li><li><a href=#minimiser-lerreur--deux-approches-principales>Minimiser l&rsquo;erreur : deux approches principales</a></li></ul></li></ul></li></ul></nav></div></aside></main><script src=https://cdn.jsdelivr.net/npm/iframe-resizer/js/iframeResizer.min.js defer></script><script>document.addEventListener("DOMContentLoaded",()=>{const e=document.querySelectorAll('iframe[data-iresize="true"]');if(!e.length||typeof iFrameResize!="function")return;const t={license:"GPLv3",checkOrigin:!1,heightCalculationMethod:"max"};e.forEach(e=>{const n={...t},s=e.getAttribute("data-hcm");s&&(n.heightCalculationMethod=s);const o=e.getAttribute("data-check-origin");o==="true"&&(n.checkOrigin=!0),o==="false"&&(n.checkOrigin=!1),e.getAttribute("data-log")==="true"&&(n.log=!0),e.iFrameResizer||iFrameResize(n,e)})})</script></body></html>