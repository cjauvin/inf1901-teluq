<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Apprentissage supervisé
  #

L&rsquo;apprentissage supervisé fonctionne à partir de données pour lesquelles la
&ldquo;bonne réponse&rdquo; (i.e. celle qu&rsquo;on aimerait que l&rsquo;algorithme fournisse
systématiquement, une fois entraîné) est fournie, en tant que donnée
d’entraînement. L&rsquo;apprentissage supervisé correspond à la notion intuitive qu&rsquo;on
a de l&rsquo;enseignement et de l&rsquo;apprentissage : un enseignant qui pose une question
à un étudiant  est en mesure de le corriger en lui indiquant si sa réponse est
correcte ou non (car l&rsquo;enseignant connaît, à priori, la &ldquo;bonne réponse&rdquo; à sa
propre question)."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Apprentissage supervisé"><meta property="og:description" content="Apprentissage supervisé # L’apprentissage supervisé fonctionne à partir de données pour lesquelles la “bonne réponse” (i.e. celle qu’on aimerait que l’algorithme fournisse systématiquement, une fois entraîné) est fournie, en tant que donnée d’entraînement. L’apprentissage supervisé correspond à la notion intuitive qu’on a de l’enseignement et de l’apprentissage : un enseignant qui pose une question à un étudiant est en mesure de le corriger en lui indiquant si sa réponse est correcte ou non (car l’enseignant connaît, à priori, la “bonne réponse” à sa propre question)."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Apprentissage supervisé | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.c2a3a3930cc3c92484d4c7886a609454c1ccc7fbe839b6904dde85b081e514b4.css integrity="sha256-wqOjkwzDySSE1MeIamCUVMHMx/voObaQTd6FsIHlFLQ=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><img src=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png alt=Logo class=book-icon><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Approche pédagogique du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/feuille-de-route/>Feuille de route</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/ class=flex-auto>Module 1 - Intelligence artificielle</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle checked>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/ class=flex-auto>Module 2 - Apprentissage automatique</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/>Un scénario réaliste</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/diff%C3%A9rence-avec-x/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/mod%C3%A8les/>Qu'est-ce qu'un modèle?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/>Les paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/ class=active>Apprentissage supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/ class=flex-auto>Module 3 - Réseaux de neurones et apprentissage profond</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/01-r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/ class=flex-auto>Module 4 - IA générative et grands modèles de langage</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class=flex-auto>Module 5 - Autour de l'IA</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/>Attitudes à l'égard de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/menu.svg class=book-icon alt=Menu></label><h3>Apprentissage supervisé</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#classification>Classification</a><ul><li><a href=#la-régression-logistique>La régression logistique</a></li><li><a href=#classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)</a></li><li><a href=#classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)</a><ul><li><a href=#représenter-un-courriel-comme-un-vecteur>Représenter un courriel comme un vecteur</a></li><li><a href=#le-modèle-probabiliste--multinomial>Le modèle probabiliste : multinomial</a></li><li><a href=#rappel--hypothèse-de-naïveté>Rappel : hypothèse de naïveté</a></li><li><a href=#décision-du-classificateur>Décision du classificateur</a></li></ul></li><li><a href=#autres-algorithmes-de-classification>Autres algorithmes de classification</a></li></ul></li><li><a href=#régression>Régression</a><ul><li><a href=#régression-linéaire>Régression linéaire</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=apprentissage-supervisé>Apprentissage supervisé
<a class=anchor href=#apprentissage-supervis%c3%a9>#</a></h1><p>L&rsquo;apprentissage supervisé fonctionne à partir de données pour lesquelles la
&ldquo;bonne réponse&rdquo; (i.e. celle qu&rsquo;on aimerait que l&rsquo;algorithme fournisse
systématiquement, une fois entraîné) est fournie, en tant que donnée
d’entraînement. L&rsquo;apprentissage supervisé correspond à la notion intuitive qu&rsquo;on
a de l&rsquo;enseignement et de l&rsquo;apprentissage : un enseignant qui pose une question
à un étudiant est en mesure de le corriger en lui indiquant si sa réponse est
correcte ou non (car l&rsquo;enseignant connaît, à priori, la &ldquo;bonne réponse&rdquo; à sa
propre question).</p><h2 id=classification>Classification
<a class=anchor href=#classification>#</a></h2><p>La famille d&rsquo;algorithmes d&rsquo;apprentissage supervisé la plus facile à comprendre
est celle des modèles de classification. Un algorithme de classification est une
fonction mathématique qui associe des &ldquo;objets&rdquo; (donc des points dans un
<a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/#niveau-de-lapprentissage-automatique-et-des-mathématiques>espace vectoriel</a>) vers une série prédéfinie d&rsquo;étiquettes, qu&rsquo;on appelle souvent des &ldquo;classes&rdquo;.</p><h3 id=la-régression-logistique>La régression logistique
<a class=anchor href=#la-r%c3%a9gression-logistique>#</a></h3><p>Considérons tout d&rsquo;abord un petit exemple interactif où vous jouerez vous-même
le rôle d&rsquo;un modèle de classification particulier : la <strong>régression
logistique</strong>. Les données d&rsquo;entraînement ont deux classes possibles : <code>bleue</code> ou
<code>rouge</code>, ainsi que deux valeurs (nombres, ou <em>paramètres</em>) pour les décrire :
$x$ et $y$ (puisqu&rsquo;il s&rsquo;agit d&rsquo;un graphe en deux dimensions). La tâche du modèle
est de séparer (c-à-d classifier) les deux groupes. La ligne pointillée constitue la
&ldquo;fonction de décision&rdquo; du modèle : les deux classes se situent de part et
d&rsquo;autre de la ligne. Comme il s&rsquo;agit d&rsquo;une fonction en deux dimensions, on peut
la représenter par la formule simple :</p>$$f(x) \le mx + b$$<p>où $m$ représente la pente et $b$ l&rsquo;ordonnée à l&rsquo;origine. Remarquez un détail
important : il s&rsquo;agit d&rsquo;une fonction d&rsquo;inégalité (inéquation), et non d&rsquo;égalité,
ce qui veut dire qu&rsquo;on peut l&rsquo;interpréter en tant que <em>fonction binaire</em> (deux
valeurs possibles) : <code>rouge</code> si $f(x) \le mx + b$ et <code>bleue</code> si $f(x) \gt mx +
b$ (ou vice versa, arbitrairement). Quand vous déplacez cette ligne de décision
vous-même (en utilisant la souris), vous modifiez les paramètres $m$ et $b$
dynamiquement. Ces paramètres constituent le <strong>modèle</strong>. La situation idéale est
quand cette ligne de décision sépare parfaitement les points rouges des points
bleus, ce qui correspond à une valeur de 0% pour la fonction d&rsquo;erreur (elle-même
représentée par la barre à droite, et distincte de la fonction de décision). Ce
n&rsquo;est pas toujours possible ! Notez qu&rsquo;il est possible d&rsquo;ajouter ou d&rsquo;enlever
des points, et de les déplacer, en utilisant la souris.</p><div style=text-align:center;margin-bottom:10px><label for=pointSlider>Nombre de points : </label><input type=range id=pointSlider min=2 max=50 value=12 style=width:200px>
<span id=pointCount>10</span></div><canvas id=canvas></canvas><div id=info style=text-align:center;margin-top:20px>f(x) <=> mx + b</div><p>Remarquez un détail important : quoiqu&rsquo;on fasse, l&rsquo;erreur ne peut jamais
dépasser 50%. Quand on y pense, c&rsquo;est logique, car même si on place la ligne de
décision à un endroit extrême, qui fait en sorte que TOUS les points se trouvent
d&rsquo;un côté, il reste que 50% de ceux-ci sont tout de même correctement
classifiés. Et si on place la ligne dans une configuration plus pathologique,
qui ferait en sorte par exemple que 75% des points seraient incorrectement
classifiés, la chose logique à faire (ce que l&rsquo;applet interactive fait en fait)
est d&rsquo;inverser le schéma de classification (les points <code>bleus</code> deviennent
<code>rouges</code>, et vice versa), ce qui fait en sorte que l&rsquo;erreur est réduite à 25%.</p><p>La tâche de l&rsquo;algorithme de régression logistique est de trouver les &ldquo;meilleures&rdquo;
valeurs pour les paramètres pour la fonction de décision (donc $m$ et $b$),
celles qui font en sorte que la valeur de la fonction d&rsquo;erreur est la plus
petite possible (zéro idéalement).</p><blockquote class="book-hint info"><p>Matière à réflexion : pourquoi ce n&rsquo;est pas toujours possible de séparer
parfaitement les points? Dans quelles conditions est-ce le cas? Qu&rsquo;est-ce qui
permettrait de faire en sorte que ça devienne possible?</p></blockquote><details open><summary>Les mathématiques de la régression logistique</summary><div class=markdown-inner><p>Bien que nous en ayons parlé en termes purement géométriques jusqu&rsquo;ici, la
régression logistique est en fait une méthode probabiliste : un point est
considéré <code>bleu</code> si le modèle calcule que la probabilité qu&rsquo;il le soit est $\ge
50\%$ (et évidemment vice versa pour <code>rouge</code>). Une probabilité est une valeur
nécessairement entre 0 et 1. Pour transformer une fonction arbitraire en une
fonction de probabilité, on peut utiliser la fonction sigmoïde (aussi appelée
fonction logistique), qui &ldquo;force&rdquo; une valeur à être dans la plage 0 et 1 :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/Logistic-curve-02.png alt></p><p>Nous allons à partir d&rsquo;ici changer un peu la notation que nous avons utilisée
jusqu&rsquo;ici, pour la rendre plus générale :</p>$$\mathbf{x} = [x_1, x_2]$$<p></p>$$y \in \{0, 1\}$$<p>Cette notation classique en apprentissage automatique utilise donc $\mathbf{x}$
pour dénoter les points en 2D sous forme vectorielle ($x_1$ et $x_2$
correspondent aux $x$ et $y$ de la représentation 2D classique, et $\mathbf{x}$
est donc un <em>vecteur</em>, dont les 2 valeurs correspondent aux &ldquo;caractéristiques&rdquo;
d&rsquo;un point, sa description numérique). La variable scalaire (donc une valeur
numérique simple, par opposition à un vecteur) $y$ est utilisée pour dénoter la
<em>vraie</em> classe d&rsquo;un point (0 ou 1, correspondant arbitrairement à <code>bleu</code> ou
<code>rouge</code>). Les paramètres seront représentés par le vecteur $\mathbf{w} = [w_1,
w2]$. Il est maintenant possible de réécrire notre fonction de décision à l&rsquo;aide
de cette nouvelle notation vectorielle :</p>$$z = \mathbf{w}^\top \mathbf{x} + b.$$<p>($\mathbf{w}^\top \mathbf{x}$ est le produit vectoriel de $\mathbf{w}$ et
$\mathbf{x}$). Notons tout d&rsquo;abord qu&rsquo;il y maintenant 3 paramètres ($w1$, $w2$
et $b$), alors que dans l&rsquo;exemple ci-haut seulement 2 sont mentionnés : $m$ et
$b$. On introduit aussi une nouvelle variable $z$ : que veut-elle dire? Pour
comprendre cela, on doit faire un peu d&rsquo;algèbre. Il suffit de noter que notre
équation de départ :</p>$$y = mx + b$$<p>est en fait équivalente à :</p>$$x_2 = mx_1 + b$$<p>ce qu&rsquo;on peut réécrire aisément :</p>$$mx_1 - x_2 + b = 0.$$<p>En choisissant ensuite $m = -w_1/w_2$ et $b = -b/w_2$, on peut réécrire :</p>$$\frac{-w_1 x_1}{w_2} - x_2 - \frac{b}{w_2} = 0$$<p>En multipliant les deux membres de l&rsquo;équation par $-w_2$, on arrive à :</p>$$w_1 x_1 + w_2 x_2 + b = 0$$<p>ce qui constitue la forme générale d&rsquo;une équation en 2D. Étant donné que ce qui
nous intéresse se passe de part et d&rsquo;autre de la ligne de décision (car il
s&rsquo;agit comme nous l&rsquo;avons vu d&rsquo;une inéquation), on introduit le score $z$, pour
quantifier la distance à laquelle un point se trouve, de cette ligne de
séparation :</p>$$z = w_1 x_1 + w_2 x_2 + b$$<p>En utilisant la fonction logistique que nous avons introduite ci-haut pour
transformer ce score (une valeur arbitraire) en une probabilité (donc une valeur
contrainte entre 0 et 1), on peut maintenant introduire l&rsquo;équation de la
régression logistique :</p>$$P(y) = \hat{y} = \frac{1}{1 + e^{-z}}$$<p>avec laquelle il est bien important de comprendre que $\hat{y}$ représente une
probabilité (donc que $\hat{y} \in [0, 1]$), tandis que $y$ représente une vraie
classe (donc que $y \in {0, 1}$). La régression logistique transforme donc la
distance entre un point et la ligne de décision, en une mesure de probabilité.
L&rsquo;algorithme de classification utilisera donc la probabilité calculée pour chaque
point de la manière suivante :</p>$$
\text{classification}(x_1, x_2) =
\left\{
\begin{array}{ll}
\mathtt{bleu} \text{ si } \hat{y} \ge 0.5 & \\
\mathtt{rouge} \text{ si } \hat{y} < 0.5 & \\
\end{array}
\right.
$$<p>Notre but est maintenant de trouver les valeurs optimales pour les paramètres
$\mathbf{w}$ (donc deux nombres précis, $w_1$ et $w_2$), celles qui vont faire en
sorte de minimiser l&rsquo;erreur de classification. Nous avons donc besoin de définir
tout d&rsquo;abord cette erreur en tant que fonction précise :</p>$$E(y, \hat{y}) = -[y \log(\hat{y}) + (1 - y)\log(1 - \hat{y})]$$<p>Pour bien comprendre le fonctionnement de cette équation, examinons les différents
cas de figure :</p><ol><li>Un point est en réalité <code>bleu</code> (donc $y = 1$) et la confiance du modèle en ce fait est élevée ($\hat{y} = 0.9$) : $E(y, \hat{y}) = -\log(0.9) \approx 0.1$ (l&rsquo;erreur est basse).</li><li>Un point est en réalité <code>bleu</code> (donc $y = 1$) mais la confiance du modèle en ce fait est basse ($\hat{y} = 0.1$) : $E(y, \hat{y}) = -\log(0.1) \approx 2.3$ (l&rsquo;erreur est élevée).</li><li>Un point est en réalité <code>rouge</code> (donc $y = 0$) et la confiance du modèle en ce fait est élevée ($\hat{y} = 0.1$) : $E(y, \hat{y}) = -\log(0.9) \approx 0.1$ (l&rsquo;erreur est basse).</li><li>Un point est en réalité <code>rouge</code> (donc $y = 0$) mais la confiance du modèle en ce fait est basse ($\hat{y} = 0.9$) : $E(y, \hat{y}) = -\log(0.1) \approx 2.3$ (l&rsquo;erreur est élevée).</li></ol><p>La fonction d&rsquo;erreur $E$ que nous avons s&rsquo;applique à un seul point. Nous avons
besoin de la généraliser à l&rsquo;ensemble des $n$ points que nous avons, en en
faisant simplement la somme. Ceci est une nouvelle fonction nommée $J$, qui
utilise des indices $(i)$ pour dénoter les valeurs associées aux points
particuliers de notre ensemble d’entraînement :</p>$$J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} E(y^{(i)}, \hat{y}^{(i)})$$<p></p>$$J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} \left[ y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)}) \right]$$<p>Vous pouvez remarquer qu&rsquo;on spécifie cette fois les paramètres $\mathbf{w}$ et
$b$ pour la fonction $J$ : la raison est que nous voulons maintenant <em>optimiser</em>
la fonction $J$, c&rsquo;est-à-dire trouver les valeurs de ses paramètres
($\mathbf{w}$ et $b$) qui vont faire en sorte de la minimiser (c-à-d que sa
valeur soit la plus petite possible, quand on considère l&rsquo;ensemble de toutes ses
valeurs possibles, donc indirectement via l&rsquo;ensemble de toutes les valeurs
possibles pour ses paramètres $\mathbf{w}$ et $b$). Cette opération
d&rsquo;optimisation est l&rsquo;essence même de l&rsquo;apprentissage automatique. Apprendre,
c&rsquo;est optimiser une fonction d&rsquo;erreur, de manière à la rendre la plus petite
possible. On fait cela à l&rsquo;aide de la technique de la <strong>descente de gradient</strong>,
qui consiste à déterminer tout d&rsquo;abord la &ldquo;direction&rdquo; (c-à-d le vecteur) dans
laquelle la valeur de la fonction change le plus, à un point donné. Si on
utilise la métaphore d&rsquo;un terrain montagneux pour représenter une fonction
d&rsquo;erreur en 3 dimensions, l&rsquo;altitude d&rsquo;un point à un endroit particulier
représente la valeur de la fonction, tant que les coordonnées géographiques du
point (<code>x</code> et <code>y</code>, ou lat/lon si on utilise un GPS), représentent les
paramètres. Le gradient, dans cette métaphore, représente la direction dans
laquelle le changement d&rsquo;altitude sera le plus abrupt.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/mountain_gradient.jpg alt></p>$$\frac{\partial J}{\partial \mathbf{w}} = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)}) \mathbf{x}^{(i)}$$<p></p>$$\frac{\partial J}{\partial b} = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)})$$<p>Le symbole $\partial$ peut faire un peu peur à priori, mais sa signification
devient claire quand on le traduit en mots : le gradient de la fonction $J$ par
rapport au paramètre $w$ (ou $b$). Et son calcul, dans le cas de la régression
logistique, est très simple : pour chaque point, on considère :</p><ol><li>La différence entre la probabilité produite par le modèle et la vraie étiquette : $\hat{y}^{(i)} - y^{(i)}$</li><li>Le produit de cette différence et du vecteur d&rsquo;entrée : $(\hat{y}^{(i)} - y^{(i)}) \mathbf{x}^{(i)}$ (rappelons que $\mathbf{x} = [x_1, x_2]$ est un vecteur
à deux dimensions, donc ce produit sera également bi-dimensionnel, tout comme l&rsquo;est également $\mathbf{w}$)</li><li>On veut la moyenne de ces produits (donc la somme et une division)</li></ol><p>Nos règles de mise à jour (la mise à jour, qui est un concept généralement plus
associé à la programmation qu&rsquo;aux mathématiques, est représentée ici par le
symbole $\leftarrow$) pour les paramètres sont donc :</p>$$\mathbf{w} \leftarrow \mathbf{w} - \alpha \cdot \frac{\partial J}{\partial \mathbf{w}}, \quad b \leftarrow b - \alpha \cdot \frac{\partial J}{\partial b}$$<p>L&rsquo;algorithme d&rsquo;optimisation (apprentissage) de la régression logistique consiste
donc en l&rsquo;application itérative (répétée) de ces règles de mise à jour des
paramètres, qui feront en sorte de changer graduellement les valeurs de
$\mathbf{w}$ et $\mathbf{b}$, tout en diminuant également progressivement la
valeur de l&rsquo;erreur cumulée, c&rsquo;est-à-dire la valeur de la fonction $J$. $\alpha$
est le <em>taux d&rsquo;apprentissage</em> (une simple valeur numérique), qui fait en sorte
de limiter la taille des &ldquo;pas&rdquo; qu&rsquo;on prend dans la direction du gradient, à
chaque itération. Pour le distinguer des paramètres ($\mathbf{w}$ et
$\mathbf{b}$), on appelle $\alpha$ un <em>hyper-paramètre</em>.</p></div></details><details open><summary>La programmation de la régression logistique</summary><div class=markdown-inner><iframe src=https://cjauvin.github.io/inf1901-teluq/html/notebooks/module2/reglog.html width=100% height=800px></iframe></div></details><blockquote class="book-hint info"><p>Une question qu&rsquo;il peut être intéressant de considérer, une fois qu&rsquo;on a fait
l&rsquo;effort de mieux comprendre le fonctionnement d&rsquo;un algorithme relativement
simple comme la régression logistique (simple mais très représentatif, si vous
le comprenez bien, vous avez déjà une excellente compréhension de l&rsquo;AA au sens
plus général) : en quoi est-ce que ceci constitue de l&rsquo;intelligence,
<em>artificielle</em> ou non? &mldr;</p></blockquote><p>Une fois que les idées de base de ce petit exemple interactif sont bien claires
pour vous, on peut généraliser le concept de la régression logistique pour en
faire un modèle plus puissant et complexe :</p><ul><li>Considérer ..</li></ul><h3 id=classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)
<a class=anchor href=#classification-bay%c3%a9sienne-naive-gaussienne>#</a></h3><p>Examinons maintenant un autre algorithme de classification que nous pourrions
utiliser sur nos données en deux dimensions.</p><p>La régression logistique est un algorithme d&rsquo;apprentissage <strong>discriminatif</strong> :
elle tente de modéliser la probabilité qu&rsquo;un exemple appartienne directement à
une classe (<code>bleue</code> ou <code>rouge</code>) directement à partir des caractéristiques de cet
exemples ($x_1$ et $x_2$). En contraste, la classification naive bayésienne est
un algorithme <strong>génératif</strong>, qui tente tout d&rsquo;abord de modéliser la distribution
statistiques des classes, avant d&rsquo;utiliser ces modèles (un modèle pour la classe
<code>bleue</code> et un pour la classe <code>rouge</code>) pour déterminer si un point particulier a
plus de chance d&rsquo;avoir été <em>généré</em> par un modèle particulier (disons <code>rouge</code>)
plutôt qu&rsquo;un autre.</p><p>Chaque couple <strong>dimension + classe</strong> sera modélisé par une gaussienne à une
dimension (donc 4 modèles en tout : un pour la classe <code>rouge</code> sur la dimension
$x$, un pour la classe <code>bleue</code> aussi sur $x_1$, et la même chose pour la
dimension $x_2$). Une gaussienne (aussi appelée distribution normale) est la
fameuse &ldquo;courbe en cloche&rdquo;, qui détermine comment la &ldquo;masse de probabilité&rdquo; est
répartie autour d&rsquo;une valeur centrale (qu&rsquo;on appelle la moyenne) :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/gaussian.png alt></p><p>La gaussienne est une fonction continue 1D car elle n&rsquo;a qu&rsquo;une seule valeur
dépendante (l&rsquo;axe horizontal). L&rsquo;axe vertical, la valeur de la fonction,
correspond à la masse de la probabilité. Remarquez un aspect important : la
valeur de la fonction à un point précis donné sur l&rsquo;axe horizontal (par exemple
la moyenne) ne correspond PAS à la probabilité de ce point, malgré ce que
l&rsquo;intuition voudrait croire. Étant donné que la masse de probabilité est une
fonction continue, pour obtenir une probabilité donnée il faut calculer
l&rsquo;intégrale de la fonction entre deux points donnés. Étant donné que la totalité
de la masse (l&rsquo;aire sous la courbe) est 1, on peut dire que la probabilité qu&rsquo;un
événement soit plus petit que la moyenne (ou plus grand) est de 50% (c-à-d que
l&rsquo;aire sous la courbe, ou l&rsquo;intégrale, de la partie à droite ou à gauche de la
barre verticale de la moyenne totalise 0.5).</p><p>Mais donc que veut-on dire par la modélisation par une gaussienne?</p><p>La première étape consiste à projeter les points sur l&rsquo;axe $x_1$, ce qui les
rend uni-dimensionnels.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x1_proj.png alt></p><p>Une fois les points projetés, on peut modéliser (c-à-d <em>décrire
mathématiquement</em>) les classes de points à l&rsquo;aide de gaussiennes, dont
l&rsquo;épaisseur correspondra à la densité (ou quantité) de points projetés sur
l&rsquo;axe, pour chaque classe.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x1_gauss.png alt></p><p>On répète la procédure pour les deux classes, sur l&rsquo;axe $x_2$.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x2_proj.png alt></p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x2_gauss.png alt></p><p>À ce stade, nous avons donc quatre modèles :</p>$$p(x_1 \mid \text{rouge}) = \mathcal{N}(x_1; \mu_{1,\text{rouge}}, \sigma_{1,\text{rouge}}^2)$$<p></p>$$p(x_2 \mid \text{rouge}) = \mathcal{N}(x_2; \mu_{2,\text{rouge}}, \sigma_{2,\text{rouge}}^2)$$<p></p>$$p(x_1 \mid \text{bleue}) = \mathcal{N}(x_1; \mu_{1,\text{bleue}}, \sigma_{1,\text{bleue}}^2)$$<p></p>$$p(x_2 \mid \text{bleue}) = \mathcal{N}(x_2; \mu_{2,\text{bleue}}, \sigma_{2,\text{bleue}}^2)$$<p>où $\mathcal{N}$ représente la gaussienne, et $\mu$ et $\sigma$ représentent ses
paramètres (qui déterminent sa forme particulière). L&rsquo;apprentissage d&rsquo;un modèle
de classification naive bayésienne constitue donc le calcul des valeurs
optimales pour ces différents paramètres, que l&rsquo;on peut faire directement dans
ce contexte (en contraste de la méthode itérative que nous avons utilisée pour
l&rsquo;apprentissage des paramètres de la régression logistique) :</p>$$\hat\mu_{1,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}} x_{i1},\quad$$<p></p>$$\hat\mu_{2,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}} x_{i2},$$<p></p>$$\hat\mu_{1,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}} x_{i1},\quad$$<p></p>$$\hat\mu_{2,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}} x_{i2},$$<p></p>$$\hat\sigma^2_{1,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}}(x_{i1}-\hat\mu_{1,\text{rouge}})^2,\quad$$<p></p>$$\hat\sigma^2_{2,\text{rouge}}=\frac{1}{N_{\text{rouge}}}\sum_{i\in I_{\text{rouge}}}(x_{i2}-\hat\mu_{2,\text{rouge}})^2,$$<p></p>$$\hat\sigma^2_{1,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}}(x_{i1}-\hat\mu_{1,\text{bleue}})^2,\quad$$<p></p>$$\hat\sigma^2_{2,\text{bleue}}=\frac{1}{N_{\text{bleue}}}\sum_{i\in I_{\text{bleue}}}(x_{i2}-\hat\mu_{2,\text{bleue}})^2.$$<p>On peut combiner les modèles :</p>$$p(x_1, x_2 \mid \text{rouge}) \;=\; p(x_1 \mid \text{rouge}) \cdot p(x_2 \mid \text{rouge})$$<p></p>$$p(x_1, x_2 \mid \text{bleue}) \;=\; p(x_1 \mid \text{bleue}) \cdot p(x_2 \mid \text{bleue})$$<p>ou encore, pour simplifier :</p>$$P(\mathbf{x} \mid y)$$<p>Notez qu&rsquo;on change ici la notation de $p$ à $P$, pour mettre l&rsquo;emphase sur le
fait que nous passons d&rsquo;une fonction de densité à une fonction de probabilité.
Ce modèle est <em>génératif</em>, car il génère un point $\mathbf{x}$ (donc ses
coordonnées $x_1$ et $x_2$), à partir d&rsquo;une classe donnée $y$ (<code>rouge</code> ou
<code>bleue</code>). On dit aussi que ce que ce modèle est la probabilité de $\mathbf{x}$
<em>conditionnelle</em> à $y$.</p><p>Mais ce qui nous intéresse, dans un contexte de classification, est l&rsquo;équivalent
de ce que nous avons calculé pour le modèle de régression logistique, soit :</p>$$P(y \mid \mathbf{x})$$<p>Il semble donc que notre modèle génératif soit le contraire de ce qu&rsquo;on l&rsquo;on
veut. Est-il possible de &ldquo;l&rsquo;inverser&rdquo;, pour obtenir le modèle que l&rsquo;on souhaite,
soit la probabilité d&rsquo;une classe étant donné un point?</p><p>Il est possible de faire cela à l&rsquo;aide du <a href=https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Bayes>théorème de
Bayes</a> (ce qui
explique donc le nom de l&rsquo;algorithme), qui stipule que :</p>$$P(y \mid \mathbf{x}) \;=\; \frac{P(\mathbf{x} \mid y) \, P(y)}{P(\mathbf{x})}$$<p>Nous connaissons déjà évidemment $P(\mathbf{x} \mid y)$, que nous avons calculé
ci-haut, et $P(y)$ est simple à calculer : il s&rsquo;agit simplement de la
probabilité à priori (sans aucune autre connaissance) que les points soient
<code>rouges</code> ou <code>bleus</code> (ce qui est possiblement 50%, équiprobable, si notre
ensemble d’entraînement est balancé, moitié <code>rouge</code> moitié <code>bleu</code>).
$P(\mathbf{x})$ est moins clair (la probabilité à priori des données?), mais
étant donné que cette valeur ne dépend pas de $y$, on peut simplement l&rsquo;ignorer
pour obtenir un algorithme de classification final :</p>$$
\text{classification}(\mathbf{x}) =
\left\{
\begin{array}{ll}
\mathtt{rouge} \text{ si } P(\mathbf{x} \mid \text{rouge}) P(\text{rouge}) \ge P(\mathbf{x} \mid \text{bleu}) P(\text{bleu}) & \\
\mathtt{bleu} \text{ sinon } & \\
\end{array}
\right.
$$<p>Tout comme la régression logistique que nous avons étudiée, cet algorithme
produit une décision linéaire, pour des raisons mathématiques que nous n&rsquo;allons
pas explorer plus à fond.</p><p>Question intéressante à se poser? Pourquoi la décision est une ligne?</p><h3 id=classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)
<a class=anchor href=#classification-bay%c3%a9sienne-naive-multinomiale>#</a></h3><p>Nous avons vu jusqu’à présent deux exemples de classificateurs supervisés en
deux dimensions : la régression logistique et le naïf bayésien gaussien. Ces
modèles travaillaient directement dans l’espace des variables réelles, où chaque
donnée est représentée par un point dans le plan.</p><p>Nous allons maintenant changer de domaine d’application et considérer un
problème très concret : la détection de courriels indésirables (pourriels, ou
spam en anglais). Ce sera aussi le sujet de votre <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>travail noté 2</a>.</p><h4 id=représenter-un-courriel-comme-un-vecteur>Représenter un courriel comme un vecteur
<a class=anchor href=#repr%c3%a9senter-un-courriel-comme-un-vecteur>#</a></h4><p>Comme nous l’avons expliqué dans le chapitre sur <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/#les-mots-et-leur-sens>les données</a>, un texte peut être
représenté par un vecteur dans l’« espace des mots ». Dans ce modèle vectoriel,
chaque dimension correspond à un mot du vocabulaire, et la valeur dans cette
dimension correspond au nombre de fois que le mot apparaît dans le document.</p><p>Ainsi, un courriel devient un vecteur en très haute dimension :</p>$$\mathbf{x} = (n_{1}, n_{2}, \ldots, n_{V})$$<p>où $n_{i}$ est le nombre d’occurrences du mot $i$ dans le courriel, et $V$ est
la taille du vocabulaire.</p><p>Il est utile de faire l&rsquo;effort de se représenter l&rsquo;analogie entre le
$\mathbf{x}$ de nos exemples 2D précédents, et ce $\mathbf{x}$ qui vit dans un
espace de beaucoup plus grande dimension, et composé de valeurs entières au lieu
de valeurs continues (les comptes pour chaque dimension / mot), mais tout de
même un vecteur de même nature.</p><h4 id=le-modèle-probabiliste--multinomial>Le modèle probabiliste : multinomial
<a class=anchor href=#le-mod%c3%a8le-probabiliste--multinomial>#</a></h4><p>Dans le cas du classificateur naïf bayésien pour les données en deux dimensions,
nous avions supposé que chaque classe (par exemple <code>bleu</code> et <code>rouge</code>) était
associée à une distribution gaussienne. Autrement dit, nous modélisions la
distribution des variables continues $x_1$ et $x_2$ à l’aide d’une loi normale.
Ce modèle est <em>génératif</em> dans le sens où il génère les données d&rsquo;une classe
(vecteurs 2D pour les classes <code>bleu</code> ou <code>rouge</code>, et vecteurs en dimension $|V|$
pour les classes <code>pourriel</code> ou <code>courriel</code>).</p><p>Dans le cas du texte d&rsquo;un courriel, la situation est différente. Les variables
$n_i$ sont des comptes de mots, et il est naturel de les modéliser par une
distribution multinomiale. Si on lance un dé à 6 faces 1000 fois, la
distribution multinomiale permet de calculer la probabilité d&rsquo;obtenir $X_1$ fois
la face, $X_2$ fois la face 2, et ainsi de suite. Il s&rsquo;agit donc d&rsquo;une
distribution qui modélise des événements <em>discrets</em> (des comptes entiers) par
opposition à la distribution normale qui modélise des valeurs <em>continues</em>.</p><p>Si un courriel appartient à la classe <code>pourriel</code>, alors la probabilité
d’observer un vecteur $\mathbf{x}$ de comptes de mots est :</p>$$P(\mathbf{x} \mid \text{pourriel}) = \frac{N!}{n_{1}! \, n_{2}! \, \cdots \, n_{V}!} \, \prod_{i=1}^{V} p_{i}^{\,n_{i}}$$<p>où :</p><ul><li>$N = \sum_{i=1}^{V} n_i$ est le nombre total de mots du courriel,</li><li>$p_i$ est la probabilité à priori qu’un mot de classe <code>pourriel</code> soit le mot $i$ (cette probabilité à priori est probablement plus grande pour le mot &ldquo;prix&rdquo; que pour le mot &ldquo;parent&rdquo;, par exemple).</li></ul><p>De la même façon, on définit un modèle multinomial pour la classe <code>courriel</code>.</p><h4 id=rappel--hypothèse-de-naïveté>Rappel : hypothèse de naïveté
<a class=anchor href=#rappel--hypoth%c3%a8se-de-na%c3%afvet%c3%a9>#</a></h4><p>Comme dans le modèle gaussien naïf bayésien, nous faisons l’hypothèse que les
mots sont générés indépendamment les uns des autres. Cette hypothèse est
évidemment fausse (certains mots apparaissent souvent ensemble), mais elle rend
le modèle beaucoup plus simple et efficace en pratique.</p><h4 id=décision-du-classificateur>Décision du classificateur
<a class=anchor href=#d%c3%a9cision-du-classificateur>#</a></h4><p>Pour classer un courriel, nous utilisons la règle de Bayes :</p>$$P(\text{pourriel} \mid \mathbf{x}) = \frac{P(x \mid \text{pourriel}) \, P(\text{pourriel})}{P(\mathbf{x})}$$$$P(\text{courriel} \mid \mathbf{x}) = \frac{P(\mathbf{x} \mid \text{courriel}) \, P(\text{courriel})}{P(\mathbf{x})}$$<p>ce qui permet, en ignorant $P(\mathbf{x})$ pour la même raison que celle
expliquée ci-haut, d&rsquo;obtenir un algorithme de classification similaire à celui
que nous avons déjà vu :</p>$$
\text{classification}(\mathbf{x}) =
\left\{
\begin{array}{ll}
\mathtt{pourriel} \text{ si } P(\mathbf{x} \mid \text{pourriel}) P(\text{pourriel}) \ge P(\mathbf{x} \mid \text{courriel}) P(\text{courriel}) & \\
\mathtt{courriel} \text{ sinon } & \\
\end{array}
\right.
$$<p>Cela montre que la décision finale est une combinaison linéaire pondérée des
fréquences de mots, ce qui fait le lien avec la régression logistique étudiée
précédemment.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/spam_vector_space.png alt></p><h3 id=autres-algorithmes-de-classification>Autres algorithmes de classification
<a class=anchor href=#autres-algorithmes-de-classification>#</a></h3><ul><li>k-NN</li><li>SVM</li><li>Arbres de décision</li><li>Réseau de neurones</li></ul><h2 id=régression>Régression
<a class=anchor href=#r%c3%a9gression>#</a></h2><p>Une régression est une famille d&rsquo;algorithmes d&rsquo;apprentissage supervisé
(ou plus classiquement, de modélisation statistique) dont le but est
de découvrir une fonction numérique continue, au sens classique
mathématique (dans sa forme la plus simple, une fonction associe une
valeur numérique du domaine X vers l&rsquo;image Y).</p><ul><li>Régression linéaire (ex. à partir du nombre de pièces et l&rsquo;année de construction, on aimerait prédire le prix d&rsquo;une maison)</li><li>Réseau de neurones</li></ul><h3 id=régression-linéaire>Régression linéaire
<a class=anchor href=#r%c3%a9gression-lin%c3%a9aire>#</a></h3><p>Voici un autre exemple interactif pour explorer la régression linéaire. Les
points bleus suivent une droite cachée avec du bruit, et vous pouvez ajuster
votre ligne pour minimiser l&rsquo;erreur quadratique moyenne :</p><div style=text-align:center;margin-bottom:10px><label for=pointSlider2>Nombre de points : </label><input type=range id=pointSlider2 min=2 max=50 value=25 style=width:200px>
<span id=pointCount2>25</span></div><canvas id=canvas2></canvas><div id=info2 style=text-align:center;margin-top:20px>f(x) = mx + b</div><script>const BLUE="#4285F4",RED="#EA4335",canvas=document.getElementById("canvas"),ctx=canvas.getContext("2d"),info=document.getElementById("info"),pointSlider=document.getElementById("pointSlider"),pointCount=document.getElementById("pointCount");let width,height,graphWidth,graphOffsetX;window.addEventListener("load",()=>{const e=canvas.parentElement.getBoundingClientRect().width;width=e,height=Math.round(e*(500/780)),canvas.width=width,canvas.height=height,graphWidth=Math.min(width-80,width*.85),graphOffsetX=35,anchor={x:graphWidth/2+20,y:height/2},generateRandomPoints(12),draw()});let points=[];function generateRandomPoints(e){points=[];const t=20;for(let n=0;n<e;n++){const s=n<Math.floor(e/2)?0:1,o=Math.random()*(graphWidth-2*t)+t,i=Math.random()*(height-2*t)+t;points.push({x:o,y:i,label:s})}}let anchor={x:300,y:200},angle=-Math.PI/4;const anchorRadius=12,innerRadius=11,outerRadius=12;let dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1;function drawGrid(e=25,t=0){ctx.strokeStyle="#eee",ctx.lineWidth=1;for(let n=0;n<=graphWidth;n+=e)ctx.beginPath(),ctx.moveTo(t+n,0),ctx.lineTo(t+n,height),ctx.stroke();for(let n=0;n<=height;n+=e)ctx.beginPath(),ctx.moveTo(t,n),ctx.lineTo(t+graphWidth,n),ctx.stroke()}function draw(){ctx.clearRect(0,0,width,height);const e=(width-graphWidth)/2-graphOffsetX;ctx.fillStyle="white",ctx.fillRect(e,0,graphWidth,height),ctx.strokeStyle="#aaa",ctx.lineWidth=1,ctx.strokeRect(e,0,graphWidth,height),drawGrid(25,e);const u=Math.cos(angle),d=Math.sin(angle),a=1e3,y=anchor.x-u*a,f=anchor.y-d*a,j=anchor.x+u*a,b=anchor.y+d*a;let l=-Math.tan(angle),h=-(anchor.y-l*anchor.x);const v=isFinite(l)?l.toFixed(2):"∞",g=isFinite(h)?h.toFixed(2):"∞";info.textContent=`f(x) <= ${v}x + ${g}`;let i=0,r=[];for(let e of points){const s=e.x-anchor.x,o=e.y-anchor.y,a=u*o-d*s;let t=a>0?1:0;const n=t===e.label;r.push({predicted:t,correct:n}),n||i++}const p=i>points.length/2;p&&(i=points.length-i,r=r.map(e=>({predicted:1-e.predicted,correct:!e.correct})));for(let n=0;n<points.length;n++){const t=points[n],s=r[n].correct,o=t.label===0?RED:BLUE;if(ctx.beginPath(),ctx.arc(t.x+e,t.y,outerRadius,0,Math.PI*2),ctx.fillStyle=o,ctx.fill(),!s){ctx.strokeStyle="grey",ctx.lineWidth=2;const n=outerRadius+2;ctx.beginPath(),ctx.moveTo(t.x+e-n,t.y-n),ctx.lineTo(t.x+e+n,t.y+n),ctx.moveTo(t.x+e+n,t.y-n),ctx.lineTo(t.x+e-n,t.y+n),ctx.stroke()}}const m=points.length>0?i/points.length*100:0,n=e+graphWidth+20,s=50,o=height-100,t=20;ctx.fillStyle="#f0f0f0",ctx.fillRect(n,s,t,o),ctx.strokeStyle="#aaa",ctx.lineWidth=1,ctx.strokeRect(n,s,t,o);const c=m/100*o;ctx.fillStyle="#ff6b6b",ctx.fillRect(n,s+o-c,t,c),ctx.fillStyle=getComputedStyle(document.body).getPropertyValue("--body-font-color")||"#333",ctx.font="12px sans-serif",ctx.textAlign="left",ctx.fillText("100%",n+t+5,s+5),ctx.fillText("0%",n+t+5,s+o+5),ctx.fillText(`${m.toFixed(1)}%`,n+t+5,s+o-c+5),ctx.font="14px sans-serif",ctx.textAlign="center",ctx.fillText("Erreur",n+t/2,s-10),ctx.save(),ctx.beginPath(),ctx.rect(e,0,graphWidth,height),ctx.clip(),ctx.beginPath(),ctx.moveTo(y+e,f),ctx.lineTo(j+e,b),ctx.strokeStyle="black",ctx.lineWidth=2,ctx.setLineDash([5,5]),ctx.stroke(),ctx.setLineDash([]),ctx.restore(),ctx.fillStyle="#000",ctx.beginPath(),ctx.arc(anchor.x+e,anchor.y,anchorRadius,0,Math.PI*2),ctx.fill(),ctx.fillStyle="#fff",ctx.beginPath(),ctx.arc(anchor.x+e,anchor.y,innerRadius,0,Math.PI*2),ctx.fill()}function distance(e,t){return Math.hypot(e.x-t.x,e.y-t.y)}canvas.addEventListener("mousedown",e=>{e.preventDefault();const o=canvas.getBoundingClientRect(),t={x:e.clientX-o.left,y:e.clientY-o.top},s=(width-graphWidth)/2-graphOffsetX;if(mouseDownPos={x:t.x,y:t.y},hasMoved=!1,t.x<s||t.x>s+graphWidth)return;const n={x:t.x-s,y:t.y};if(e.button===0){if(distance(n,anchor)<=anchorRadius){dragging=!0,dragMode="translate";return}const e=Math.cos(angle),t=Math.sin(angle),s=n.x-anchor.x,o=n.y-anchor.y,i=Math.abs(t*s-e*o);if(i<10){dragging=!0,dragMode="rotate";return}}for(let t=0;t<points.length;t++)if(distance(n,points[t])<outerRadius){if(e.button===0){dragging=!0,dragMode="point",draggedPointIndex=t;return}if(e.button===2){points.splice(t,1),draw();return}}const i=Math.max(15,Math.min(graphWidth-15,n.x)),a=Math.max(15,Math.min(height-15,n.y));e.button===0?points.push({x:i,y:a,label:0}):e.button===2&&points.push({x:i,y:a,label:1}),draw()}),canvas.addEventListener("mousemove",e=>{const o=canvas.getBoundingClientRect(),n={x:e.clientX-o.left,y:e.clientY-o.top},s=(width-graphWidth)/2-graphOffsetX,t={x:n.x-s,y:n.y};if(mouseDownPos&&distance(n,mouseDownPos)>3&&(hasMoved=!0),dragging){if(dragMode==="translate")anchor.x=Math.max(15,Math.min(585,t.x)),anchor.y=Math.max(15,Math.min(height-15,t.y));else if(dragMode==="rotate"){const e=t.x-anchor.x,n=t.y-anchor.y;angle=Math.atan2(n,e)}else dragMode==="point"&&draggedPointIndex>=0&&(points[draggedPointIndex].x=Math.max(15,Math.min(585,t.x)),points[draggedPointIndex].y=Math.max(15,Math.min(height-15,t.y)));draw()}else{if(n.x<s||n.x>s+graphWidth){canvas.style.cursor="default";return}if(distance(t,anchor)<=anchorRadius){canvas.style.cursor="grab";return}const e=Math.cos(angle),o=Math.sin(angle),i=t.x-anchor.x,a=t.y-anchor.y,r=Math.abs(o*i-e*a);if(r<10){canvas.style.cursor="grab";return}for(let e of points)if(distance(t,e)<outerRadius){canvas.style.cursor="grab";return}canvas.style.cursor="default"}}),canvas.addEventListener("mouseup",()=>{dragMode==="point"&&draggedPointIndex>=0&&!hasMoved&&(points.splice(draggedPointIndex,1),draw()),dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1}),canvas.addEventListener("mouseleave",()=>{dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1}),canvas.addEventListener("contextmenu",e=>{e.preventDefault()});function getTouchCoordinates(e){const t=canvas.getBoundingClientRect(),n=e.touches[0]||e.changedTouches[0];return{x:n.clientX-t.left,y:n.clientY-t.top}}let touchStartTime=0,touchHoldTimer=null,touchHoldTriggered=!1;canvas.addEventListener("touchstart",e=>{e.preventDefault();const n=getTouchCoordinates(e),s=(width-graphWidth)/2-graphOffsetX;if(touchStartTime=Date.now(),touchHoldTriggered=!1,mouseDownPos={x:n.x,y:n.y},hasMoved=!1,n.x<s||n.x>s+graphWidth)return;const t={x:n.x-s,y:n.y};if(touchHoldTimer=setTimeout(()=>{touchHoldTriggered=!0;for(let e=0;e<points.length;e++)if(distance(t,points[e])<outerRadius){points.splice(e,1),draw();return}const e=Math.max(15,Math.min(graphWidth-15,t.x)),n=Math.max(15,Math.min(height-15,t.y));points.push({x:e,y:n,label:1}),draw()},500),distance(t,anchor)<=anchorRadius){dragging=!0,dragMode="translate";return}const o=Math.cos(angle),i=Math.sin(angle),a=t.x-anchor.x,r=t.y-anchor.y,c=Math.abs(i*a-o*r);if(c<10){dragging=!0,dragMode="rotate";return}for(let e=0;e<points.length;e++)if(distance(t,points[e])<outerRadius){dragging=!0,dragMode="point",draggedPointIndex=e;return}}),canvas.addEventListener("touchmove",e=>{e.preventDefault();const n=getTouchCoordinates(e),s=(width-graphWidth)/2-graphOffsetX,t={x:n.x-s,y:n.y};if(touchHoldTimer&&(clearTimeout(touchHoldTimer),touchHoldTimer=null),mouseDownPos&&distance(n,mouseDownPos)>3&&(hasMoved=!0),dragging&&!touchHoldTriggered){if(dragMode==="translate")anchor.x=Math.max(15,Math.min(585,t.x)),anchor.y=Math.max(15,Math.min(height-15,t.y));else if(dragMode==="rotate"){const e=t.x-anchor.x,n=t.y-anchor.y;angle=Math.atan2(n,e)}else dragMode==="point"&&draggedPointIndex>=0&&(points[draggedPointIndex].x=Math.max(15,Math.min(graphWidth-15,t.x)),points[draggedPointIndex].y=Math.max(15,Math.min(height-15,t.y)));draw()}}),canvas.addEventListener("touchend",e=>{if(e.preventDefault(),touchHoldTimer&&(clearTimeout(touchHoldTimer),touchHoldTimer=null),touchHoldTriggered){dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1;return}if(!hasMoved&&Date.now()-touchStartTime<300){const t=getTouchCoordinates(e),n=(width-graphWidth)/2-graphOffsetX;if(t.x>=n&&t.x<=n+graphWidth){const e={x:t.x-n,y:t.y};for(let t=0;t<points.length;t++)if(distance(e,points[t])<outerRadius){points.splice(t,1),draw(),dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1;return}const s=Math.max(15,Math.min(graphWidth-15,e.x)),o=Math.max(15,Math.min(height-15,e.y));points.push({x:s,y:o,label:0}),draw()}}dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1}),canvas.addEventListener("touchcancel",e=>{e.preventDefault(),touchHoldTimer&&(clearTimeout(touchHoldTimer),touchHoldTimer=null),dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1,touchHoldTriggered=!1}),pointSlider.addEventListener("input",e=>{const t=parseInt(e.target.value);pointCount.textContent=t,generateRandomPoints(t),draw()});const canvas2=document.getElementById("canvas2"),ctx2=canvas2.getContext("2d"),info2=document.getElementById("info2"),pointSlider2=document.getElementById("pointSlider2"),pointCount2=document.getElementById("pointCount2");let width2,height2,graphWidth2,graphOffsetX2,points2=[],anchor2={x:300,y:200},angle2=-Math.PI/4,hiddenSlope,hiddenIntercept,dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1,touchStartTime2=0,touchHoldTimer2=null,touchHoldTriggered2=!1;const anchorRadius2=12,innerRadius2=11,outerRadius2=12;window.addEventListener("load",()=>{const e=canvas2.parentElement.getBoundingClientRect().width;width2=e,height2=Math.round(e*(500/780)),canvas2.width=width2,canvas2.height=height2,graphWidth2=Math.min(width2-80,width2*.85),graphOffsetX2=35,hiddenSlope=(Math.random()-.5)*1.5,hiddenIntercept=height2*.3+Math.random()*height2*.4,anchor2={x:graphWidth2/2+20,y:height2/2},generateRandomPoints2(25),draw2()});function generateRandomPoints2(e){points2=[];const t=20,a=80,n=t,s=graphWidth2-t,o=t+a/2,i=height2-t-a/2,l=(i-o)/(s-n),r=-(i-o)/(s-n);hiddenSlope=r+Math.random()*(l-r);const d=o-hiddenSlope*n,u=i-hiddenSlope*s,c=Math.max(d,u),h=Math.min(i-hiddenSlope*n,o-hiddenSlope*s);hiddenIntercept=c+Math.random()*(h-c);for(let n=0;n<e;n++){const s=Math.random()*(graphWidth2-2*t)+t,o=hiddenSlope*s+hiddenIntercept,i=(Math.random()-.5)*a,r=o+i;points2.push({x:s,y:r,label:1})}}function drawGrid2(e=25,t=0){ctx2.strokeStyle="#eee",ctx2.lineWidth=1;for(let n=0;n<=graphWidth2;n+=e)ctx2.beginPath(),ctx2.moveTo(t+n,0),ctx2.lineTo(t+n,height2),ctx2.stroke();for(let n=0;n<=height2;n+=e)ctx2.beginPath(),ctx2.moveTo(t,n),ctx2.lineTo(t+graphWidth2,n),ctx2.stroke()}function draw2(){ctx2.clearRect(0,0,width2,height2);const e=(width2-graphWidth2)/2-graphOffsetX2;ctx2.fillStyle="white",ctx2.fillRect(e,0,graphWidth2,height2),ctx2.strokeStyle="#aaa",ctx2.lineWidth=1,ctx2.strokeRect(e,0,graphWidth2,height2),drawGrid2(25,e);const h=Math.cos(angle2),u=Math.sin(angle2),i=Math.max(width2,height2),_=anchor2.x-h*i,y=anchor2.y-u*i,m=anchor2.x+h*i,g=anchor2.y+u*i;points2.forEach(t=>{ctx2.fillStyle=BLUE,ctx2.beginPath(),ctx2.arc(t.x+e,t.y,outerRadius2,0,2*Math.PI),ctx2.fill(),ctx2.strokeStyle="#333",ctx2.lineWidth=1,ctx2.stroke()}),ctx2.fillStyle="#000",ctx2.beginPath(),ctx2.arc(anchor2.x+e,anchor2.y,anchorRadius2,0,2*Math.PI),ctx2.fill(),ctx2.fillStyle="#fff",ctx2.beginPath(),ctx2.arc(anchor2.x+e,anchor2.y,innerRadius2,0,2*Math.PI),ctx2.fill(),ctx2.save(),ctx2.rect(e,0,graphWidth2,height2),ctx2.clip(),ctx2.strokeStyle="#000",ctx2.lineWidth=2,ctx2.setLineDash([5,5]),ctx2.beginPath(),ctx2.moveTo(_+e,y),ctx2.lineTo(m+e,g),ctx2.stroke(),ctx2.setLineDash([]),ctx2.restore();let c=0;points2.forEach(e=>{const t=anchor2.y+(e.x-anchor2.x)*Math.tan(angle2),n=(e.y-t)**2;c+=n});const l=points2.length>0?c/points2.length:0,p=1e4,f=Math.min(100,l/p*100),n=e+graphWidth2+20,t=50,o=height2-100,s=20;ctx2.fillStyle="#f0f0f0",ctx2.fillRect(n,t,s,o),ctx2.strokeStyle="#666",ctx2.lineWidth=1,ctx2.strokeRect(n,t,s,o);const r=f/100*o;ctx2.fillStyle="#ff6b6b",ctx2.fillRect(n,t+o-r,s,r),ctx2.fillStyle=getComputedStyle(document.body).getPropertyValue("--body-font-color")||"#333",ctx2.font="12px sans-serif",ctx2.textAlign="left",ctx2.fillText("Max",n+s+5,t+5),ctx2.fillText("0",n+s+5,t+o+5);const v=t+o-r+5,b=t+20,j=Math.max(v,b);ctx2.fillText(`${l.toFixed(1)}`,n+s+5,j),ctx2.font="14px sans-serif",ctx2.textAlign="center",ctx2.fillText("Erreur",n+s/2,t-10);const a=-Math.tan(angle2),d=-(anchor2.y-a*anchor2.x),w=isFinite(a)?a.toFixed(2):"∞",O=isFinite(d)?d.toFixed(2):"∞";info2.textContent=`f(x) = ${w}x + ${O}`}pointSlider2.addEventListener("input",e=>{const t=parseInt(e.target.value);pointCount2.textContent=t,generateRandomPoints2(t),draw2()});function distance2(e,t){return Math.hypot(e.x-t.x,e.y-t.y)}canvas2.addEventListener("mousedown",e=>{e.preventDefault();const o=canvas2.getBoundingClientRect(),n={x:e.clientX-o.left,y:e.clientY-o.top},s=(width2-graphWidth2)/2-graphOffsetX2;if(mouseDownPos2={x:n.x,y:n.y},hasMoved2=!1,n.x<s||n.x>s+graphWidth2)return;const t={x:n.x-s,y:n.y};if(e.button===0){if(distance2(t,anchor2)<=anchorRadius2){dragging2=!0,dragMode2="translate";return}const e=Math.cos(angle2),n=Math.sin(angle2),s=t.x-anchor2.x,o=t.y-anchor2.y,i=Math.abs(n*s-e*o);if(i<10){dragging2=!0,dragMode2="rotate";return}for(let e=0;e<points2.length;e++)if(distance2(t,points2[e])<outerRadius2){dragging2=!0,dragMode2="point",draggedPointIndex2=e;return}const a=Math.max(15,Math.min(graphWidth2-15,t.x)),r=Math.max(15,Math.min(height2-15,t.y));points2.push({x:a,y:r,label:1})}else if(e.button===2){const e=Math.max(15,Math.min(graphWidth2-15,t.x)),n=Math.max(15,Math.min(height2-15,t.y));points2.push({x:e,y:n,label:1})}draw2()}),canvas2.addEventListener("mousemove",e=>{const o=canvas2.getBoundingClientRect(),n={x:e.clientX-o.left,y:e.clientY-o.top},s=(width2-graphWidth2)/2-graphOffsetX2,t={x:n.x-s,y:n.y};if(mouseDownPos2&&distance2(n,mouseDownPos2)>3&&(hasMoved2=!0),dragging2){if(dragMode2==="translate")anchor2.x=Math.max(15,Math.min(graphWidth2-15,t.x)),anchor2.y=Math.max(15,Math.min(height2-15,t.y));else if(dragMode2==="rotate"){const e=t.x-anchor2.x,n=t.y-anchor2.y;angle2=Math.atan2(n,e)}else dragMode2==="point"&&draggedPointIndex2>=0&&(points2[draggedPointIndex2].x=Math.max(15,Math.min(graphWidth2-15,t.x)),points2[draggedPointIndex2].y=Math.max(15,Math.min(height2-15,t.y)));draw2()}else{if(n.x<s||n.x>s+graphWidth2){canvas2.style.cursor="default";return}if(distance2(t,anchor2)<=anchorRadius2){canvas2.style.cursor="grab";return}const e=Math.cos(angle2),o=Math.sin(angle2),i=t.x-anchor2.x,a=t.y-anchor2.y,r=Math.abs(o*i-e*a);if(r<10){canvas2.style.cursor="grab";return}for(let e of points2)if(distance2(t,e)<outerRadius2){canvas2.style.cursor="grab";return}canvas2.style.cursor="default"}}),canvas2.addEventListener("mouseup",e=>{dragMode2==="point"&&draggedPointIndex2>=0&&!hasMoved2&&(points2.splice(draggedPointIndex2,1),draw2()),dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1}),canvas2.addEventListener("contextmenu",e=>{e.preventDefault()});function getTouchCoordinates2(e){const t=canvas2.getBoundingClientRect(),n=e.touches[0]||e.changedTouches[0];return{x:n.clientX-t.left,y:n.clientY-t.top}}canvas2.addEventListener("touchstart",e=>{e.preventDefault();const n=getTouchCoordinates2(e),s=(width2-graphWidth2)/2-graphOffsetX2;if(touchStartTime2=Date.now(),touchHoldTriggered2=!1,mouseDownPos2={x:n.x,y:n.y},hasMoved2=!1,n.x<s||n.x>s+graphWidth2)return;const t={x:n.x-s,y:n.y};if(touchHoldTimer2=setTimeout(()=>{touchHoldTriggered2=!0;for(let e=0;e<points2.length;e++)if(distance2(t,points2[e])<outerRadius2){points2.splice(e,1),draw2();return}const e=Math.max(15,Math.min(graphWidth2-15,t.x)),n=Math.max(15,Math.min(height2-15,t.y));points2.push({x:e,y:n,label:1}),draw2()},500),distance2(t,anchor2)<=anchorRadius2){dragging2=!0,dragMode2="translate";return}const o=Math.cos(angle2),i=Math.sin(angle2),a=t.x-anchor2.x,r=t.y-anchor2.y,c=Math.abs(i*a-o*r);if(c<10){dragging2=!0,dragMode2="rotate";return}for(let e=0;e<points2.length;e++)if(distance2(t,points2[e])<outerRadius2){dragging2=!0,dragMode2="point",draggedPointIndex2=e;return}}),canvas2.addEventListener("touchmove",e=>{e.preventDefault();const n=getTouchCoordinates2(e),s=(width2-graphWidth2)/2-graphOffsetX2,t={x:n.x-s,y:n.y};if(touchHoldTimer2&&(clearTimeout(touchHoldTimer2),touchHoldTimer2=null),mouseDownPos2&&distance2(n,mouseDownPos2)>3&&(hasMoved2=!0),dragging2){if(dragMode2==="translate")anchor2.x=Math.max(15,Math.min(graphWidth2-15,t.x)),anchor2.y=Math.max(15,Math.min(height2-15,t.y));else if(dragMode2==="rotate"){const e=t.x-anchor2.x,n=t.y-anchor2.y;angle2=Math.atan2(n,e)}else dragMode2==="point"&&draggedPointIndex2>=0&&(points2[draggedPointIndex2].x=Math.max(15,Math.min(graphWidth2-15,t.x)),points2[draggedPointIndex2].y=Math.max(15,Math.min(height2-15,t.y)));draw2()}}),canvas2.addEventListener("touchend",e=>{if(e.preventDefault(),touchHoldTimer2&&(clearTimeout(touchHoldTimer2),touchHoldTimer2=null),touchHoldTriggered2){dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1;return}if(!hasMoved2&&Date.now()-touchStartTime2<300){const t=getTouchCoordinates2(e),n=(width2-graphWidth2)/2-graphOffsetX2;if(t.x>=n&&t.x<=n+graphWidth2){const e={x:t.x-n,y:t.y};for(let t=0;t<points2.length;t++)if(distance2(e,points2[t])<outerRadius2){points2.splice(t,1),draw2(),dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1;return}const s=Math.max(15,Math.min(graphWidth2-15,e.x)),o=Math.max(15,Math.min(height2-15,e.y));points2.push({x:s,y:o,label:1}),draw2()}}dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1})</script></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><div class="flex flex-wrap justify-between"><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/ class="flex align-center float-left book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title="Les paradigmes de l'AA">
<span>Les paradigmes de l'AA</span>
</a><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/ class="flex align-center float-right book-icon"><span>Travail noté 2</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Travail noté 2"></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#classification>Classification</a><ul><li><a href=#la-régression-logistique>La régression logistique</a></li><li><a href=#classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)</a></li><li><a href=#classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)</a><ul><li><a href=#représenter-un-courriel-comme-un-vecteur>Représenter un courriel comme un vecteur</a></li><li><a href=#le-modèle-probabiliste--multinomial>Le modèle probabiliste : multinomial</a></li><li><a href=#rappel--hypothèse-de-naïveté>Rappel : hypothèse de naïveté</a></li><li><a href=#décision-du-classificateur>Décision du classificateur</a></li></ul></li><li><a href=#autres-algorithmes-de-classification>Autres algorithmes de classification</a></li></ul></li><li><a href=#régression>Régression</a><ul><li><a href=#régression-linéaire>Régression linéaire</a></li></ul></li></ul></nav></div></aside></main></body></html>