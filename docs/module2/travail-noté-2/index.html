<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Classification naïve bayésienne pour détecter les pourriels (travail noté 2)# La classification naïve bayésienne est un algorithme d’apprentissage supervisé qui fonctionne avec les probabilités. Nous avons vu deux variantes de cet algorithme :
La classification de simples points en 2d avec un modèle gaussien La classification de vecteurs en haute dimension avec un modèle multinomial Un problème classique qui peut être traité avec cet algorithme est la classification de courriels. On peut tenter d’estimer la probabilité qu’un courriel soit en fait un pourriel en prenant en compte les mots particuliers qu’il contient, l’idée étant que certains mots auront tendance à être plus souvent utilisés selon qu’il s’agit d’un pourriel ou d’un courriel.
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Travail noté 2"><meta property="og:description" content="Classification naïve bayésienne pour détecter les pourriels (travail noté 2)# La classification naïve bayésienne est un algorithme d’apprentissage supervisé qui fonctionne avec les probabilités. Nous avons vu deux variantes de cet algorithme :
La classification de simples points en 2d avec un modèle gaussien La classification de vecteurs en haute dimension avec un modèle multinomial Un problème classique qui peut être traité avec cet algorithme est la classification de courriels. On peut tenter d’estimer la probabilité qu’un courriel soit en fait un pourriel en prenant en compte les mots particuliers qu’il contient, l’idée étant que certains mots auront tendance à être plus souvent utilisés selon qu’il s’agit d’un pourriel ou d’un courriel."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta itemprop=name content="Travail noté 2"><meta itemprop=description content="Classification naïve bayésienne pour détecter les pourriels (travail noté 2)# La classification naïve bayésienne est un algorithme d’apprentissage supervisé qui fonctionne avec les probabilités. Nous avons vu deux variantes de cet algorithme :
La classification de simples points en 2d avec un modèle gaussien La classification de vecteurs en haute dimension avec un modèle multinomial Un problème classique qui peut être traité avec cet algorithme est la classification de courriels. On peut tenter d’estimer la probabilité qu’un courriel soit en fait un pourriel en prenant en compte les mots particuliers qu’il contient, l’idée étant que certains mots auront tendance à être plus souvent utilisés selon qu’il s’agit d’un pourriel ou d’un courriel."><meta itemprop=wordCount content="1304"><title>Travail noté 2 | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.9f533add4c447a961b609e13ee02076c6d5baa3e0173d1a8f0c006e584b123e7.css integrity="sha256-n1M63UxEepYbYJ4T7gIHbG1bqj4Bc9Go8MAG5YSxI+c=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/css/applet.css></head><body dir=ltr class="book-kind-page book-type-docs"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><img src=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png alt=Logo><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Approche pédagogique du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/feuille-de-route/>Feuille de route</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/changelog/>Évolution du cours (venez voir de temps en temps!)</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/discord/>Serveur Discord</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/>Module 1 - Intelligence artificielle</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle checked>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/>Module 2 - Apprentissage automatique</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/>Un scénario pour se faire une idée</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/diff%C3%A9rence-avec-x/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/algo-le-plus-simple/>L'algorithme le plus simple</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/similarit%C3%A9/>Le concept de similarité</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/mod%C3%A8les/>Qu'est-ce qu'un modèle?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/>Les paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/>Apprentissage supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/>Apprentissage non supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/ class=active>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/>Module 3 - Réseaux de neurones et apprentissage profond</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/architectures-avanc%C3%A9es/>Architectures avancées</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/aa-adverse/>Apprentissage automatique adverse</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/>Module 4 - IA générative et grands modèles de langage</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/>Module 5 - Autour de l'IA</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/>Attitudes à l'égard de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/icons/menu.svg class=book-icon alt=Menu></label><h3>Travail noté 2</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#consignes>Consignes</a></li><li><a href=#entraînement-du-modèle>Entraînement du modèle</a></li><li><a href=#utilisation-du-modèle-inférence>Utilisation du modèle (inférence)</a></li><li><a href=#questions-dinterprétation>Questions d&rsquo;interprétation</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=classification-naïve-bayésienne-pour-détecter-les-pourriels-travail-noté-2>Classification naïve bayésienne pour détecter les pourriels (travail noté 2)<a class=anchor href=#classification-na%c3%afve-bay%c3%a9sienne-pour-d%c3%a9tecter-les-pourriels-travail-not%c3%a9-2>#</a></h1><p>La classification naïve bayésienne est un algorithme d&rsquo;apprentissage supervisé
qui fonctionne avec les probabilités. Nous avons vu deux variantes de cet
algorithme :</p><ol><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/#classification-bayésienne-naive-gaussienne>La classification de simples points en 2d avec un modèle gaussien</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/#classification-bayésienne-naive-multinomiale>La classification de vecteurs en haute dimension avec un modèle multinomial</a></li></ol><p>Un problème classique qui peut être traité avec cet algorithme est la
classification de courriels. On peut tenter d&rsquo;estimer la probabilité qu&rsquo;un
courriel soit en fait un pourriel en prenant en compte les mots particuliers
qu&rsquo;il contient, l&rsquo;idée étant que certains mots auront tendance à être plus
souvent utilisés selon qu&rsquo;il s&rsquo;agit d&rsquo;un pourriel ou d&rsquo;un courriel.</p><p>Comme nous l&rsquo;avons vu, la classification naive bayésienne est un algorithme
d&rsquo;apprentissage <em>génératif</em>, ce qui veut donc dire qu&rsquo;on considère tout d&rsquo;abord
deux modèles (un pour chaque classe, <code>pourriel</code> ou <code>courriel</code>) qui sont en
charge de <em>générer</em> les données qu&rsquo;on observe (plutôt que de directement les
<em>classifier</em>) :</p>$$P(\text{les mots générés} \mid \text{il s'agit d'un pourriel})$$<p></p>$$P(\text{les mots générés} \mid \text{il s'agit d'un courriel})$$<p>ou encore, de manière plus compacte :</p>$$P(\mathbf{x} \mid \mathtt{pourriel})$$<p></p>$$P(\mathbf{x} \mid \mathtt{courriel})$$<p>Mais étant donné que ce qui nous intéresse, dans ce contexte, est de classifier
les courriels, nous utilisons le <a href=https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Bayes>théorème de
Bayes</a> pour
&ldquo;inverser&rdquo; les modèles, pour ainsi obtenir une règle de classification simple
(qui prédit la classe plutôt que les mots):</p>$$
\text{classification}(\mathbf{x}) =
\left\{
\begin{array}{ll}
\mathtt{pourriel} \text{ si } P(\mathbf{x} \mid \mathtt{pourriel}) P(\mathtt{pourriel}) \ge P(\mathbf{x} \mid \mathtt{courriel}) P(\mathtt{courriel}) & \\
\mathtt{courriel} \text{ sinon } & \\
\end{array}
\right.
$$<h2 id=consignes>Consignes<a class=anchor href=#consignes>#</a></h2><ol><li><p>Suivez les instructions qui suivent pour construire tout d&rsquo;abord le fichier Google Sheets avec toutes les données nécessaires.</p></li><li><p>Une fois qu&rsquo;il est complété et fonctionnel, <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/#fonction-de-partage-anonyme-dun-fichier>partagez votre fichier</a> et copier le lien vers celui-ci dans un document PDF (<strong>Attention : aucun autre format que PDF ne sera accepté</strong>).</p></li><li><p>Répondez aux questions d&rsquo;interprétation de la dernière section dans le même fichier PDF, en fournissant des réponses claires et précises.</p></li></ol><h2 id=entraînement-du-modèle>Entraînement du modèle<a class=anchor href=#entra%c3%aenement-du-mod%c3%a8le>#</a></h2><p>Voyons comment il est possible de calculer ces probabilités en entraînant un
modèle de classification sur une série de courriels particuliers.</p><p>Étant donné que nous allons utiliser le tableur en ligne <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a>, assurez-vous tout d&rsquo;abord qu&rsquo;il est
correctement configuré.</p><p>Copiez tout d&rsquo;abord ces 10 mini-courriels dans la colonne A d&rsquo;une nouvelle
&ldquo;feuille&rdquo; Google Sheets, un courriel par rangée (assurez-vous d&rsquo;utiliser
correctement la <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/#fonction-copier-coller>fonction &ldquo;copier-coller&rdquo;</a>, si vous le faites) :</p><pre tabindex=0><code>voici le colis est arrivé
bonjour voici le lien
offre spéciale colis gratuit
merci pour votre colis
colis livré demain matin
voici votre carte gratuite
réunion demain à midi
voici le code pour carte
livraison spéciale pour vous
merci encore pour votre carte</code></pre><p>Pour avoir un aperçu de la tâche d’étiquetage des données (qui dans un scénario
réel peut s&rsquo;avérer très coûteuse et laborieuse), vous êtes invités à tenter tout
d&rsquo;abord de catégoriser vous-mêmes les courriels dans la colonne <code>B</code>, en
utilisant la valeur <code>oui</code> si vous considérez qu&rsquo;il s&rsquo;agit d&rsquo;un pourriel, ou
<code>non</code> (ce n&rsquo;est pas un pourriel) sinon.</p><p>Si vous n&rsquo;avez pas envie de vous soumettre à cet exercice à ce stade,
vous pouvez toujours copier ces valeurs (dans la colonne <code>B</code>) :</p><pre tabindex=0><code>non
non
oui
non
non
oui
non
non
oui
non</code></pre><p>À ce stade, votre feuille devrait ressembler à ceci :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/tn2/sheets_cols_a_et_b.png alt></p><p>Calculons tout d&rsquo;abord dans la colonne <code>C</code> la probabilité à priori qu&rsquo;un
courriel quelconque soit un pourriel ou non (sans prendre en
considérations les mots donc, pour le moment) :</p><pre tabindex=0><code>=MAP(UNIQUE(B1:B10), LAMBDA(x, COUNTIF(B1:B10, x) / COUNTA(B1:B10)))</code></pre><blockquote class="book-hint warning"><p>Si vous obtenez une erreur avec la formule à ce stade, il est très possible que
les paramètres linguistiques de votre Google Sheets ne soient pas <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/#parametres-linguistiques>correctement
configurés</a>.</p></blockquote><p>Ces probabilités à priori nous serviront plus loin. Définissez ensuite
la colonne <code>D</code> avec cette formule :</p><pre tabindex=0><code>=UNIQUE(TRANSPOSE(SPLIT(TEXTJOIN(&#34; &#34;, TRUE, A:A), &#34; &#34;)))</code></pre><p>La colonne <code>D</code> devrait maintenant contenir le vocabulaire des courriels :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/tn2/sheets_col_d_voc.png alt></p><p>La colonne <code>E</code> devrait ensuite correspondre au nombre de fois où les
mots de la colonne <code>D</code> apparaissent dans les courriels valides (qui donc
<code>non</code>, ne sont pas des pourriels) :</p><pre tabindex=0><code>=SUMPRODUCT((B$1:B$10=`non`) * ISNUMBER(SEARCH(D1, A$1:A$10)))</code></pre><p>et de manière similaire pour la colonne <code>F</code> et la fréquence des mots qui
apparaissent dans les courriels qui <code>oui</code>, sont des pourriels :</p><pre tabindex=0><code>=SUMPRODUCT((B$1:B$10=`oui`) * ISNUMBER(SEARCH(D1, A$1:A$10)))</code></pre><blockquote class="book-hint warning"><p>Notez que les colonnes <code>E</code> et <code>F</code> doivent avoir le même nombre d&rsquo;éléments
que la colonne <code>D</code> (il faut donc utiliser la fonction de remplissage
automatique, pour laquelle le plus simple est de soit glisser (drag)
la première cellule vers le bas, une fois qu&rsquo;elle a été calculée, ou
encore de double-cliquer sur le petit &ldquo;+&rdquo; noir qui apparaît en bas à
droite de la première cellule).</p></blockquote><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/tn2/sheets_col_e_drag.png alt></p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/tn2/sheets_cols_e_et_f.png alt></p><p>À partir de ces fréquences de mots pour chaque classe (<code>oui</code> ou
<code>non</code>), on peut maintenant calculer la probabilité conditionnelle de
chaque mot du vocabulaire, étant donné le fait qu&rsquo;un courriel soit
<code>oui</code> ou <code>non</code> un pourriel. Donc la colonne <code>G</code> correspond à la
probabilité des mots étant donné que <code>non</code> il ne s&rsquo;agit pas d&rsquo;un
pourriel :</p><pre tabindex=0><code>=(E1 + 1) / (SUM(E:E) + COUNTA(D:D))</code></pre><p>et de manière similaire la colonne <code>H</code> est la probabilité des mots quand
on sait que <code>oui</code> il s&rsquo;agit d&rsquo;un pourriel :</p><pre tabindex=0><code>=(F1 + 1) / (SUM(F:F) + COUNTA(D:D))</code></pre><p>Encore une fois les colonnes <code>G</code> et <code>H</code> doivent avoir la même taille que
celle du vocabulaire (colonne <code>D</code>), il faut donc s&rsquo;assurer d&rsquo;utiliser le
mécanisme du remplissage automatique décrit précédemment.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/tn2/sheets_cols_g_et_h.png alt></p><p>Notre modèle est maintenant entièrement entraîné, et il est donc prêt
pour son utilisation!</p><hr><h2 id=utilisation-du-modèle-inférence>Utilisation du modèle (inférence)<a class=anchor href=#utilisation-du-mod%c3%a8le-inf%c3%a9rence>#</a></h2><p>Nous allons maintenant utiliser le modèle pour déterminer si un
nouveau courriel (qui n&rsquo;a pas servi à l&rsquo;entraînement) est un pourriel
ou non. Dans la colonne <code>I</code> entrez un courriel à tester :</p><pre tabindex=0><code>voici votre carte spéciale</code></pre><p>Faites l&rsquo;extraction des mots du courriel dans la colonne <code>J</code> :</p><pre tabindex=0><code>=TRANSPOSE(SPLIT(I1, &#34; &#34;))</code></pre><p>Nous avons maintenant besoin, dans la colonne <code>K</code>, de la probabilité des
mots de ce courriel de test dans l&rsquo;hypothèse où <code>non</code>, ça ne serait
pas un pourriel :</p><pre tabindex=0><code>=IFERROR(XLOOKUP(J1, D:D, G:G), 1E-5)</code></pre><p>et de manière similaire pour la colonne <code>L</code>, avec la probabilité des
mots du courriel dans l&rsquo;hypothèse où <code>oui</code> il s&rsquo;agit d&rsquo;un pourriel :</p><pre tabindex=0><code>=IFERROR(XLOOKUP(J1, D:D, H:H), 1E-5)</code></pre><p>Les colonnes <code>K</code> et <code>L</code> doivent avoir la même taille que la colonne <code>J</code>,
donc assurez-vous d&rsquo;utiliser le remplissage automatique. Calculons
dans la colonne <code>M</code> la probabilité que <code>non</code> le courriel n&rsquo;est pas un
pourriel :</p><pre tabindex=0><code>=PRODUCT(K:K) * C1</code></pre><p>Et dans la colonne <code>N</code> la probabilité que <code>oui</code> le courriel est un
pourriel :</p><pre tabindex=0><code>=PRODUCT(L:L) * C2</code></pre><p>Notre classification finale sera dans la colonne <code>O</code> :</p><pre tabindex=0><code>=IF(M1 &gt; N1; &#34;non&#34;; &#34;oui&#34;)</code></pre><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/tn2/sheets_toutes_les_cols.png alt></p><h2 id=questions-dinterprétation>Questions d&rsquo;interprétation<a class=anchor href=#questions-dinterpr%c3%a9tation>#</a></h2><ol><li><p>Que se passe-t-il si vous changez le mot &ldquo;spéciale&rdquo; par le mot
&ldquo;livrée&rdquo; dans le courriel de test de la cellule <code>I1</code>?</p></li><li><p>Après ce changement, expliquez les probabilités qu&rsquo;on retrouve aux cellules
<code>K4</code> et <code>L4</code> associées au nouveau mot &ldquo;livrée&rdquo;. D&rsquo;où proviennent ces nouvelles
valeurs, et pourquoi a-t-on besoin d&rsquo;avoir recours à celles-ci dans le cadre du calcul?</p></li><li><p>Est-ce que ce modèle est <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/#apprentissage-paramétrique-versus-non-paramétrique>paramétrique</a> ou non? Expliquez pourquoi.</p></li><li><p>S&rsquo;il s&rsquo;agit d&rsquo;un modèle paramétrique, quels sont les paramètres du
modèle (quelles colonnes)?</p></li><li><p>Quelles colonnes constituent la partie <em>générative</em> du modèle? Expliquez pourquoi.</p></li><li><p>Quelles colonnes constituent la partie <em>discriminative</em> du modèle? Expliquez pourquoi.</p></li><li><p>Quelle est la signification des nombres dans les cellules <code>G11</code> et
<code>H11</code>, comment peut-on les interpréter?</p></li><li><p>Quelles sont les probabilités non-conditionnelles (à priori)? À quoi servent-elles?</p></li><li><p>Est-ce qu&rsquo;il serait possible d&rsquo;utiliser seulement ces probabilités
non-conditionnelles pour faire un modèle de classification? Quelles
conséquences ça entraînerait?</p></li><li><p>De quelle manière peut-t-on dire que ce modèle généralise?</p></li><li><p>Est-ce que l&rsquo;ordre des mots joue un rôle dans les décisions de ce
modèle? Expliquez pourquoi c&rsquo;est ainsi.</p></li><li><p>Si l&rsquo;ordre des mots ne joue pas de rôle, comment pourrait-on
modifier le modèle de manière à ce qu&rsquo;il en joue un?</p></li><li><p>Est-ce que certains mots aident particulièrement le modèle? Si oui
pourquoi?</p></li><li><p>Est-ce que certains mots sont moins utiles? Si oui pourquoi?</p></li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/ class="flex align-center book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title="Apprentissage non supervisé">
<span>Apprentissage non supervisé</span>
</a></span><span><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/ class="flex align-center book-icon"><span>Module 3 - Réseaux de neurones et apprentissage profond</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Module 3 - Réseaux de neurones et apprentissage profond"></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#consignes>Consignes</a></li><li><a href=#entraînement-du-modèle>Entraînement du modèle</a></li><li><a href=#utilisation-du-modèle-inférence>Utilisation du modèle (inférence)</a></li><li><a href=#questions-dinterprétation>Questions d&rsquo;interprétation</a></li></ul></nav></div></aside></main></body></html>