<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="L’apprentissage non supervisé# Contrairement à l’apprentissage supervisé, où les données d’entraînement incluent explicitement les “bonnes réponses” (sous forme d’étiquettes ou de valeurs cibles), l’apprentissage non supervisé opère sur des données brutes, sans aucune guidance externe. L’algorithme doit découvrir par lui-même des structures cachées, des patterns ou des regroupements dans les données. C’est un peu comme explorer un territoire inconnu sans carte : on observe les similarités, les regroupements naturels, ou les anomalies, pour en déduire une organisation. Cela rend l’approche plus exploratoire et moins directive, idéale pour des tâches comme la segmentation de clients en marketing, la compression de données, ou la détection d’anomalies en cybersécurité.
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Apprentissage non supervisé"><meta property="og:description" content="L’apprentissage non supervisé# Contrairement à l’apprentissage supervisé, où les données d’entraînement incluent explicitement les “bonnes réponses” (sous forme d’étiquettes ou de valeurs cibles), l’apprentissage non supervisé opère sur des données brutes, sans aucune guidance externe. L’algorithme doit découvrir par lui-même des structures cachées, des patterns ou des regroupements dans les données. C’est un peu comme explorer un territoire inconnu sans carte : on observe les similarités, les regroupements naturels, ou les anomalies, pour en déduire une organisation. Cela rend l’approche plus exploratoire et moins directive, idéale pour des tâches comme la segmentation de clients en marketing, la compression de données, ou la détection d’anomalies en cybersécurité."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta itemprop=name content="Apprentissage non supervisé"><meta itemprop=description content="L’apprentissage non supervisé# Contrairement à l’apprentissage supervisé, où les données d’entraînement incluent explicitement les “bonnes réponses” (sous forme d’étiquettes ou de valeurs cibles), l’apprentissage non supervisé opère sur des données brutes, sans aucune guidance externe. L’algorithme doit découvrir par lui-même des structures cachées, des patterns ou des regroupements dans les données. C’est un peu comme explorer un territoire inconnu sans carte : on observe les similarités, les regroupements naturels, ou les anomalies, pour en déduire une organisation. Cela rend l’approche plus exploratoire et moins directive, idéale pour des tâches comme la segmentation de clients en marketing, la compression de données, ou la détection d’anomalies en cybersécurité."><meta itemprop=wordCount content="774"><title>Apprentissage non supervisé | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.165c71395eadf4cc8cb595801cc1691b0169871bbe93de1afb5ecb0f5b7c33ae.css integrity="sha256-FlxxOV6t9MyMtZWAHMFpGwFphxu+k94a+17LD1t8M64=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/css/applet.css></head><body dir=ltr class="book-kind-page book-type-docs"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><img src=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png alt=Logo><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Approche pédagogique du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/feuille-de-route/>Feuille de route</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/changelog/>Évolution du cours (venez voir de temps en temps!)</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/discord/>Serveur Discord</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/>Module 1 - Intelligence artificielle</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle checked>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/>Module 2 - Apprentissage automatique</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/>Un scénario réaliste pour se faire tout d'abord une idée</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/diff%C3%A9rence-avec-x/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/algo-le-plus-simple/>L'algorithme le plus simple</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/similarit%C3%A9/>Le concept de similarité</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/mod%C3%A8les/>Qu'est-ce qu'un modèle?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/paradigmes/>Les paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/>Apprentissage supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-non-supervis%C3%A9/ class=active>Apprentissage non supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/>Module 3 - Réseaux de neurones et apprentissage profond</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/architectures-avanc%C3%A9es/>Architectures avancées</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/aa-adverse/>Apprentissage automatique adverse</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/>Module 4 - IA générative et grands modèles de langage</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/>Module 5 - Autour de l'IA</a>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/>Attitudes à l'égard de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/icons/menu.svg class=book-icon alt=Menu></label><h3>Apprentissage non supervisé</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#clustering-avec-k-means>Clustering avec $k$-means</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=lapprentissage-non-supervisé>L&rsquo;apprentissage non supervisé<a class=anchor href=#lapprentissage-non-supervis%c3%a9>#</a></h1><p>Contrairement à l&rsquo;apprentissage supervisé, où les données d&rsquo;entraînement
incluent explicitement les &ldquo;bonnes réponses&rdquo; (sous forme d&rsquo;étiquettes ou de
valeurs cibles), l&rsquo;apprentissage non supervisé opère sur des données brutes,
sans aucune guidance externe. L&rsquo;algorithme doit découvrir par lui-même des
structures cachées, des patterns ou des regroupements dans les données. C&rsquo;est un
peu comme explorer un territoire inconnu sans carte : on observe les
similarités, les regroupements naturels, ou les anomalies, pour en déduire une
organisation. Cela rend l&rsquo;approche plus exploratoire et moins directive, idéale
pour des tâches comme la segmentation de clients en marketing, la compression de
données, ou la détection d&rsquo;anomalies en cybersécurité.</p><p>Parmi les tâches courantes en non supervisé, on trouve le clustering (regrouper
des éléments similaires), la réduction de dimensionnalité (simplifier des
données complexes sans perdre trop d&rsquo;information), ou l&rsquo;apprentissage de
représentations (comme trouver des features latentes dans des images). Nous
allons nous concentrer sur un algorithme classique de clustering : $k$-means, qui
illustre bien les principes de base. Mais avant d&rsquo;entrer dans les détails,
notons qu&rsquo;il existe de nombreux autres algorithmes dans cette famille, comme
DBSCAN (qui gère mieux les formes irrégulières et le bruit), le clustering
hiérarchique (qui construit une arborescence de regroupements), la PCA (Analyse
en Composantes Principales, pour réduire la dimensionnalité en projetant les
données sur des axes optimaux), ou encore les autoencodeurs (des réseaux de
neurones qui apprennent à compresser et reconstruire les données, révélant ainsi
des structures sous-jacentes).</p><h2 id=clustering-avec-k-means>Clustering avec $k$-means<a class=anchor href=#clustering-avec-k-means>#</a></h2><p>$k$-means est l&rsquo;un des algorithmes les plus simples et les plus utilisés pour le
clustering. L&rsquo;idée de base est de partitionner un ensemble de points en $k$
groupes (ou clusters), où $k$ est un nombre que l&rsquo;on choisit à l&rsquo;avance. Chaque
cluster est représenté par un &ldquo;centroïde&rdquo; (le point moyen du groupe), et
l&rsquo;algorithme vise à minimiser la distance totale entre les points et leur
centroïde assigné. C&rsquo;est comme organiser une fête où vous voulez regrouper les
invités en $k$ tables, en plaçant chaque table au centre de son groupe pour que
tout le monde soit le plus proche possible de sa table.</p><p>Voici comment ça fonctionne intuitivement :</p><ol><li>Choisissez aléatoirement $k$ points initiaux comme centroïdes (ils peuvent être des points réels des données ou générés aléatoirement).</li><li>Assignez chaque point de données au centroïde le plus proche (généralement en utilisant la distance euclidienne, comme la distance en ligne droite dans un plan).</li><li>Recalculez la position de chaque centroïde comme la moyenne des points assignés à son cluster.</li><li>Répétez les étapes 2 et 3 jusqu&rsquo;à ce que les assignments ne changent plus (ou que le changement soit négligeable).</li></ol><p>À la fin, vous obtenez $k$ clusters bien définis, où les points à l&rsquo;intérieur d&rsquo;un même cluster sont plus similaires entre eux qu&rsquo;avec ceux des autres clusters. C&rsquo;est particulièrement utile pour des données en 2D ou 3D, comme des coordonnées géographiques ou des caractéristiques de produits, mais ça s&rsquo;étend à plus de dimensions.</p><blockquote class="book-hint info"><p>Matière à réflexion : Comment choisir la valeur optimale de $k$? Que se
passe-t-il si les clusters ne sont pas sphériques ou si les données ont du bruit
? (Indice : des méthodes comme la &ldquo;méthode du coude&rdquo; aident pour $k$, et d&rsquo;autres
algorithmes comme DBSCAN gèrent mieux les irrégularités.)</p></blockquote><details><summary>Les mathématiques de $k$-means (optionnel)</summary><div class=markdown-inner><p>Mathématiquement, $k$-means vise à minimiser une fonction d&rsquo;erreur appelée l&rsquo;inertie (ou somme des carrés intra-cluster) :</p>$$ J = \sum_{i=1}^{n} \min_{j=1}^{k} \| \mathbf{x}_i - \boldsymbol{\mu}_j \|^2 $$<p>où :</p><ul><li>$\mathbf{x}_i$ est le i-ème point de données,</li><li>$\boldsymbol{\mu}_j$ est le centroïde du j-ème cluster,</li><li>$| \cdot |^2$ est la distance euclidienne au carré,</li><li>La minimisation assigne chaque $\mathbf{x}_i$ au $\boldsymbol{\mu}_j$ le plus proche.</li></ul><p>L&rsquo;algorithme est itératif et utilise une optimisation de type EM (Expectation-Maximization) :</p><ul><li>Étape d&rsquo;assignation (Expectation) : Pour chaque point $\mathbf{x}_i$, trouvez l&rsquo;indice $c_i = \arg\min_j | \mathbf{x}_i - \boldsymbol{\mu}_j |^2$.</li><li>Étape de mise à jour (Maximization) : Pour chaque cluster $j$, recalculez $\boldsymbol{\mu}j = \frac{1}{n_j} \sum{i: c_i = j} \mathbf{x}_i$, où $n_j$ est le nombre de points dans le cluster $j$.</li></ul><p>Ces étapes sont répétées jusqu&rsquo;à convergence (par exemple, quand les centroïdes
bougent de moins qu&rsquo;un seuil $\epsilon$). Notez que $k$-means peut converger vers
un minimum local (pas toujours global), donc on lance souvent plusieurs
initialisations aléatoires et on choisit la meilleure (celle avec la plus petite
$J$).</p></div></details><p>Voici une applet interactive pour illustrer le fonctionnement de $k$-means. Notez
que bien qu&rsquo;on pourrait penser, à priori, qu&rsquo;il s&rsquo;agit d&rsquo;une méthode de
classification, ce n&rsquo;est pas le cas, car les points à la base n&rsquo;ont pas
d&rsquo;étiquettes ! La seule chose que vous décidez (contrôlez) c&rsquo;est le nombre
d&rsquo;étiquettes, et l&rsquo;algorithme s&rsquo;occupe du reste. Il existe même des algorithmes
qui peuvent faire ce choix pour vous automatiquement.</p><div class=applet-wrapper style=width:100%><iframe src=https://cjauvin.github.io/inf1901-teluq/html/applets/kmeans.html id=applet-1767712591765858451 class=applet-iframe width=100% loading=lazy data-iresize=true data-transform-scale=1.0></iframe></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/ class="flex align-center"><img src=https://cjauvin.github.io/inf1901-teluq/icons/backward.svg class=book-icon alt=Backward>
<span>Apprentissage supervisé</span>
</a></span><span><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/ class="flex align-center"><span>Travail noté 2</span>
<img src=https://cjauvin.github.io/inf1901-teluq/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#clustering-avec-k-means>Clustering avec $k$-means</a></li></ul></nav></div></aside></main><script src=https://cdn.jsdelivr.net/npm/iframe-resizer/js/iframeResizer.min.js defer></script><script>document.addEventListener("DOMContentLoaded",()=>{const e=document.querySelectorAll('iframe[data-iresize="true"]');if(!e.length||typeof iFrameResize!="function")return;const t={license:"GPLv3",checkOrigin:!1,onResized:function({iframe:e,height:t}){const s=e?.parentElement;if(!s)return;const o=e.getAttribute("data-transform-scale")||"1";let n=parseFloat(o);(!Number.isFinite(n)||n<=0)&&(n=1),s.style.height=t*n+"px"}};e.forEach(e=>{const n={...t},s=e.getAttribute("data-check-origin");s==="true"&&(n.checkOrigin=!0),s==="false"&&(n.checkOrigin=!1),e.getAttribute("data-log")==="true"&&(n.log=!0);const o=e.getAttribute("data-transform-scale")||"1";e.style.transform=`scale(${o})`,e.iFrameResizer||iframeResize(n,e)})})</script></body></html>