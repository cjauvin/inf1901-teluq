<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Les différents paradigmes de l&rsquo;apprentissage automatique
  #

Il existe plusieurs manières de catégoriser les algorithmes d&rsquo;apprentissage
automatique, selon leur nature et la structure des problèmes qu&rsquo;ils tentent de
résoudre. Nous allons considérer deux schémas de classement fondamentaux :

L&rsquo;apprentissage supervisé versus non-supervisé
L&rsquo;apprentissage paramétrique versus non-paramétrique


  Apprentissage supervisé (classification, regression)
  #

L&rsquo;apprentissage supervisé fonctionne à partir de données pour lesquelles la
&ldquo;bonne réponse&rdquo; (i.e. celle qu&rsquo;on aimerait que l&rsquo;algorithme fournisse
systématiquement, une fois entraîné) est fournie, en tant que donnée
d’entraînement. L&rsquo;apprentissage supervisé correspond à la notion intuitive qu&rsquo;on
a de l&rsquo;enseignement et de l&rsquo;apprentissage : un enseignant qui pose une question
à un étudiant  est en mesure de le corriger en lui indiquant si sa réponse est
correcte ou non (car l&rsquo;enseignant connaît, à priori, la &ldquo;bonne réponse&rdquo; à sa
propre question)."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module2/06-paradigmes/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Paradigmes de l'AA"><meta property="og:description" content="Les différents paradigmes de l’apprentissage automatique # Il existe plusieurs manières de catégoriser les algorithmes d’apprentissage automatique, selon leur nature et la structure des problèmes qu’ils tentent de résoudre. Nous allons considérer deux schémas de classement fondamentaux :
L’apprentissage supervisé versus non-supervisé L’apprentissage paramétrique versus non-paramétrique Apprentissage supervisé (classification, regression) # L’apprentissage supervisé fonctionne à partir de données pour lesquelles la “bonne réponse” (i.e. celle qu’on aimerait que l’algorithme fournisse systématiquement, une fois entraîné) est fournie, en tant que donnée d’entraînement. L’apprentissage supervisé correspond à la notion intuitive qu’on a de l’enseignement et de l’apprentissage : un enseignant qui pose une question à un étudiant est en mesure de le corriger en lui indiquant si sa réponse est correcte ou non (car l’enseignant connaît, à priori, la “bonne réponse” à sa propre question)."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Paradigmes de l'AA | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/favicon.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module2/06-paradigmes/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.c2a3a3930cc3c92484d4c7886a609454c1ccc7fbe839b6904dde85b081e514b4.css integrity="sha256-wqOjkwzDySSE1MeIamCUVMHMx/voObaQTd6FsIHlFLQ=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Philosophie du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/ class=flex-auto>Module 1 - Intelligence artificielle</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle checked>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/ class=flex-auto>Module 2 - Apprentissage automatique</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/01-sc%C3%A9nario-r%C3%A9el/>Un scénario imaginé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/02-diff%C3%A9rence-avec-la-prog/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/05-repr%C3%A9sentation-des-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/06-paradigmes/ class=active>Paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/07-applications/>Applications de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/08-programmation/>AA et programmation</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/ class=flex-auto>Module 3 - Réseaux de neurones et apprentissage profond</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/01-r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/ class=flex-auto>Module 4 - IA générative et grands modèles de langage</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class=flex-auto>Module 5 - Autour de l'IA</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/>Attitudes par rapport à l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/menu.svg class=book-icon alt=Menu></label><h3>Paradigmes de l'AA</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#apprentissage-supervisé-classification-regression>Apprentissage supervisé (classification, regression)</a><ul><li><a href=#classification>Classification</a><ul><li><a href=#la-régression-logistique>La régression logistique</a></li><li><a href=#classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)</a></li><li><a href=#classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)</a></li><li><a href=#autres-algorithmes-de-classification>Autres algorithmes de classification</a></li></ul></li><li><a href=#régression>Régression</a><ul><li><a href=#régression-linéaire>Régression linéaire</a></li></ul></li></ul></li><li><a href=#apprentissage-non-supervisé>Apprentissage non-supervisé</a><ul><li><a href=#partitionnement-clustering>Partitionnement (clustering)</a></li></ul></li><li><a href=#apprentissage-paramétrique-versus-non-paramétrique>Apprentissage paramétrique versus non-paramétrique</a></li><li><a href=#apprentissage-inductif-versus-transductif>Apprentissage inductif versus transductif</a></li><li><a href=#apprentissage-par-renforcement-rl>Apprentissage par renforcement (RL)</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=les-différents-paradigmes-de-lapprentissage-automatique>Les différents paradigmes de l&rsquo;apprentissage automatique
<a class=anchor href=#les-diff%c3%a9rents-paradigmes-de-lapprentissage-automatique>#</a></h1><p>Il existe plusieurs manières de catégoriser les algorithmes d&rsquo;apprentissage
automatique, selon leur nature et la structure des problèmes qu&rsquo;ils tentent de
résoudre. Nous allons considérer deux schémas de classement fondamentaux :</p><ul><li>L&rsquo;apprentissage supervisé versus non-supervisé</li><li>L&rsquo;apprentissage paramétrique versus non-paramétrique</li></ul><h2 id=apprentissage-supervisé-classification-regression>Apprentissage supervisé (classification, regression)
<a class=anchor href=#apprentissage-supervis%c3%a9-classification-regression>#</a></h2><p>L&rsquo;apprentissage supervisé fonctionne à partir de données pour lesquelles la
&ldquo;bonne réponse&rdquo; (i.e. celle qu&rsquo;on aimerait que l&rsquo;algorithme fournisse
systématiquement, une fois entraîné) est fournie, en tant que donnée
d’entraînement. L&rsquo;apprentissage supervisé correspond à la notion intuitive qu&rsquo;on
a de l&rsquo;enseignement et de l&rsquo;apprentissage : un enseignant qui pose une question
à un étudiant est en mesure de le corriger en lui indiquant si sa réponse est
correcte ou non (car l&rsquo;enseignant connaît, à priori, la &ldquo;bonne réponse&rdquo; à sa
propre question).</p><h3 id=classification>Classification
<a class=anchor href=#classification>#</a></h3><p>La famille d&rsquo;algorithmes d&rsquo;apprentissage supervisé la plus facile à comprendre
est celle des modèles de classification. Un algorithme de classification est une
fonction mathématique qui associe des &ldquo;objets&rdquo; (donc des points dans un
<a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/05-repr%C3%A9sentation-des-donn%C3%A9es/#niveau-de-lapprentissage-automatique-et-des-mathématiques>espace vectoriel</a>) vers une série prédéfinie d&rsquo;étiquettes, qu&rsquo;on appelle souvent des &ldquo;classes&rdquo;.</p><h4 id=la-régression-logistique>La régression logistique
<a class=anchor href=#la-r%c3%a9gression-logistique>#</a></h4><p>Considérons tout d&rsquo;abord un petit exemple interactif où vous jouerez vous-même
le rôle d&rsquo;un modèle de classification particulier : la <strong>régression
logistique</strong>. Les données d&rsquo;entraînement ont deux classes possibles : <code>bleue</code> ou
<code>rouge</code>, ainsi que deux valeurs (nombres, ou <em>paramètres</em>) pour les décrire :
$x$ et $y$ (puisqu&rsquo;il s&rsquo;agit d&rsquo;un graphe en deux dimensions). La tâche du modèle
est de séparer (c-à-d classifier) les deux groupes. La ligne pointillée constitue la
&ldquo;fonction de décision&rdquo; du modèle : les deux classes se situent de part et
d&rsquo;autre de la ligne. Comme il s&rsquo;agit d&rsquo;une fonction en deux dimensions, on peut
la représenter par la formule simple :</p>$$f(x) \le mx + b$$<p>où $m$ représente la pente et $b$ l&rsquo;ordonnée à l&rsquo;origine. Remarquez un détail
important : il s&rsquo;agit d&rsquo;une fonction d&rsquo;inégalité (inéquation), et non d&rsquo;égalité,
ce qui veut dire qu&rsquo;on peut l&rsquo;interpréter en tant que <em>fonction binaire</em> (deux
valeurs possibles) : <code>rouge</code> si $f(x) \le mx + b$ et <code>bleue</code> si $f(x) \gt mx +
b$ (ou vice versa, arbitrairement). Quand vous déplacez cette ligne de décision
vous-même (en utilisant la souris), vous modifiez les paramètres $m$ et $b$
dynamiquement. Ces paramètres constituent le <strong>modèle</strong>. La situation idéale est
quand cette ligne de décision sépare parfaitement les points rouges des points
bleus, ce qui correspond à une valeur de 0% pour la fonction d&rsquo;erreur (elle-même
représentée par la barre à droite, et distincte de la fonction de décision). Ce
n&rsquo;est pas toujours possible ! Notez qu&rsquo;il est possible d&rsquo;ajouter ou d&rsquo;enlever
des points, et de les déplacer, en utilisant la souris.</p><div style=text-align:center;margin-bottom:10px><label for=pointSlider>Nombre de points : </label><input type=range id=pointSlider min=2 max=50 value=12 style=width:200px>
<span id=pointCount>10</span></div><canvas id=canvas></canvas><div id=info style=text-align:center;margin-top:20px>f(x) <=> mx + b</div><p>Remarquez un détail important : quoiqu&rsquo;on fasse, l&rsquo;erreur ne peut jamais
dépasser 50%. Quand on y pense, c&rsquo;est logique, car même si on place la ligne de
décision à un endroit extrême, qui fait en sorte que TOUS les points se trouvent
d&rsquo;un côté, il reste que 50% de ceux-ci sont tout de même correctement
classifiés. Et si on place la ligne dans une configuration plus pathologique,
qui ferait en sorte par exemple que 75% des points seraient incorrectement
classifiés, la chose logique à faire (ce que l&rsquo;applet interactive fait en fait)
est d&rsquo;inverser le schéma de classification (les points <code>bleus</code> deviennent
<code>rouges</code>, et vice versa), ce qui fait en sorte que l&rsquo;erreur est réduite à 25%.</p><p>La tâche de l&rsquo;algorithme de régression logistique est de trouver les &ldquo;meilleures&rdquo;
valeurs pour les paramètres pour la fonction de décision (donc $m$ et $b$),
celles qui font en sorte que la valeur de la fonction d&rsquo;erreur est la plus
petite possible (zéro idéalement).</p><blockquote class="book-hint info"><p>Matière à réflexion : pourquoi ce n&rsquo;est pas toujours possible de séparer
parfaitement les points? Dans quelles conditions est-ce le cas? Qu&rsquo;est-ce qui
permettrait de faire en sorte que ça devienne possible?</p></blockquote><details open><summary>Les mathématiques de la régression logistique</summary><div class=markdown-inner><p>Bien que nous en ayons parlé en termes purement géométriques jusqu&rsquo;ici, la
régression logistique est en fait une méthode probabiliste : un point est
considéré <code>bleu</code> si le modèle calcule que la probabilité qu&rsquo;il le soit est $\ge
50\%$ (et évidemment vice versa pour <code>rouge</code>). Une probabilité est une valeur
nécessairement entre 0 et 1. Pour transformer une fonction arbitraire en une
fonction de probabilité, on peut utiliser la fonction sigmoïde (aussi appelée
fonction logistique), qui &ldquo;force&rdquo; une valeur à être dans la plage 0 et 1 :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/Logistic-curve-02.png alt></p><p>Nous allons à partir d&rsquo;ici changer un peu la notation que nous avons utilisée
jusqu&rsquo;ici, pour la rendre plus générale :</p>$$\mathbf{x} = [x_1, x_2]$$<p></p>$$y \in \{0, 1\}$$<p>Cette notation classique en apprentissage automatique utilise donc $\mathbf{x}$
pour dénoter les points en 2D sous forme vectorielle ($x_1$ et $x_2$
correspondent aux $x$ et $y$ de la représentation 2D classique, et $\mathbf{x}$
est donc un <em>vecteur</em>, dont les 2 valeurs correspondent aux &ldquo;caractéristiques&rdquo;
d&rsquo;un point, sa description numérique). La variable scalaire (donc une valeur
numérique simple, par opposition à un vecteur) $y$ est utilisée pour dénoter la
<em>vraie</em> classe d&rsquo;un point (0 ou 1, correspondant arbitrairement à <code>bleu</code> ou
<code>rouge</code>). Les paramètres seront représentés par le vecteur $\mathbf{w} = [w_1,
w2]$. Il est maintenant possible de réécrire notre fonction de décision à l&rsquo;aide
de cette nouvelle notation vectorielle :</p>$$z = \mathbf{w}^\top \mathbf{x} + b.$$<p>($\mathbf{w}^\top \mathbf{x}$ est le produit vectoriel de $\mathbf{w}$ et
$\mathbf{x}$). Notons tout d&rsquo;abord qu&rsquo;il y maintenant 3 paramètres ($w1$, $w2$
et $b$), alors que dans l&rsquo;exemple ci-haut seulement 2 sont mentionnés : $m$ et
$b$. On introduit aussi une nouvelle variable $z$ : que veut-elle dire? Pour
comprendre cela, on doit faire un peu d&rsquo;algèbre. Il suffit de noter que notre
équation de départ :</p>$$y = mx + b$$<p>est en fait équivalente à :</p>$$x_2 = mx_1 + b$$<p>ce qu&rsquo;on peut réécrire aisément :</p>$$mx_1 - x_2 + b = 0.$$<p>En choisissant ensuite $m = -w_1/w_2$ et $b = -b/w_2$, on peut réécrire :</p>$$\frac{-w_1 x_1}{w_2} - x_2 - \frac{b}{w_2} = 0$$<p>En multipliant les deux membres de l&rsquo;équation par $-w_2$, on arrive à :</p>$$w_1 x_1 + w_2 x_2 + b = 0$$<p>ce qui constitue la forme générale d&rsquo;une équation en 2D. Étant donné que ce qui
nous intéresse se passe de part et d&rsquo;autre de la ligne de décision (car il
s&rsquo;agit comme nous l&rsquo;avons vu d&rsquo;une inéquation), on introduit le score $z$, pour
quantifier la distance à laquelle un point se trouve, de cette ligne de
séparation :</p>$$z = w_1 x_1 + w_2 x_2 + b$$<p>En utilisant la fonction logistique que nous avons introduite ci-haut pour
transformer ce score (une valeur arbitraire) en une probabilité (donc une valeur
contrainte entre 0 et 1), on peut maintenant introduire l&rsquo;équation de la
régression logistique :</p>$$P(y) = \hat{y} = \frac{1}{1 + e^{-z}}$$<p>avec laquelle il est bien important de comprendre que $\hat{y}$ représente une
probabilité (donc que $\hat{y} \in [0, 1]$), tandis que $y$ représente une vraie
classe (donc que $y \in {0, 1}$). La régression logistique transforme donc la
distance entre un point et la ligne de décision, en une mesure de probabilité.
L&rsquo;algorithme de classification utilisera donc la probabilité calculée pour chaque
point de la manière suivante :</p>$$
\text{classification}(x_1, x_2) =
\left\{
\begin{array}{ll}
\mathtt{bleu} \text{ si } \hat{y} \ge 0.5 & \\
\mathtt{rouge} \text{ si } \hat{y} < 0.5 & \\
\end{array}
\right.
$$<p>Notre but est maintenant de trouver les valeurs optimales pour les paramètres
$\mathbf{w}$ (donc deux nombres précis, $w_1$ et $w_2$), celles qui vont faire en
sorte de minimiser l&rsquo;erreur de classification. Nous avons donc besoin de définir
tout d&rsquo;abord cette erreur en tant que fonction précise :</p>$$E(y, \hat{y}) = -[y \log(\hat{y}) + (1 - y)\log(1 - \hat{y})]$$<p>Pour bien comprendre le fonctionnement de cette équation, examinons les différents
cas de figure :</p><ol><li>Un point est en réalité <code>bleu</code> (donc $y = 1$) et la confiance du modèle en ce fait est élevée ($\hat{y} = 0.9$) : $E(y, \hat{y}) = -\log(0.9) \approx 0.1$ (l&rsquo;erreur est basse).</li><li>Un point est en réalité <code>bleu</code> (donc $y = 1$) mais la confiance du modèle en ce fait est basse ($\hat{y} = 0.1$) : $E(y, \hat{y}) = -\log(0.1) \approx 2.3$ (l&rsquo;erreur est élevée).</li><li>Un point est en réalité <code>rouge</code> (donc $y = 0$) et la confiance du modèle en ce fait est élevée ($\hat{y} = 0.1$) : $E(y, \hat{y}) = -\log(0.9) \approx 0.1$ (l&rsquo;erreur est basse).</li><li>Un point est en réalité <code>rouge</code> (donc $y = 0$) mais la confiance du modèle en ce fait est basse ($\hat{y} = 0.9$) : $E(y, \hat{y}) = -\log(0.1) \approx 2.3$ (l&rsquo;erreur est élevée).</li></ol><p>La fonction d&rsquo;erreur $E$ que nous avons s&rsquo;applique à un seul point. Nous avons
besoin de la généraliser à l&rsquo;ensemble des $n$ points que nous avons, en en
faisant simplement la somme. Ceci est une nouvelle fonction nommée $J$, qui
utilise des indices $(i)$ pour dénoter les valeurs associées aux points
particuliers de notre ensemble d’entraînement :</p>$$J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} E(y^{(i)}, \hat{y}^{(i)})$$<p></p>$$J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} \left[ y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)}) \right]$$<p>Vous pouvez remarquer qu&rsquo;on spécifie cette fois les paramètres $\mathbf{w}$ et
$b$ pour la fonction $J$ : la raison est que nous voulons maintenant <em>optimiser</em>
la fonction $J$, c&rsquo;est-à-dire trouver les valeurs de ses paramètres
($\mathbf{w}$ et $b$) qui vont faire en sorte de la minimiser (c-à-d que sa
valeur soit la plus petite possible, quand on considère l&rsquo;ensemble de toutes ses
valeurs possibles, donc indirectement via l&rsquo;ensemble de toutes les valeurs
possibles pour ses paramètres $\mathbf{w}$ et $b$). Cette opération
d&rsquo;optimisation est l&rsquo;essence même de l&rsquo;apprentissage automatique. Apprendre,
c&rsquo;est optimiser une fonction d&rsquo;erreur, de manière à la rendre la plus petite
possible. On fait cela à l&rsquo;aide de la technique de la <strong>descente de gradient</strong>,
qui consiste à déterminer tout d&rsquo;abord la &ldquo;direction&rdquo; (c-à-d le vecteur) dans
laquelle la valeur de la fonction change le plus, à un point donné. Si on
utilise la métaphore d&rsquo;un terrain montagneux pour représenter une fonction
d&rsquo;erreur en 3 dimensions, l&rsquo;altitude d&rsquo;un point à un endroit particulier
représente la valeur de la fonction, tant que les coordonnées géographiques du
point (<code>x</code> et <code>y</code>, ou lat/lon si on utilise un GPS), représentent les
paramètres. Le gradient, dans cette métaphore, représente la direction dans
laquelle le changement d&rsquo;altitude sera le plus abrupt.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/mountain_gradient.jpg alt></p>$$\frac{\partial J}{\partial \mathbf{w}} = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)}) \mathbf{x}^{(i)}$$<p></p>$$\frac{\partial J}{\partial b} = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)})$$<p>Le symbole $\partial$ peut faire un peu peur à priori, mais sa signification
devient claire quand on le traduit en mots : le gradient de la fonction $J$ par
rapport au paramètre $w$ (ou $b$). Et son calcul, dans le cas de la régression
logistique, est très simple : pour chaque point, on considère :</p><ol><li>La différence entre la probabilité produite par le modèle et la vraie étiquette : $\hat{y}^{(i)} - y^{(i)}$</li><li>Le produit de cette différence et du vecteur d&rsquo;entrée : $(\hat{y}^{(i)} - y^{(i)}) \mathbf{x}^{(i)}$ (rappelons que $\mathbf{x} = [x_1, x_2]$ est un vecteur
à deux dimensions, donc ce produit sera également bi-dimensionnel, tout comme l&rsquo;est également $\mathbf{w}$)</li><li>On veut la moyenne de ces produits (donc la somme et une division)</li></ol><p>Nos règles de mise à jour (la mise à jour, qui est un concept généralement plus
associé à la programmation qu&rsquo;aux mathématiques, est représentée ici par le
symbole $\leftarrow$) pour les paramètres sont donc :</p>$$\mathbf{w} \leftarrow \mathbf{w} - \alpha \cdot \frac{\partial J}{\partial \mathbf{w}}, \quad b \leftarrow b - \alpha \cdot \frac{\partial J}{\partial b}$$<p>L&rsquo;algorithme d&rsquo;optimisation (apprentissage) de la régression logistique consiste
donc en l&rsquo;application itérative (répétée) de ces règles de mise à jour des
paramètres, qui feront en sorte de changer graduellement les valeurs de
$\mathbf{w}$ et $\mathbf{b}$, tout en diminuant également progressivement la
valeur de l&rsquo;erreur cumulée, c&rsquo;est-à-dire la valeur de la fonction $J$. $\alpha$
est le <em>taux d&rsquo;apprentissage</em> (une simple valeur numérique), qui fait en sorte
de limiter la taille des &ldquo;pas&rdquo; qu&rsquo;on prend dans la direction du gradient, à
chaque itération. Pour le distinguer des paramètres ($\mathbf{w}$ et
$\mathbf{b}$), on appelle $\alpha$ un <em>hyper-paramètre</em>.</p></div></details><details open><summary>La programmation de la régression logistique</summary><div class=markdown-inner><iframe src=https://cjauvin.github.io/inf1901-teluq/notebooks/module2/reglog.html width=100% height=800px></iframe></div></details><blockquote class="book-hint info"><p>Une question qu&rsquo;il peut être intéressant de considérer, une fois qu&rsquo;on a fait
l&rsquo;effort de mieux comprendre le fonctionnement d&rsquo;un algorithme relativement
simple comme la régression logistique (simple mais très représentatif, si vous
le comprenez bien, vous avez déjà une excellente compréhension de l&rsquo;AA au sens
plus général) : en quoi est-ce que ceci constitue de l&rsquo;intelligence,
<em>artificielle</em> ou non? &mldr;</p></blockquote><p>Une fois que les idées de base de ce petit exemple interactif sont bien claires
pour vous, on peut généraliser le concept de la régression logistique pour en
faire un modèle plus puissant et complexe :</p><ul><li>Considérer ..</li></ul><h4 id=classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)
<a class=anchor href=#classification-bay%c3%a9sienne-naive-gaussienne>#</a></h4><p>Examinons maintenant un autre algorithme de classification que nous pourrions
utiliser sur nos données en deux dimensions.</p><p>La régression logistique est un algorithme d&rsquo;apprentissage <strong>discriminatif</strong> :
elle tente de modéliser la probabilité qu&rsquo;un exemple appartienne directement à
une classe (<code>bleue</code> ou <code>rouge</code>) directement à partir des caractéristiques de cet
exemples ($x_1$ et $x_2$). En contraste, la classification naive bayésienne est
un algorithme <strong>génératif</strong>, qui tente tout d&rsquo;abord de modéliser la distribution
des classes, avant d&rsquo;utiliser ces modèles (un modèle pour la classe <code>bleue</code> et
un pour la classe <code>rouge</code>) pour déterminer si un point particulier a plus de
chance d&rsquo;avoir été <em>généré</em> par un modèle particulier (disons <code>rouge</code>) plutôt
qu&rsquo;un autre.</p><p>Chaque couple dimension / classe sera modélisé par une gaussienne à une
dimension (donc 4 modèles en tout : un pour la classe <code>rouge</code> sur la dimension
$x$, un pour la classe <code>bleue</code> aussi sur $x_1$, et la même chose pour la
dimension $x_2$). Une gaussienne (aussi appelée distribution normale) est la
fameuse &ldquo;courbe en cloche&rdquo;, qui détermine comment la &ldquo;masse de probabilité&rdquo; est
répartie autour d&rsquo;une valeur centrale (qu&rsquo;on appelle la moyenne) :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/gaussian.png alt></p><p>La gaussienne est une fonction continue 1D car elle n&rsquo;a qu&rsquo;une seule valeur
dépendante (l&rsquo;axe horizontal). L&rsquo;axe vertical, la valeur de la fonction,
correspond à la masse de la probabilité. Remarquez un aspect important : la
valeur de la fonction à un point précis donné sur l&rsquo;axe horizontal (par exemple
la moyenne) ne correspond PAS à la probabilité de ce point, malgré ce que
l&rsquo;intuition voudrait croire. Étant donné que la masse de probabilité est une
fonction continue, pour calculer une probabilité donnée il faut calculer
l&rsquo;intégrale de la fonction entre deux points donnés. Étant donné que la totalité
de la masse (l&rsquo;aire sous la courbe) est 1, on peut dire que la probabilité qu&rsquo;un
événement soit plus petit que la moyenne (ou plus grand) est de 50% (c-à-d que
l&rsquo;aire sous la courbe, ou l&rsquo;intégrale, de la partie à droite ou à gauche de la
barre verticale de la moyenne totalise 0.5).</p><p>Mais donc que veut-on dire par la modélisation par une gaussienne?</p><p>La première étape consiste à projeter les points sur l&rsquo;axe $x_1$, ce qui les
rend uni-dimensionnels.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x1_proj.png alt></p><p>Une fois les points projetés, on peut modéliser (c-à-d décrire) les classes de
points à l&rsquo;aide de gaussiennes, dont l&rsquo;épaisseur correspondra à la densité (ou
quantité) de points sur l&rsquo;axe, pour chaque classe.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x1_gauss.png alt></p><p>On répète la procédure pour les deux classes, sur l&rsquo;axe $x_2$.</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x2_proj.png alt></p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module2/nb_x2_gauss.png alt></p><p>À ce stade, nous avons donc quatre modèles :</p>$$p(x_1 \mid \text{rouge}) = \mathcal{N}(x_1; \mu_{1,\text{rouge}}, \sigma_{1,\text{rouge}}^2)$$<p></p>$$p(x_2 \mid \text{rouge}) = \mathcal{N}(x_2; \mu_{2,\text{rouge}}, \sigma_{2,\text{rouge}}^2)$$<p></p>$$p(x_1 \mid \text{bleue}) = \mathcal{N}(x_1; \mu_{1,\text{bleue}}, \sigma_{1,\text{bleue}}^2)$$<p></p>$$p(x_2 \mid \text{bleue}) = \mathcal{N}(x_2; \mu_{2,\text{bleue}}, \sigma_{2,\text{bleue}}^2)$$<p>où $\mathcal{N}$ représente la gaussienne, et $\mu$ et $\sigma$ représentent ses
paramètres (qui déterminent sa forme particulière). L&rsquo;apprentissage d&rsquo;un modèle
de classification naive bayésienne constitue donc le calcul des valeurs
optimales pour ces différents paramètres (que nous n&rsquo;allons pas couvrir ici).</p><p>On peut combiner les modèles :</p>$$p(x_1, x_2 \mid \text{rouge}) \;=\; p(x_1 \mid \text{rouge}) \cdot p(x_2 \mid \text{rouge})$$<p></p>$$p(x_1, x_2 \mid \text{bleue}) \;=\; p(x_1 \mid \text{bleue}) \cdot p(x_2 \mid \text{bleue})$$<p>ou encore, pour simplifier :</p>$$P(\mathbf{x} \mid y)$$<p>Ce modèle est <em>génératif</em>, car il génère un point $\mathbf{x}$ (donc ses coordonnées
$x_1$ et $x_2$), à partir d&rsquo;une classe donnée $y$ (<code>rouge</code> ou <code>bleue</code>). On dit
aussi que ce que ce modèle est la probabilité de $\mathbf{x}$ <em>conditionnelle</em> à $y$.</p><p>Mais ce qui nous intéresse, dans un contexte de classification, est l&rsquo;équivalent
de ce que nous avons calculé pour le modèle de régression logistique, soit :</p>$$P(y \mid \mathbf{x})$$<p>Il semble donc que notre modèle génératif soit le contraire de ce qu&rsquo;on l&rsquo;on
veut. Est-il possible de &ldquo;l&rsquo;inverser&rdquo;, pour obtenir le modèle que l&rsquo;on souhaite,
soit la probabilité d&rsquo;une classe étant donné un point?</p><p>Il est possible de faire cela à l&rsquo;aide du <a href=https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Bayes>théorème de
Bayes</a> (ce qui
explique donc le nom de l&rsquo;algorithme), qui stipule que :</p>$$P(y \mid \mathbf{x}) \;=\; \frac{P(\mathbf{x} \mid y) \, P(y)}{P(\mathbf{x})}$$<p>Nous connaissons déjà évidemment $P(\mathbf{x} \mid y)$, que nous avons calculé
ci-haut, et $P(y)$ est simple à calculer : il s&rsquo;agit simplement de la
probabilité à priori (sans aucune autre connaissance) que les points soient
<code>rouges</code> ou <code>bleus</code> (ce qui est possiblement 50%, équiprobable, si notre
ensemble d’entraînement est balancé, moitié <code>rouge</code> moitié <code>bleu</code>).
$P(\mathbf{x})$ est moins clair (la probabilité à priori des données?), mais
étant donné que cette valeur ne dépend pas de $y$, on peut simplement l&rsquo;ignorer
pour obtenir un algorithme de classification final :</p>$$
\text{classification}(\mathbf{x}) =
\left\{
\begin{array}{ll}
\mathtt{rouge} \text{ si } P(\mathbf{x} \mid \text{rouge}) P(\text{rouge}) \ge P(\mathbf{x} \mid \text{bleu}) P(\text{bleu}) & \\
\mathtt{bleu} \text{ sinon } & \\
\end{array}
\right.
$$<p>Tout comme la régression logistique que nous avons étudiée, cet algorithme
produit une décision linéaire, pour des raisons mathématiques que nous n&rsquo;allons
pas explorer plus à fond.</p><h4 id=classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)
<a class=anchor href=#classification-bay%c3%a9sienne-naive-multinomiale>#</a></h4><h4 id=autres-algorithmes-de-classification>Autres algorithmes de classification
<a class=anchor href=#autres-algorithmes-de-classification>#</a></h4><ul><li>Régression logistique (ex1: à partir du nombre d&rsquo;heures étudiées et du nombre de cours, prédire si un étudiant a gradué ou non, ex2: à partir des caractéristiques des passagers du Titanic, prédire s&rsquo;ils ont survécu ou non)</li><li>k-NN</li><li>Arbres de décision</li><li>Naive Bayes</li><li>Réseau de neurones</li></ul><h3 id=régression>Régression
<a class=anchor href=#r%c3%a9gression>#</a></h3><p>Une régression est une famille d&rsquo;algorithmes d&rsquo;apprentissage supervisé
(ou plus classiquement, de modélisation statistique) dont le but est
de découvrir une fonction numérique continue, au sens classique
mathématique (dans sa forme la plus simple, une fonction associe une
valeur numérique du domaine X vers l&rsquo;image Y).</p><ul><li>Régression linéaire (ex. à partir du nombre de pièces et l&rsquo;année de construction, on aimerait prédire le prix d&rsquo;une maison)</li><li>Réseau de neurones</li></ul><h4 id=régression-linéaire>Régression linéaire
<a class=anchor href=#r%c3%a9gression-lin%c3%a9aire>#</a></h4><p>Voici un autre exemple interactif pour explorer la régression linéaire. Les
points bleus suivent une droite cachée avec du bruit, et vous pouvez ajuster
votre ligne pour minimiser l&rsquo;erreur quadratique moyenne :</p><div style=text-align:center;margin-bottom:10px><label for=pointSlider2>Nombre de points : </label><input type=range id=pointSlider2 min=2 max=50 value=25 style=width:200px>
<span id=pointCount2>25</span></div><canvas id=canvas2></canvas><div id=info2 style=text-align:center;margin-top:20px>f(x) = mx + b</div><h2 id=apprentissage-non-supervisé>Apprentissage non-supervisé
<a class=anchor href=#apprentissage-non-supervis%c3%a9>#</a></h2><p>Nous avons vu qu&rsquo;une caractéristique essentielle de l&rsquo;apprentissage
supervisé est que la &ldquo;bonne réponse&rdquo; (qu&rsquo;il s&rsquo;agisse du prix réel
d&rsquo;une maison, ou la variable binaire oui/non correspondant au fait
qu&rsquo;un étudiant ait échoué ou non) est fournie avec les données
d’entraînement. Un algorithme d&rsquo;apprentissage supervisé (nous avons vu
qu&rsquo;il y en avait plusieurs) utilise cette &ldquo;bonne réponse&rdquo; comme une
cible cruciale qu&rsquo;il doit s&rsquo;efforcer d&rsquo;atteindre, de modéliser donc.
En contraste, un algorithme non-supervisé n&rsquo;a pas cette &ldquo;bonne
réponse&rdquo;, il n&rsquo;a que des données non-étiquetées. Les algorithmes de
cette famille ont donc une tâche entièrement différente que celle de
l&rsquo;apprentissage supervisé. Il doivent découvrir la structure inhérente
aux données, de manière autonome, tout en étant guidé possible par des
hypothèses. Par exemple, si les données sont des mesures décrivant un
ensemble de fleurs de différentes espèces, il est possible que je
sache à priori combien d&rsquo;espèces l&rsquo;ensemble d’entraînement contient.
Dans ce cas, supposons que je sache qu&rsquo;il y a trois espèces, alors
l&rsquo;algorithme n&rsquo;aura qu&rsquo;à découvrir ces trois groupes, et associer
chaque exemple à un groupe en particulier. Il pourrait être également
possible que le nombre d&rsquo;espèces soit à priori inconnu, ce qui rendrait
la tâche de l&rsquo;algorithme de classification encore plus difficile.</p><h3 id=partitionnement-clustering>Partitionnement (clustering)
<a class=anchor href=#partitionnement-clustering>#</a></h3><p>Avec un algorithme de partitionnement, on peut découvrir des
&ldquo;agrégats&rdquo;, ou des groupes naturels dans les données.</p><ul><li><p>k-Means</p></li><li><p>DBScan</p></li><li><p>Hierarchical clustering
*** Réduction de la dimensionnalité
En tentant de réduire la dimensionnalité des données, on peut
découvrir sa structure inhérente, ce qui est souvent utile en
visualisation (par exemple, une donnée exprimée en très haute
dimension peut être plus facile à comprendre ou visualiser en 2d ou
3d).</p></li><li><p>PCA</p></li></ul><h2 id=apprentissage-paramétrique-versus-non-paramétrique>Apprentissage paramétrique versus non-paramétrique
<a class=anchor href=#apprentissage-param%c3%a9trique-versus-non-param%c3%a9trique>#</a></h2><p>Il existe une autre manière, complètement différente, de classifier les
algorithmes d&rsquo;apprentissage : si l&rsquo;algorithme est implémenté à l&rsquo;aide d&rsquo;une
fonction mathématique essentiellement définie par des paramètres, qui sont
indépendants des données qui seront traitées par l&rsquo;algorithme, on parle
d&rsquo;apprentissage paramétrique. Avec l&rsquo;apprentissage non-paramétrique, en
contraste, la fonction de décision est définie à partir des données
d&rsquo;entraînement. Les données elles-mêmes constituent l&rsquo;algorithme.</p><p>Exemples d&rsquo;algorithmes paramétriques :</p><ul><li>Régression linéaire (apprentissage supervisé)</li><li>Régression logistique (supervisé)</li><li>Réseau de neurones</li></ul><p>Exemples d&rsquo;algorithmes non-paramétriques :</p><ul><li>Arbres de décision</li><li>k-NN</li></ul><p>Pour certains algorithmes, la frontière entre ces deux classes est un peu plus
floue.</p><h2 id=apprentissage-inductif-versus-transductif>Apprentissage inductif versus transductif
<a class=anchor href=#apprentissage-inductif-versus-transductif>#</a></h2><p>TODO</p><h2 id=apprentissage-par-renforcement-rl>Apprentissage par renforcement (RL)
<a class=anchor href=#apprentissage-par-renforcement-rl>#</a></h2><p>L&rsquo;apprentissage par renforcement (APR) est un autre paradigme
d&rsquo;apprentissage automatique, très différent des précédents dont nous avons
parlés. On peut généraliser les apprentissages supervisé et
non-supervisé en considérant qu&rsquo;ils sont une forme de &ldquo;reconnaissance
de motifs&rdquo; (en anglais &ldquo;pattern recognition&rdquo;). Les mécanismes de ce
genre sont souvent associés aux fonctions cognitives de la perception,
chez les humains. Par exemple, mes yeux perçoivent une information
visuelle qu&rsquo;on m&rsquo;a appris à classifier en tant que &ldquo;balle&rdquo;, alors
quand je vois une balle, la classification appropriée est effectuée
par mon esprit (exemple d&rsquo;apprentissage supervisé). D&rsquo;une manière
apparentée mais un peu différente, il se peut que mes yeux détectent,
lors d&rsquo;une promenade en forêt, une forme ou des couleurs
particulières, que je ne parviens pas à identifier, mais qui vont tout
de même attirer mon attention (exemple d&rsquo;apprentissage non-supervisé).
En contraste de cette reconnaissance de motifs, l&rsquo;apprentissage par
renforcement est plutôt une modélisation du comportement, plutôt que
de la perception (quelle action devrait être posée dans ce contexte
particulier). L&rsquo;APR est souvent utilisé dans les jeux et la robotique.</p><script>const BLUE="#4285F4",RED="#EA4335",canvas=document.getElementById("canvas"),ctx=canvas.getContext("2d"),info=document.getElementById("info"),pointSlider=document.getElementById("pointSlider"),pointCount=document.getElementById("pointCount");let width,height,graphWidth,graphOffsetX;window.addEventListener("load",()=>{const e=canvas.parentElement.getBoundingClientRect().width;width=e,height=Math.round(e*(500/780)),canvas.width=width,canvas.height=height,graphWidth=Math.min(width-80,width*.85),graphOffsetX=35,anchor={x:graphWidth/2+20,y:height/2},generateRandomPoints(12),draw()});let points=[];function generateRandomPoints(e){points=[];const t=20;for(let n=0;n<e;n++){const s=n<Math.floor(e/2)?0:1,o=Math.random()*(graphWidth-2*t)+t,i=Math.random()*(height-2*t)+t;points.push({x:o,y:i,label:s})}}let anchor={x:300,y:200},angle=-Math.PI/4;const anchorRadius=12,innerRadius=11,outerRadius=12;let dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1;function drawGrid(e=25,t=0){ctx.strokeStyle="#eee",ctx.lineWidth=1;for(let n=0;n<=graphWidth;n+=e)ctx.beginPath(),ctx.moveTo(t+n,0),ctx.lineTo(t+n,height),ctx.stroke();for(let n=0;n<=height;n+=e)ctx.beginPath(),ctx.moveTo(t,n),ctx.lineTo(t+graphWidth,n),ctx.stroke()}function draw(){ctx.clearRect(0,0,width,height);const e=(width-graphWidth)/2-graphOffsetX;ctx.fillStyle="white",ctx.fillRect(e,0,graphWidth,height),ctx.strokeStyle="#aaa",ctx.lineWidth=1,ctx.strokeRect(e,0,graphWidth,height),drawGrid(25,e);const u=Math.cos(angle),d=Math.sin(angle),a=1e3,y=anchor.x-u*a,f=anchor.y-d*a,j=anchor.x+u*a,b=anchor.y+d*a;let l=-Math.tan(angle),h=-(anchor.y-l*anchor.x);const v=isFinite(l)?l.toFixed(2):"∞",g=isFinite(h)?h.toFixed(2):"∞";info.textContent=`f(x) <= ${v}x + ${g}`;let i=0,r=[];for(let e of points){const s=e.x-anchor.x,o=e.y-anchor.y,a=u*o-d*s;let t=a>0?1:0;const n=t===e.label;r.push({predicted:t,correct:n}),n||i++}const p=i>points.length/2;p&&(i=points.length-i,r=r.map(e=>({predicted:1-e.predicted,correct:!e.correct})));for(let n=0;n<points.length;n++){const t=points[n],s=r[n].correct,o=t.label===0?RED:BLUE;if(ctx.beginPath(),ctx.arc(t.x+e,t.y,outerRadius,0,Math.PI*2),ctx.fillStyle=o,ctx.fill(),!s){ctx.strokeStyle="grey",ctx.lineWidth=2;const n=outerRadius+2;ctx.beginPath(),ctx.moveTo(t.x+e-n,t.y-n),ctx.lineTo(t.x+e+n,t.y+n),ctx.moveTo(t.x+e+n,t.y-n),ctx.lineTo(t.x+e-n,t.y+n),ctx.stroke()}}const m=points.length>0?i/points.length*100:0,n=e+graphWidth+20,s=50,o=height-100,t=20;ctx.fillStyle="#f0f0f0",ctx.fillRect(n,s,t,o),ctx.strokeStyle="#aaa",ctx.lineWidth=1,ctx.strokeRect(n,s,t,o);const c=m/100*o;ctx.fillStyle="#ff6b6b",ctx.fillRect(n,s+o-c,t,c),ctx.fillStyle=getComputedStyle(document.body).getPropertyValue("--body-font-color")||"#333",ctx.font="12px sans-serif",ctx.textAlign="left",ctx.fillText("100%",n+t+5,s+5),ctx.fillText("0%",n+t+5,s+o+5),ctx.fillText(`${m.toFixed(1)}%`,n+t+5,s+o-c+5),ctx.font="14px sans-serif",ctx.textAlign="center",ctx.fillText("Erreur",n+t/2,s-10),ctx.save(),ctx.beginPath(),ctx.rect(e,0,graphWidth,height),ctx.clip(),ctx.beginPath(),ctx.moveTo(y+e,f),ctx.lineTo(j+e,b),ctx.strokeStyle="black",ctx.lineWidth=2,ctx.setLineDash([5,5]),ctx.stroke(),ctx.setLineDash([]),ctx.restore(),ctx.fillStyle="#000",ctx.beginPath(),ctx.arc(anchor.x+e,anchor.y,anchorRadius,0,Math.PI*2),ctx.fill(),ctx.fillStyle="#fff",ctx.beginPath(),ctx.arc(anchor.x+e,anchor.y,innerRadius,0,Math.PI*2),ctx.fill()}function distance(e,t){return Math.hypot(e.x-t.x,e.y-t.y)}canvas.addEventListener("mousedown",e=>{e.preventDefault();const o=canvas.getBoundingClientRect(),t={x:e.clientX-o.left,y:e.clientY-o.top},s=(width-graphWidth)/2-graphOffsetX;if(mouseDownPos={x:t.x,y:t.y},hasMoved=!1,t.x<s||t.x>s+graphWidth)return;const n={x:t.x-s,y:t.y};if(e.button===0){if(distance(n,anchor)<=anchorRadius){dragging=!0,dragMode="translate";return}const e=Math.cos(angle),t=Math.sin(angle),s=n.x-anchor.x,o=n.y-anchor.y,i=Math.abs(t*s-e*o);if(i<10){dragging=!0,dragMode="rotate";return}}for(let t=0;t<points.length;t++)if(distance(n,points[t])<outerRadius){if(e.button===0){dragging=!0,dragMode="point",draggedPointIndex=t;return}if(e.button===2){points.splice(t,1),draw();return}}const i=Math.max(15,Math.min(graphWidth-15,n.x)),a=Math.max(15,Math.min(height-15,n.y));e.button===0?points.push({x:i,y:a,label:0}):e.button===2&&points.push({x:i,y:a,label:1}),draw()}),canvas.addEventListener("mousemove",e=>{const o=canvas.getBoundingClientRect(),n={x:e.clientX-o.left,y:e.clientY-o.top},s=(width-graphWidth)/2-graphOffsetX,t={x:n.x-s,y:n.y};if(mouseDownPos&&distance(n,mouseDownPos)>3&&(hasMoved=!0),dragging){if(dragMode==="translate")anchor.x=Math.max(15,Math.min(585,t.x)),anchor.y=Math.max(15,Math.min(height-15,t.y));else if(dragMode==="rotate"){const e=t.x-anchor.x,n=t.y-anchor.y;angle=Math.atan2(n,e)}else dragMode==="point"&&draggedPointIndex>=0&&(points[draggedPointIndex].x=Math.max(15,Math.min(585,t.x)),points[draggedPointIndex].y=Math.max(15,Math.min(height-15,t.y)));draw()}else{if(n.x<s||n.x>s+graphWidth){canvas.style.cursor="default";return}if(distance(t,anchor)<=anchorRadius){canvas.style.cursor="grab";return}const e=Math.cos(angle),o=Math.sin(angle),i=t.x-anchor.x,a=t.y-anchor.y,r=Math.abs(o*i-e*a);if(r<10){canvas.style.cursor="grab";return}for(let e of points)if(distance(t,e)<outerRadius){canvas.style.cursor="grab";return}canvas.style.cursor="default"}}),canvas.addEventListener("mouseup",()=>{dragMode==="point"&&draggedPointIndex>=0&&!hasMoved&&(points.splice(draggedPointIndex,1),draw()),dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1}),canvas.addEventListener("mouseleave",()=>{dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1}),canvas.addEventListener("contextmenu",e=>{e.preventDefault()});function getTouchCoordinates(e){const t=canvas.getBoundingClientRect(),n=e.touches[0]||e.changedTouches[0];return{x:n.clientX-t.left,y:n.clientY-t.top}}let touchStartTime=0,touchHoldTimer=null,touchHoldTriggered=!1;canvas.addEventListener("touchstart",e=>{e.preventDefault();const n=getTouchCoordinates(e),s=(width-graphWidth)/2-graphOffsetX;if(touchStartTime=Date.now(),touchHoldTriggered=!1,mouseDownPos={x:n.x,y:n.y},hasMoved=!1,n.x<s||n.x>s+graphWidth)return;const t={x:n.x-s,y:n.y};if(touchHoldTimer=setTimeout(()=>{touchHoldTriggered=!0;for(let e=0;e<points.length;e++)if(distance(t,points[e])<outerRadius){points.splice(e,1),draw();return}const e=Math.max(15,Math.min(graphWidth-15,t.x)),n=Math.max(15,Math.min(height-15,t.y));points.push({x:e,y:n,label:1}),draw()},500),distance(t,anchor)<=anchorRadius){dragging=!0,dragMode="translate";return}const o=Math.cos(angle),i=Math.sin(angle),a=t.x-anchor.x,r=t.y-anchor.y,c=Math.abs(i*a-o*r);if(c<10){dragging=!0,dragMode="rotate";return}for(let e=0;e<points.length;e++)if(distance(t,points[e])<outerRadius){dragging=!0,dragMode="point",draggedPointIndex=e;return}}),canvas.addEventListener("touchmove",e=>{e.preventDefault();const n=getTouchCoordinates(e),s=(width-graphWidth)/2-graphOffsetX,t={x:n.x-s,y:n.y};if(touchHoldTimer&&(clearTimeout(touchHoldTimer),touchHoldTimer=null),mouseDownPos&&distance(n,mouseDownPos)>3&&(hasMoved=!0),dragging&&!touchHoldTriggered){if(dragMode==="translate")anchor.x=Math.max(15,Math.min(585,t.x)),anchor.y=Math.max(15,Math.min(height-15,t.y));else if(dragMode==="rotate"){const e=t.x-anchor.x,n=t.y-anchor.y;angle=Math.atan2(n,e)}else dragMode==="point"&&draggedPointIndex>=0&&(points[draggedPointIndex].x=Math.max(15,Math.min(graphWidth-15,t.x)),points[draggedPointIndex].y=Math.max(15,Math.min(height-15,t.y)));draw()}}),canvas.addEventListener("touchend",e=>{if(e.preventDefault(),touchHoldTimer&&(clearTimeout(touchHoldTimer),touchHoldTimer=null),touchHoldTriggered){dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1;return}if(!hasMoved&&Date.now()-touchStartTime<300){const t=getTouchCoordinates(e),n=(width-graphWidth)/2-graphOffsetX;if(t.x>=n&&t.x<=n+graphWidth){const e={x:t.x-n,y:t.y};for(let t=0;t<points.length;t++)if(distance(e,points[t])<outerRadius){points.splice(t,1),draw(),dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1;return}const s=Math.max(15,Math.min(graphWidth-15,e.x)),o=Math.max(15,Math.min(height-15,e.y));points.push({x:s,y:o,label:0}),draw()}}dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1}),canvas.addEventListener("touchcancel",e=>{e.preventDefault(),touchHoldTimer&&(clearTimeout(touchHoldTimer),touchHoldTimer=null),dragging=!1,dragMode=null,draggedPointIndex=-1,mouseDownPos=null,hasMoved=!1,touchHoldTriggered=!1}),pointSlider.addEventListener("input",e=>{const t=parseInt(e.target.value);pointCount.textContent=t,generateRandomPoints(t),draw()});const canvas2=document.getElementById("canvas2"),ctx2=canvas2.getContext("2d"),info2=document.getElementById("info2"),pointSlider2=document.getElementById("pointSlider2"),pointCount2=document.getElementById("pointCount2");let width2,height2,graphWidth2,graphOffsetX2,points2=[],anchor2={x:300,y:200},angle2=-Math.PI/4,hiddenSlope,hiddenIntercept,dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1,touchStartTime2=0,touchHoldTimer2=null,touchHoldTriggered2=!1;const anchorRadius2=12,innerRadius2=11,outerRadius2=12;window.addEventListener("load",()=>{const e=canvas2.parentElement.getBoundingClientRect().width;width2=e,height2=Math.round(e*(500/780)),canvas2.width=width2,canvas2.height=height2,graphWidth2=Math.min(width2-80,width2*.85),graphOffsetX2=35,hiddenSlope=(Math.random()-.5)*1.5,hiddenIntercept=height2*.3+Math.random()*height2*.4,anchor2={x:graphWidth2/2+20,y:height2/2},generateRandomPoints2(25),draw2()});function generateRandomPoints2(e){points2=[];const t=20,a=80,n=t,s=graphWidth2-t,o=t+a/2,i=height2-t-a/2,l=(i-o)/(s-n),r=-(i-o)/(s-n);hiddenSlope=r+Math.random()*(l-r);const d=o-hiddenSlope*n,u=i-hiddenSlope*s,c=Math.max(d,u),h=Math.min(i-hiddenSlope*n,o-hiddenSlope*s);hiddenIntercept=c+Math.random()*(h-c);for(let n=0;n<e;n++){const s=Math.random()*(graphWidth2-2*t)+t,o=hiddenSlope*s+hiddenIntercept,i=(Math.random()-.5)*a,r=o+i;points2.push({x:s,y:r,label:1})}}function drawGrid2(e=25,t=0){ctx2.strokeStyle="#eee",ctx2.lineWidth=1;for(let n=0;n<=graphWidth2;n+=e)ctx2.beginPath(),ctx2.moveTo(t+n,0),ctx2.lineTo(t+n,height2),ctx2.stroke();for(let n=0;n<=height2;n+=e)ctx2.beginPath(),ctx2.moveTo(t,n),ctx2.lineTo(t+graphWidth2,n),ctx2.stroke()}function draw2(){ctx2.clearRect(0,0,width2,height2);const e=(width2-graphWidth2)/2-graphOffsetX2;ctx2.fillStyle="white",ctx2.fillRect(e,0,graphWidth2,height2),ctx2.strokeStyle="#aaa",ctx2.lineWidth=1,ctx2.strokeRect(e,0,graphWidth2,height2),drawGrid2(25,e);const h=Math.cos(angle2),u=Math.sin(angle2),i=Math.max(width2,height2),_=anchor2.x-h*i,y=anchor2.y-u*i,m=anchor2.x+h*i,g=anchor2.y+u*i;points2.forEach(t=>{ctx2.fillStyle=BLUE,ctx2.beginPath(),ctx2.arc(t.x+e,t.y,outerRadius2,0,2*Math.PI),ctx2.fill(),ctx2.strokeStyle="#333",ctx2.lineWidth=1,ctx2.stroke()}),ctx2.fillStyle="#000",ctx2.beginPath(),ctx2.arc(anchor2.x+e,anchor2.y,anchorRadius2,0,2*Math.PI),ctx2.fill(),ctx2.fillStyle="#fff",ctx2.beginPath(),ctx2.arc(anchor2.x+e,anchor2.y,innerRadius2,0,2*Math.PI),ctx2.fill(),ctx2.save(),ctx2.rect(e,0,graphWidth2,height2),ctx2.clip(),ctx2.strokeStyle="#000",ctx2.lineWidth=2,ctx2.setLineDash([5,5]),ctx2.beginPath(),ctx2.moveTo(_+e,y),ctx2.lineTo(m+e,g),ctx2.stroke(),ctx2.setLineDash([]),ctx2.restore();let c=0;points2.forEach(e=>{const t=anchor2.y+(e.x-anchor2.x)*Math.tan(angle2),n=(e.y-t)**2;c+=n});const l=points2.length>0?c/points2.length:0,p=1e4,f=Math.min(100,l/p*100),n=e+graphWidth2+20,t=50,o=height2-100,s=20;ctx2.fillStyle="#f0f0f0",ctx2.fillRect(n,t,s,o),ctx2.strokeStyle="#666",ctx2.lineWidth=1,ctx2.strokeRect(n,t,s,o);const r=f/100*o;ctx2.fillStyle="#ff6b6b",ctx2.fillRect(n,t+o-r,s,r),ctx2.fillStyle=getComputedStyle(document.body).getPropertyValue("--body-font-color")||"#333",ctx2.font="12px sans-serif",ctx2.textAlign="left",ctx2.fillText("Max",n+s+5,t+5),ctx2.fillText("0",n+s+5,t+o+5);const v=t+o-r+5,b=t+20,j=Math.max(v,b);ctx2.fillText(`${l.toFixed(1)}`,n+s+5,j),ctx2.font="14px sans-serif",ctx2.textAlign="center",ctx2.fillText("Erreur",n+s/2,t-10);const a=-Math.tan(angle2),d=-(anchor2.y-a*anchor2.x),w=isFinite(a)?a.toFixed(2):"∞",O=isFinite(d)?d.toFixed(2):"∞";info2.textContent=`f(x) = ${w}x + ${O}`}pointSlider2.addEventListener("input",e=>{const t=parseInt(e.target.value);pointCount2.textContent=t,generateRandomPoints2(t),draw2()});function distance2(e,t){return Math.hypot(e.x-t.x,e.y-t.y)}canvas2.addEventListener("mousedown",e=>{e.preventDefault();const o=canvas2.getBoundingClientRect(),n={x:e.clientX-o.left,y:e.clientY-o.top},s=(width2-graphWidth2)/2-graphOffsetX2;if(mouseDownPos2={x:n.x,y:n.y},hasMoved2=!1,n.x<s||n.x>s+graphWidth2)return;const t={x:n.x-s,y:n.y};if(e.button===0){if(distance2(t,anchor2)<=anchorRadius2){dragging2=!0,dragMode2="translate";return}const e=Math.cos(angle2),n=Math.sin(angle2),s=t.x-anchor2.x,o=t.y-anchor2.y,i=Math.abs(n*s-e*o);if(i<10){dragging2=!0,dragMode2="rotate";return}for(let e=0;e<points2.length;e++)if(distance2(t,points2[e])<outerRadius2){dragging2=!0,dragMode2="point",draggedPointIndex2=e;return}const a=Math.max(15,Math.min(graphWidth2-15,t.x)),r=Math.max(15,Math.min(height2-15,t.y));points2.push({x:a,y:r,label:1})}else if(e.button===2){const e=Math.max(15,Math.min(graphWidth2-15,t.x)),n=Math.max(15,Math.min(height2-15,t.y));points2.push({x:e,y:n,label:1})}draw2()}),canvas2.addEventListener("mousemove",e=>{const o=canvas2.getBoundingClientRect(),n={x:e.clientX-o.left,y:e.clientY-o.top},s=(width2-graphWidth2)/2-graphOffsetX2,t={x:n.x-s,y:n.y};if(mouseDownPos2&&distance2(n,mouseDownPos2)>3&&(hasMoved2=!0),dragging2){if(dragMode2==="translate")anchor2.x=Math.max(15,Math.min(graphWidth2-15,t.x)),anchor2.y=Math.max(15,Math.min(height2-15,t.y));else if(dragMode2==="rotate"){const e=t.x-anchor2.x,n=t.y-anchor2.y;angle2=Math.atan2(n,e)}else dragMode2==="point"&&draggedPointIndex2>=0&&(points2[draggedPointIndex2].x=Math.max(15,Math.min(graphWidth2-15,t.x)),points2[draggedPointIndex2].y=Math.max(15,Math.min(height2-15,t.y)));draw2()}else{if(n.x<s||n.x>s+graphWidth2){canvas2.style.cursor="default";return}if(distance2(t,anchor2)<=anchorRadius2){canvas2.style.cursor="grab";return}const e=Math.cos(angle2),o=Math.sin(angle2),i=t.x-anchor2.x,a=t.y-anchor2.y,r=Math.abs(o*i-e*a);if(r<10){canvas2.style.cursor="grab";return}for(let e of points2)if(distance2(t,e)<outerRadius2){canvas2.style.cursor="grab";return}canvas2.style.cursor="default"}}),canvas2.addEventListener("mouseup",e=>{dragMode2==="point"&&draggedPointIndex2>=0&&!hasMoved2&&(points2.splice(draggedPointIndex2,1),draw2()),dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1}),canvas2.addEventListener("contextmenu",e=>{e.preventDefault()});function getTouchCoordinates2(e){const t=canvas2.getBoundingClientRect(),n=e.touches[0]||e.changedTouches[0];return{x:n.clientX-t.left,y:n.clientY-t.top}}canvas2.addEventListener("touchstart",e=>{e.preventDefault();const n=getTouchCoordinates2(e),s=(width2-graphWidth2)/2-graphOffsetX2;if(touchStartTime2=Date.now(),touchHoldTriggered2=!1,mouseDownPos2={x:n.x,y:n.y},hasMoved2=!1,n.x<s||n.x>s+graphWidth2)return;const t={x:n.x-s,y:n.y};if(touchHoldTimer2=setTimeout(()=>{touchHoldTriggered2=!0;for(let e=0;e<points2.length;e++)if(distance2(t,points2[e])<outerRadius2){points2.splice(e,1),draw2();return}const e=Math.max(15,Math.min(graphWidth2-15,t.x)),n=Math.max(15,Math.min(height2-15,t.y));points2.push({x:e,y:n,label:1}),draw2()},500),distance2(t,anchor2)<=anchorRadius2){dragging2=!0,dragMode2="translate";return}const o=Math.cos(angle2),i=Math.sin(angle2),a=t.x-anchor2.x,r=t.y-anchor2.y,c=Math.abs(i*a-o*r);if(c<10){dragging2=!0,dragMode2="rotate";return}for(let e=0;e<points2.length;e++)if(distance2(t,points2[e])<outerRadius2){dragging2=!0,dragMode2="point",draggedPointIndex2=e;return}}),canvas2.addEventListener("touchmove",e=>{e.preventDefault();const n=getTouchCoordinates2(e),s=(width2-graphWidth2)/2-graphOffsetX2,t={x:n.x-s,y:n.y};if(touchHoldTimer2&&(clearTimeout(touchHoldTimer2),touchHoldTimer2=null),mouseDownPos2&&distance2(n,mouseDownPos2)>3&&(hasMoved2=!0),dragging2){if(dragMode2==="translate")anchor2.x=Math.max(15,Math.min(graphWidth2-15,t.x)),anchor2.y=Math.max(15,Math.min(height2-15,t.y));else if(dragMode2==="rotate"){const e=t.x-anchor2.x,n=t.y-anchor2.y;angle2=Math.atan2(n,e)}else dragMode2==="point"&&draggedPointIndex2>=0&&(points2[draggedPointIndex2].x=Math.max(15,Math.min(graphWidth2-15,t.x)),points2[draggedPointIndex2].y=Math.max(15,Math.min(height2-15,t.y)));draw2()}}),canvas2.addEventListener("touchend",e=>{if(e.preventDefault(),touchHoldTimer2&&(clearTimeout(touchHoldTimer2),touchHoldTimer2=null),touchHoldTriggered2){dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1;return}if(!hasMoved2&&Date.now()-touchStartTime2<300){const t=getTouchCoordinates2(e),n=(width2-graphWidth2)/2-graphOffsetX2;if(t.x>=n&&t.x<=n+graphWidth2){const e={x:t.x-n,y:t.y};for(let t=0;t<points2.length;t++)if(distance2(e,points2[t])<outerRadius2){points2.splice(t,1),draw2(),dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1;return}const s=Math.max(15,Math.min(graphWidth2-15,e.x)),o=Math.max(15,Math.min(height2-15,e.y));points2.push({x:s,y:o,label:1}),draw2()}}dragging2=!1,dragMode2=null,draggedPointIndex2=-1,mouseDownPos2=null,hasMoved2=!1})</script></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><div class="flex flex-wrap justify-between"><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/05-repr%C3%A9sentation-des-donn%C3%A9es/ class="flex align-center float-left book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title="Que sont les données?">
<span>Que sont les données?</span>
</a><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/07-applications/ class="flex align-center float-right book-icon"><span>Applications de l'AA</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Applications de l'AA"></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#apprentissage-supervisé-classification-regression>Apprentissage supervisé (classification, regression)</a><ul><li><a href=#classification>Classification</a><ul><li><a href=#la-régression-logistique>La régression logistique</a></li><li><a href=#classification-bayésienne-naive-gaussienne>Classification bayésienne naive (gaussienne)</a></li><li><a href=#classification-bayésienne-naive-multinomiale>Classification bayésienne naive (multinomiale)</a></li><li><a href=#autres-algorithmes-de-classification>Autres algorithmes de classification</a></li></ul></li><li><a href=#régression>Régression</a><ul><li><a href=#régression-linéaire>Régression linéaire</a></li></ul></li></ul></li><li><a href=#apprentissage-non-supervisé>Apprentissage non-supervisé</a><ul><li><a href=#partitionnement-clustering>Partitionnement (clustering)</a></li></ul></li><li><a href=#apprentissage-paramétrique-versus-non-paramétrique>Apprentissage paramétrique versus non-paramétrique</a></li><li><a href=#apprentissage-inductif-versus-transductif>Apprentissage inductif versus transductif</a></li><li><a href=#apprentissage-par-renforcement-rl>Apprentissage par renforcement (RL)</a></li></ul></nav></div></aside></main></body></html>