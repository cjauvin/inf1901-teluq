<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Un mini ChatGPT dans Google Sheets
  #

Un modèle de langage est un outil mathématique qui permet d&rsquo;établir la
distribution statistique des mots : en présence (ou dans le contexte) de
certains mots, quel mot a tendance à suivre, et dans quelle proportion des cas
(c&rsquo;est-à-dire avec quelle probabilité). Un modèle de langage n&rsquo;est pas un objet
abstrait qui décrit une réalité théorique : il s&rsquo;agit d&rsquo;un modèle statistique
entraîné sur des données particulières. De la même manière qu&rsquo;un modèle de
prédiction de la température pour la ville de Montréal est différent d&rsquo;un modèle
pour la ville de Québec, un modèle de langage créé par exemple à partir des
données de 100 livres écrits au 19ième siècle, et un autre à partir de 100
livres écrits au 20ième siècles, seront deux modèles distincts, et auront des
propriétés statistiques très différentes."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Travail noté 4"><meta property="og:description" content="Un mini ChatGPT dans Google Sheets # Un modèle de langage est un outil mathématique qui permet d’établir la distribution statistique des mots : en présence (ou dans le contexte) de certains mots, quel mot a tendance à suivre, et dans quelle proportion des cas (c’est-à-dire avec quelle probabilité). Un modèle de langage n’est pas un objet abstrait qui décrit une réalité théorique : il s’agit d’un modèle statistique entraîné sur des données particulières. De la même manière qu’un modèle de prédiction de la température pour la ville de Montréal est différent d’un modèle pour la ville de Québec, un modèle de langage créé par exemple à partir des données de 100 livres écrits au 19ième siècle, et un autre à partir de 100 livres écrits au 20ième siècles, seront deux modèles distincts, et auront des propriétés statistiques très différentes."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Travail noté 4 | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/favicon.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.c2a3a3930cc3c92484d4c7886a609454c1ccc7fbe839b6904dde85b081e514b4.css integrity="sha256-wqOjkwzDySSE1MeIamCUVMHMx/voObaQTd6FsIHlFLQ=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Philosophie du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/ class=flex-auto>Module 1 - Intelligence artificielle</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/ class=flex-auto>Module 2 - Apprentissage automatique</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/01-sc%C3%A9nario-r%C3%A9el/>Un scénario imaginé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/02-diff%C3%A9rence-avec-la-prog/>AA versus programmation</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/03-diff%C3%A9rence-avec-lia/>AA versus IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/04-ia-versus-stats/>AA versus statistiques</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/05-repr%C3%A9sentation-des-donn%C3%A9es/>Représentation des données</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/06-paradigmes/>Paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/07-applications/>Applications de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/08-programmation/>AA et programmation</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/ class=flex-auto>Module 3 - Réseaux de neurones et apprentissage profond</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/01-r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle checked>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/ class=flex-auto>Module 4 - IA générative et grands modèles de langage</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/ class=active>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class=flex-auto>Module 5 - Enjeux éthiques et philosophiques</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/menu.svg class=book-icon alt=Menu></label><h3>Travail noté 4</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#entraînement-du-modèle>Entraînement du modèle</a></li><li><a href=#utilisation-du-modèle-inférence>Utilisation du modèle (inférence)</a></li><li><a href=#questions>Questions</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=un-mini-chatgpt-dans-google-sheets>Un mini ChatGPT dans Google Sheets
<a class=anchor href=#un-mini-chatgpt-dans-google-sheets>#</a></h1><p>Un modèle de langage est un outil mathématique qui permet d&rsquo;établir la
distribution statistique des mots : en présence (ou dans le contexte) de
certains mots, quel mot a tendance à suivre, et dans quelle proportion des cas
(c&rsquo;est-à-dire avec quelle probabilité). Un modèle de langage n&rsquo;est pas un objet
abstrait qui décrit une réalité théorique : il s&rsquo;agit d&rsquo;un modèle statistique
entraîné sur des données particulières. De la même manière qu&rsquo;un modèle de
prédiction de la température pour la ville de Montréal est différent d&rsquo;un modèle
pour la ville de Québec, un modèle de langage créé par exemple à partir des
données de 100 livres écrits au 19ième siècle, et un autre à partir de 100
livres écrits au 20ième siècles, seront deux modèles distincts, et auront des
propriétés statistiques très différentes.</p><p>Tout comme le modèle de classification du travail noté #2, il est encore ici
question de probabilité conditionnelle. Étant donné que nous allons construire
un modèle bigramme, il s&rsquo;agit donc de la probabilité d&rsquo;un mot, étant donné le
mot qui le précède (la barre verticale dans l&rsquo;équation signifie &ldquo;étant donné&rdquo;,
ou &ldquo;en présence de&rdquo;, ou &ldquo;dans le contexte de&rdquo;) :</p>$$\text{Prob(mot à prédire | mot qui précède)}$$<p>La tâche de notre modèle de classification pour les courriels était de
discriminer (répondre oui ou non à la question : est-ce un pourriel?) tandis que
la tâche de notre modèle bigramme sera ici de générer du nouveau texte, une fois
le modèle entraîné, en faisant de l&rsquo;échantillonnage. La génération de nouveau
texte à l&rsquo;aide de l&rsquo;échantillonnage est précisément ce qui permet à ChatGPT de
répondre à une question, ou de composer un poème.</p><h2 id=entraînement-du-modèle>Entraînement du modèle
<a class=anchor href=#entra%c3%aenement-du-mod%c3%a8le>#</a></h2><p>Voyons maintenant comment il est possible de calculer ces probabilités en
entraînant un modèle bigramme génératif sur un texte très simple.</p><p>Ètant donné que nous allons encore une fois utiliser la tableur en ligne <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google
Sheets</a>, assurez-vous que votre version
est correctement configurée.</p><p>Copiez tout d&rsquo;abord les mots de ce texte dans la colonne <code>A</code> d&rsquo;une nouvelle
&ldquo;feuille&rdquo; Google Sheets, un mot par rangée :</p><pre tabindex=0><code>le
chat
dort
le
chien
mange
le
chat
mange
une
souris
le
chien
dort
la
souris
court
la
souris
mange
le
fromage
le
chat
court
le
chien
voit
le
chat
le
chat
voit
la
souris
le
chien
court
</code></pre><p>Notez tout d&rsquo;abord que la colonne <code>A</code> (son contenu) est très souvent nommée le
&ldquo;corpus d&rsquo;entraînement&rdquo;. Il s&rsquo;agit du texte brut à partir duquel nous allons
calculer les paramètres du modèle. Pour les vrais modèles de langage, ce texte
peut être extrêmement volumineux ! (Il peut comprendre des millions de livres,
par exemple).</p><p>Dans la première cellule de la colonne <code>B</code> (donc <code>B1</code>), entrez maintenant cette
formule :</p><pre tabindex=0><code>=A2
</code></pre><p>La colonne <code>B</code> devrait être étendue jusqu&rsquo;à la cellule <code>B37</code>, en double-cliquant
sur le petit &ldquo;+&rdquo; qui apparaît quand votre curseur est placé au-dessus du coin
inférieur droit de la cellule <code>B1</code> (il est possible que Google Sheets offre de
le faire pour vous, automatiquement).</p><p>Dans la cellule <code>C1</code>, entrez maintenant cette formule :</p><pre tabindex=0><code>=A1 &amp; &#34; &#34; &amp; B1
</code></pre><p>Encore une fois, la colonne <code>C</code> doit s&rsquo;étendre jusqu&rsquo;à la cellule <code>C37</code>. À ce stade,
votre feuille devrait ressembler à ceci :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/sheets_3_first_cols.png alt></p><p>À ce stade, il devrait être clair pour vous que la colonne <code>C</code> contient tous les
bigrammes extraits du texte de la colonne <code>A</code> (la colonne <code>B</code> n&rsquo;est qu&rsquo;un
mécanisme intermédiaire pour les obtenir facilement).</p><p>Nous allons maintenant compter, dans la colonne <code>D</code>, le nombre de fois où un
bigramme particulier (une séquence particulière de deux mots) apparaît dans le
corpus d&rsquo;entraînement de la colonne <code>A</code> (la colonne <code>D</code> doit être étendue pour
avoir le même nombre d&rsquo;éléments que la colonne <code>C</code>) :</p><pre tabindex=0><code>=COUNTIF(C:C, C1)
</code></pre><p>On constate par exemple que le bigramme &ldquo;le chien&rdquo; apparaît 4 fois, tandis que
le bigramme &ldquo;fromage le&rdquo;, apparaît seulement une fois.</p><p>Dans la colonne <code>E</code>, nous allons maintenant calculer les paramètres de notre
modèle, soit la probabilité d&rsquo;un mot, étant donné le mot qui le précède :</p>$$\text{Prob(mot de la col B | mot de la col A)} =
\frac{
\#(\text{mots A et B})
}{
\#(\text{mot A})
}
$$<p>Pour ce faire, entrez dans la cellule <code>E1</code> (la formule est un peu complexifiée par
le fait qu&rsquo;on veut considérer tous les mots de la colonne A sauf le dernier, car
sa présence fausserait légèrement les probabilités) :</p><pre tabindex=0><code>=D1 / COUNTIF(A$1:INDEX(A:A, COUNTA(A:A)-1), A1)
</code></pre><p>La probabilité d&rsquo;un mot étant donné le mot qui le précède est donc simplement le
nombre de fois où ce bigramme particulier apparaît dans le texte, divisée par le
nombre de fois où le premier mot du bigramme apparaît (le dénominateur est
nécessairement plus grand ou égal que le numérateur, prenez un moment pour vous
en convaincre). Étant donné que cette valeur est une probabilité, elle doit
nécessairement être contenue entre 0 et 1.</p><p>Dans la colonne <code>F</code> nous allons filtrer la colonne <code>C</code> (tous les bigrammes, qui
comprennent donc des bigrammes répétés) pour ne retenir que les bigrammes
uniques :</p><pre tabindex=0><code>=SORT(UNIQUE(C:C))
</code></pre><p>Nous devons ensuite séparer les mots des bigrammes uniques, les
premiers mots dans la colonne <code>G</code> :</p><pre tabindex=0><code>=INDEX(SPLIT(F1, &#34; &#34;), 1)
</code></pre><p>suivis des deuxièmes mots (des bigrammes uniques de la colonne <code>F</code>) dans la
colonne <code>H</code> :</p><pre tabindex=0><code>=INDEX(SPLIT(F1, &#34; &#34;), 2)
</code></pre><p>Et dans la colonne <code>I</code> nous allons ajouter les probabilités
correspondantes (provenant de la colonne <code>E</code>):</p><pre tabindex=0><code>=INDEX(E:E, MATCH(F1, C:C, 0))
</code></pre><p>On peut maintenant constater que le mot &ldquo;souris&rdquo; suit nécessairement (avec
certitude, soit une probabilité de 1) le mot &ldquo;la&rdquo;, tandis que le mot &ldquo;le&rdquo; peut
être suivi des mots &ldquo;chat&rdquo;, &ldquo;chien&rdquo; et &ldquo;fromage&rdquo; avec des probabilités de 0.5,
0.4 et 0.1, respectivement.</p><p>À ce stade, votre feuille devrait ressembler à ceci :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/sheets_model_complete.png alt></p><h2 id=utilisation-du-modèle-inférence>Utilisation du modèle (inférence)
<a class=anchor href=#utilisation-du-mod%c3%a8le-inf%c3%a9rence>#</a></h2><p>Maintenant que notre modèle de langage est &ldquo;entraîné&rdquo; (c&rsquo;est-à-dire que les
probabilités pour les différents bigrammes, les paramètres donc, sont
calculées), on peut l&rsquo;utiliser pour générer un nouveau texte, différent du
corpus d&rsquo;entraînement.</p><p>Pour démarrer le mécanisme de génération, on peut entrer un premier mot dans la
cellule <code>J1</code>, par exemple le mot &ldquo;le&rdquo; (ce mot doit faire partie du vocabulaire du
modèle).</p><p>Ensuite, la génération peut être effectuée de manière itérative avec cette
formule plus complexe, à partir de la cellule <code>K1</code> si vous désirez que les mots
soient générés à la verticale, ou <code>J2</code> si vous désirez qu&rsquo;ils le soient à
l&rsquo;horizontale (attention étant donné que cette formule contient plusieurs lignes
elle doit être entrée dans l&rsquo;espace de la formule, en haut des colonnes) :</p><pre tabindex=0><code>=LET(
  next_word_mask, ARRAYFORMULA($G:$G = J1),
  next_words, FILTER($H:$H, next_word_mask),
  probs, FILTER($I:$I, next_word_mask),
  probs_cumul, SCAN(0, probs, LAMBDA(a, b, a + b)),
  sampled_word_idx, MATCH(RAND(), {0; probs_cumul}, 1),
  INDEX(next_words, sampled_word_idx)
)
</code></pre><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/sheets_generate.png alt></p><p>Cette formule détermine tout d&rsquo;abord quels sont les prochains mots possibles
(suivant le mot &ldquo;le&rdquo;, dans ce cas particulier), ainsi que leur probabilité
associée. Elle détermine ensuite le mot suivant en choisissant un nombre
aléatoire qui est utilisé en tant qu&rsquo;index dans la liste des probabilités
cumulatives (cette procédure est appelée échantillonnage).</p><p>Si votre deuxième mot généré se trouve dans la cellule <code>K2</code>, vous pouvez
continuer la génération en glissant la cellule vers la droite. Si votre deuxième
mot se trouve plutôt dans la cellule <code>J2</code>, vous pouvez poursuivre la génération
en glissant la cellule <code>J2</code> vers le bas.</p><h2 id=questions>Questions
<a class=anchor href=#questions>#</a></h2><ol><li><p>Quels sont les paramètres du modèle (quelles colonnes exactement)?</p></li><li><p>Expliquez en vos mots comment ces paramètres sont calculés.</p></li><li><p>En quoi la colonne <code>B</code> de ce modèle diffère de la colonne <code>B</code> du modèle de
classification des courriels du <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>travail noté #2</a>?</p></li><li><p>Expliquez en quoi le modèle de classification du travail #2 était un modèle
discriminatif, alors que ce modèle de langage est un modèle génératif?</p></li><li><p>Quelle est la conséquence du fait que le bigramme &ldquo;le chat&rdquo; apparaisse 5 fois
dans le corpus d&rsquo;entraînement (colonne <code>A</code>)?</p></li><li><p>Quelle est la conséquence du fait que le bigramme &ldquo;la souris&rdquo; apparaisse 3
fois, et en quoi cela diffère du bigramme de la question (4)?</p></li><li><p>Est-ce que la présence de certains bigrammes fait en sorte qu&rsquo;il est possible
de générer des séquences moins grammaticales? Lesquels en particulier?</p></li><li><p>Est-ce que la présence de certains bigrammes fait en sorte qu&rsquo;il est possible
de générer des séquences sémantiquement plus étranges? Lesquels en
particulier?</p></li><li><p>De quel type d&rsquo;apprentissage s&rsquo;agit-il ici : supervisé, non-supervisé ou
semi-supervisé? Expliquez en quoi ça l&rsquo;est.</p></li><li><p>Si on utilisait un modèle trigramme au lieu d&rsquo;un bigramme, qu&rsquo;est-ce qui
changerait? Quelles seraient les contraintes entraînées par l&rsquo;utilisation
d&rsquo;un modèle trigramme au lieu d&rsquo;un modèle bigramme?</p></li><li><p>Supposons que le modèle ait généré le mot &ldquo;voit&rdquo;, expliquez la conséquence
que le choix du prochain mot (celui suivant immédiatement &ldquo;voit&rdquo;) va avoir
sur la suite de la phrase générée.</p></li><li><p>Est-ce qu&rsquo;il y a une limite à la longueur de la phrase pouvant être générée
par le modèle?</p></li><li><p>Est-ce qu&rsquo;il est possible que le modèle génère un bigramme qui ne fait pas
partie des exemples qui ont servis à son entraînement?</p></li><li><p>Expliquez quelles sont les limites au niveau de la capacité de
généralisation de ce modèle. À quoi sont dues ces limites?</p></li><li><p>Expliquez comment on pourrait faire en sorte que le modèle puisse modéliser
et générer des phrases complètes (avec une majuscule et un point final).</p></li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><div class="flex flex-wrap justify-between"><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/ class="flex align-center float-left book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title=3Blue1Brown>
<span>3Blue1Brown</span>
</a><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class="flex align-center float-right book-icon"><span>Module 5 - Enjeux éthiques et philosophiques</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Module 5 - Enjeux éthiques et philosophiques"></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#entraînement-du-modèle>Entraînement du modèle</a></li><li><a href=#utilisation-du-modèle-inférence>Utilisation du modèle (inférence)</a></li><li><a href=#questions>Questions</a></li></ul></nav></div></aside></main></body></html>