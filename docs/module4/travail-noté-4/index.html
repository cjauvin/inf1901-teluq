<!doctype html><html lang=fr dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Un mini ChatGPT dans Google Sheets (travail noté 4)
  #

Un modèle de langage est un outil mathématique qui permet de modéliser la
distribution statistique des mots : en présence (ou dans le contexte) de
certains mots, quel mot a tendance à suivre, et dans quelle proportion des cas
(c&rsquo;est-à-dire avec quelle probabilité). Un modèle de langage n&rsquo;est pas un objet
abstrait qui décrit une réalité théorique : il s&rsquo;agit d&rsquo;un modèle statistique
entraîné sur des données particulières. De la même manière qu&rsquo;un modèle de
prédiction de la température pour la ville de Montréal est différent d&rsquo;un modèle
pour la ville de Québec, un modèle de langage créé par exemple à partir des
données de 100 livres écrits au 19e siècle, et un autre à partir de 100
livres écrits au 20e siècle, seront deux modèles distincts, et auront des
propriétés statistiques très différentes."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/"><meta property="og:site_name" content="INF1901 - Initiation à l'IA : concepts et réflexions"><meta property="og:title" content="Travail noté 4"><meta property="og:description" content="Un mini ChatGPT dans Google Sheets (travail noté 4) # Un modèle de langage est un outil mathématique qui permet de modéliser la distribution statistique des mots : en présence (ou dans le contexte) de certains mots, quel mot a tendance à suivre, et dans quelle proportion des cas (c’est-à-dire avec quelle probabilité). Un modèle de langage n’est pas un objet abstrait qui décrit une réalité théorique : il s’agit d’un modèle statistique entraîné sur des données particulières. De la même manière qu’un modèle de prédiction de la température pour la ville de Montréal est différent d’un modèle pour la ville de Québec, un modèle de langage créé par exemple à partir des données de 100 livres écrits au 19e siècle, et un autre à partir de 100 livres écrits au 20e siècle, seront deux modèles distincts, et auront des propriétés statistiques très différentes."><meta property="og:locale" content="fr"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Travail noté 4 | INF1901 - Initiation à l'IA : concepts et réflexions</title><link rel=icon href=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png><link rel=manifest href=https://cjauvin.github.io/inf1901-teluq/manifest.json><link rel=canonical href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/><link rel=stylesheet href=https://cjauvin.github.io/inf1901-teluq/book.min.c2a3a3930cc3c92484d4c7886a609454c1ccc7fbe839b6904dde85b081e514b4.css integrity="sha256-wqOjkwzDySSE1MeIamCUVMHMx/voObaQTd6FsIHlFLQ=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=https://cjauvin.github.io/inf1901-teluq/><img src=https://cjauvin.github.io/inf1901-teluq/images/paperclip-logo.png alt=Logo class=book-icon><span>INF1901 - Initiation à l'IA : concepts et réflexions</span></a></h2><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/pr%C3%A9sentation/>Présentation du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/philosophie/>Approche pédagogique du cours</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/professeurs/>Les professeurs</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/livres/>Les livres</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/travaux-not%C3%A9s/>Travaux notés</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/feuille-de-route/>Feuille de route</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google Sheets</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/assistants-intelligents/>Usage de l'IA</a></li><li><input type=checkbox id=section-8907ef67e4ecdf3db52171242f091373 class=toggle>
<label for=section-8907ef67e4ecdf3db52171242f091373 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/ class=flex-auto>Module 1 - Intelligence artificielle</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/activit%C3%A9s/>Activités</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module1/travail-not%C3%A9-1/>Travail noté 1</a></li></ul></li><li><input type=checkbox id=section-0e47afea11237f1612150a31e7123755 class=toggle>
<label for=section-0e47afea11237f1612150a31e7123755 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/ class=flex-auto>Module 2 - Apprentissage automatique</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/sc%C3%A9nario-r%C3%A9el/>Un scénario réaliste</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/diff%C3%A9rence-avec-x/>AA versus X</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-donn%C3%A9es/>Que sont les données?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/mod%C3%A8les/>Qu'est-ce qu'un modèle?</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/les-paradigmes/>Les paradigmes de l'AA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/apprentissage-supervis%C3%A9/>Apprentissage supervisé</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>Travail noté 2</a></li></ul></li><li><input type=checkbox id=section-9cc60359ac12343378e5fa944b3863f7 class=toggle>
<label for=section-9cc60359ac12343378e5fa944b3863f7 class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/ class=flex-auto>Module 3 - Réseaux de neurones et apprentissage profond</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/01-r%C3%A9seaux-de-neurones/>Les réseaux de neurones</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/02-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module3/travail-not%C3%A9-3/>Travail noté 3</a></li></ul></li><li><input type=checkbox id=section-d23b9c643b16319dcdaeed5376bcec9c class=toggle checked>
<label for=section-d23b9c643b16319dcdaeed5376bcec9c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/ class=flex-auto>Module 4 - IA générative et grands modèles de langage</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/01-ia-g%C3%A9n%C3%A9rative/>IA générative</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/02-grands-mod%C3%A8les-de-langage/>Grands modèles de langage</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/>3Blue1Brown</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/travail-not%C3%A9-4/ class=active>Travail noté 4</a></li></ul></li><li><input type=checkbox id=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=toggle>
<label for=section-b90ca6a3362bb22be66d4f5e1f8ab16c class=flex><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class=flex-auto>Module 5 - Autour de l'IA</a></label><ul><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/attitudes/>Attitudes à l'égard de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/conversation/>Conversation synoptique autour de l'IA</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/travail-not%C3%A9-5/>Travail noté 5</a></li></ul></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/ressources-additionnelles/>Ressources supplémentaires</a></li><li><a href=https://cjauvin.github.io/inf1901-teluq/docs/conclusion/>Conclusion</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/menu.svg class=book-icon alt=Menu></label><h3>Travail noté 4</h3><label for=toc-control><img src=https://cjauvin.github.io/inf1901-teluq/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#consignes>Consignes</a></li><li><a href=#entraînement-du-modèle>Entraînement du modèle</a></li><li><a href=#utilisation-du-modèle-inférence>Utilisation du modèle (inférence)</a></li><li><a href=#questions>Questions</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=un-mini-chatgpt-dans-google-sheets-travail-noté-4>Un mini ChatGPT dans Google Sheets (travail noté 4)
<a class=anchor href=#un-mini-chatgpt-dans-google-sheets-travail-not%c3%a9-4>#</a></h1><p>Un modèle de langage est un outil mathématique qui permet de modéliser la
distribution statistique des mots : en présence (ou dans le contexte) de
certains mots, quel mot a tendance à suivre, et dans quelle proportion des cas
(c&rsquo;est-à-dire avec quelle probabilité). Un modèle de langage n&rsquo;est pas un objet
abstrait qui décrit une réalité théorique : il s&rsquo;agit d&rsquo;un modèle statistique
entraîné sur des données particulières. De la même manière qu&rsquo;un modèle de
prédiction de la température pour la ville de Montréal est différent d&rsquo;un modèle
pour la ville de Québec, un modèle de langage créé par exemple à partir des
données de 100 livres écrits au 19e siècle, et un autre à partir de 100
livres écrits au 20e siècle, seront deux modèles distincts, et auront des
propriétés statistiques très différentes.</p><p>Le modèle du <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>travail noté du module 2</a> était un modèle de classification, dont le fonctionnement implicite (&ldquo;sous
le capot&rdquo;) était en fait un modèle génératif, &ldquo;inversé&rdquo; comme nous l&rsquo;avons vu à
l&rsquo;aide du théorème de Bayes. Le modèle que nous allons construire ici sera
explicitement génératif. Notre modèle sera un modèle <em>bigramme</em>, qui calcule la
probabilité d&rsquo;un mot <em>étant donné</em> le mot qui le précède :</p>$$P(\mathtt{mot\ à\ prédire} \mid \mathtt{mot\ qui\ précède})$$<blockquote class="book-hint info"><p>La barre verticale dans la notation signifie &ldquo;étant donné&rdquo;, ou &ldquo;en présence de&rdquo;,
ou &ldquo;dans le contexte de&rdquo;, ce qui, mathématiquement, correspond à une
<a href=https://fr.wikipedia.org/wiki/Probabilit%C3%A9_conditionnelle>probabilité conditionnelle</a>.</p></blockquote><p>La tâche de notre modèle de classification pour les courriels était de
discriminer (répondre oui ou non à la question : est-ce un pourriel?) tandis que
la tâche de notre modèle bigramme sera ici de générer du nouveau texte, une fois
le modèle entraîné, en faisant de l&rsquo;échantillonnage. La génération se fera un
mot à la fois, en choisissant à chaque fois le mot suivant, de manière
aléatoire, selon la distribution de probabilité conditionnée sur le mot
précédent (pour faire une analogie, c&rsquo;est comme si nous utilisions à chaque fois
un dé spécialisé, avec autant de faces qu&rsquo;il y a de mots dans le vocabulaire, et
chacune biaisée de manière spécifique en fonction du mot précédent, ce qui est
représenté dans le diagramme qui suit avec les petites enclumes, pour dénoter
les différents poids) :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/word_dice.png alt></p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/generate_words.png alt></p><p>La génération de nouveau texte à l&rsquo;aide de l&rsquo;échantillonnage est précisément ce
qui permet à ChatGPT de répondre à une question, ou de composer un poème.</p><h2 id=consignes>Consignes
<a class=anchor href=#consignes>#</a></h2><ol><li><p>Suivez les instructions ci-haut pour construire tout d&rsquo;abord le fichier Google Sheets avec toutes les données nécessaires.</p></li><li><p>Une fois qu&rsquo;il est complété et fonctionnel, <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/#fonction-de-partage-anonyme-dun-fichier>partagez votre fichier</a> et copier le lien vers celui-ci dans un document PDF (<strong>Attention : aucun autre format que PDF ne sera accepté</strong>).</p></li><li><p>Répondez aux questions d&rsquo;interprétation qui suivent dans le même fichier PDF, en fournissant des réponses claires et précises.</p></li></ol><h2 id=entraînement-du-modèle>Entraînement du modèle
<a class=anchor href=#entra%c3%aenement-du-mod%c3%a8le>#</a></h2><p>Voyons maintenant comment il est possible de calculer ces probabilités en
entraînant un modèle bigramme génératif à partir d&rsquo;un texte très simple.</p><p>Étant donné que nous allons encore une fois utiliser la tableur en ligne <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/>Google
Sheets</a>, assurez-vous tout d&rsquo;abord que
votre version est correctement configurée.</p><p>Copiez tout d&rsquo;abord les mots de ce texte dans la colonne <code>A</code> d&rsquo;une nouvelle
&ldquo;feuille&rdquo; Google Sheets, un mot par rangée (assurez-vous d&rsquo;utiliser correctement
la <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/#fonction-copier-coller>fonction &ldquo;copier-coller&rdquo;</a>, si vous le faites) :</p><pre tabindex=0><code>le
chat
dort
le
chien
mange
le
chat
mange
une
souris
le
chien
dort
la
souris
court
la
souris
mange
le
fromage
le
chat
court
le
chien
voit
le
chat
le
chat
voit
la
souris
le
chien
court
</code></pre><p>Notez tout d&rsquo;abord que la colonne <code>A</code> (son contenu) est très souvent nommée le
&ldquo;corpus d&rsquo;entraînement&rdquo;. Il s&rsquo;agit du texte brut à partir duquel nous allons
calculer (ou entraîner) les paramètres du modèle. Pour les vrais modèles de
langage, ce texte peut être <a href=https://commoncrawl.org>extrêmement volumineux</a> !
(Il peut comprendre des millions de livres, par exemple).</p><p>Dans la première cellule de la colonne <code>B</code> (donc <code>B1</code>), entrez maintenant cette
formule :</p><pre tabindex=0><code>=A2
</code></pre><p>La colonne <code>B</code> devrait être étendue jusqu&rsquo;à la cellule <code>B37</code>, en double-cliquant
sur le petit &ldquo;+&rdquo; qui apparaît quand votre curseur est placé au-dessus du coin
inférieur droit de la cellule <code>B1</code> (il est possible que Google Sheets offre de
le faire pour vous, automatiquement).</p><p>Dans la cellule <code>C1</code>, entrez maintenant cette formule :</p><pre tabindex=0><code>=A1 &amp; &#34; &#34; &amp; B1
</code></pre><p>Encore une fois, la colonne <code>C</code> doit s&rsquo;étendre jusqu&rsquo;à la cellule <code>C37</code>. À ce stade,
votre feuille devrait ressembler à ceci :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/sheets_3_first_cols.png alt></p><p>À ce stade, il devrait être clair pour vous que la colonne <code>C</code> contient tous les
bigrammes (séquences de deux mots consécutifs) extraits du texte de la colonne
<code>A</code> (notez que la colonne <code>B</code> n&rsquo;est qu&rsquo;un mécanisme intermédiaire pour les obtenir
facilement).</p><p>Nous allons maintenant compter, dans la colonne <code>D</code>, le nombre de fois où un
bigramme particulier apparaît dans le corpus d&rsquo;entraînement de la colonne <code>A</code>
(la colonne <code>D</code> doit être étendue pour avoir le même nombre d&rsquo;éléments que la
colonne <code>C</code>) :</p><pre tabindex=0><code>=COUNTIF(C:C, C1)
</code></pre><blockquote class="book-hint warning"><p>Si vous obtenez une erreur avec la formule à ce stade, il est très possible que
les paramètres linguistiques de votre Google Sheets ne soient pas <a href=https://cjauvin.github.io/inf1901-teluq/docs/google-sheets/#parametres-linguistiques>correctement
configurés</a>.</p></blockquote><p>On constate par exemple que le bigramme <code>le chien</code> apparaît 4 fois, tandis que
le bigramme <code>fromage le</code>, apparaît seulement une fois.</p><p>Dans la colonne <code>E</code>, nous allons maintenant calculer les paramètres de notre
modèle, soit la probabilité d&rsquo;un mot, étant donné le mot qui le précède (ce qui
constitue donc un modèle qui <em>génère</em> des mots):</p>$${P(\text{mot de la col B} \mid \text{mot de la col A})} =
\frac{
\#(\text{mots A et B})
}{
\#(\text{mot A})
}
$$<p>Pour ce faire, entrez dans la cellule <code>E1</code> (la formule est un peu complexifiée par
le fait qu&rsquo;on veut considérer tous les mots de la colonne A sauf le dernier, car
sa présence fausserait légèrement les probabilités) :</p><pre tabindex=0><code>=D1 / COUNTIF(A$1:INDEX(A:A, COUNTA(A:A)-1), A1)
</code></pre><p>La probabilité d&rsquo;un mot étant donné le mot qui le précède est donc simplement le
nombre de fois où ce bigramme particulier apparaît dans le texte, divisé par le
nombre de fois où le premier mot du bigramme apparaît (le dénominateur est
nécessairement plus grand ou égal que le numérateur, prenez un moment pour vous
en convaincre). Étant donné que cette valeur est une probabilité, elle doit
nécessairement être contenue entre 0 et 1. Le colonne <code>E</code> doit s&rsquo;étendre jusqu&rsquo;à
<code>E37</code>.</p><p>Dans la colonne <code>F</code> nous allons filtrer la colonne <code>C</code> (tous les bigrammes, qui
comprennent donc des bigrammes répétés) pour ne retenir que les bigrammes
uniques (cette colonne devrait avoir 26 éléments) :</p><pre tabindex=0><code>=SORT(UNIQUE(C:C))
</code></pre><p>Nous devons ensuite séparer les mots des bigrammes uniques, les premiers mots
dans la colonne <code>G</code> :</p><pre tabindex=0><code>=INDEX(SPLIT(F1, &#34; &#34;), 1)
</code></pre><p>suivis des deuxièmes mots (des bigrammes uniques de la colonne <code>F</code>) dans la
colonne <code>H</code> :</p><pre tabindex=0><code>=INDEX(SPLIT(F1, &#34; &#34;), 2)
</code></pre><p>Et dans la colonne <code>I</code> nous allons ajouter les probabilités correspondantes
(provenant de la colonne <code>E</code>):</p><pre tabindex=0><code>=INDEX(E:E, MATCH(F1, C:C, 0))
</code></pre><p>On peut maintenant constater que le mot <code>souris</code> suit nécessairement (avec
certitude, soit une probabilité de 1) le mot <code>la</code>, tandis que le mot <code>le</code> peut
être suivi des mots <code>chat</code>, <code>chien</code> et <code>fromage</code> avec des probabilités de 0.5,
0.4 et 0.1, respectivement.</p><p>À ce stade, votre feuille devrait ressembler à ceci :</p><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/sheets_model_complete.png alt></p><h2 id=utilisation-du-modèle-inférence>Utilisation du modèle (inférence)
<a class=anchor href=#utilisation-du-mod%c3%a8le-inf%c3%a9rence>#</a></h2><p>Maintenant que notre modèle de langage est &ldquo;entraîné&rdquo; (c&rsquo;est-à-dire que les
probabilités pour les différents bigrammes, les paramètres donc, sont
calculées), on peut l&rsquo;utiliser pour générer, avec l&rsquo;échantillonnage, un nouveau
texte, aléatoire, probablement différent donc du corpus d&rsquo;entraînement.</p><p>Pour démarrer le mécanisme de génération, on peut entrer un premier mot dans la
cellule <code>J1</code>, par exemple le mot <code>le</code> (ce mot <em>doit</em> faire partie du vocabulaire du
modèle).</p><p>Ensuite, la génération peut être effectuée de manière itérative avec cette
formule plus complexe, à partir de la cellule <code>K1</code> si vous désirez que les mots
soient générés à la verticale, ou <code>J2</code> si vous désirez qu&rsquo;ils le soient à
l&rsquo;horizontale.</p><pre tabindex=0><code>=LET(
  next_word_mask, ARRAYFORMULA($G:$G = J1),
  next_words, FILTER($H:$H, next_word_mask),
  probs, FILTER($I:$I, next_word_mask),
  probs_cumul, SCAN(0, probs, LAMBDA(a, b, a + b)),
  sampled_word_idx, MATCH(RAND(), {0; probs_cumul}, 1),
  INDEX(next_words, sampled_word_idx)
)
</code></pre><blockquote class="book-hint warning"><p>Étant donné que cette formule contient plusieurs lignes
elle doit être entrée dans l&rsquo;espace de la formule, en haut des colonnes.</p></blockquote><p><img src=https://cjauvin.github.io/inf1901-teluq/images/module4/tn4/sheets_generate.png alt></p><p>Cette formule détermine tout d&rsquo;abord quels sont les prochains mots possibles
(suivant le mot de départ <code>le</code> que nous avons choisi, dans ce cas particulier),
ainsi que leur probabilité associée. Elle détermine ensuite le mot suivant en
choisissant un nombre aléatoire qui est utilisé en tant qu&rsquo;index dans la liste
des probabilités cumulatives (cette procédure est appelée échantillonnage).</p><p>Si votre deuxième mot généré se trouve dans la cellule <code>K2</code>, vous pouvez
continuer la génération en glissant la cellule vers la droite. Si votre deuxième
mot se trouve plutôt dans la cellule <code>J2</code>, vous pouvez poursuivre la génération
en glissant la cellule <code>J2</code> vers le bas.</p><h2 id=questions>Questions
<a class=anchor href=#questions>#</a></h2><ol><li><p>Quels sont les paramètres du modèle (quelles colonnes exactement)?</p></li><li><p>Expliquez en vos mots comment ces paramètres sont calculés.</p></li><li><p>En quoi la colonne <code>B</code> de ce modèle diffère de la colonne <code>B</code> du modèle de
classification des courriels du <a href=https://cjauvin.github.io/inf1901-teluq/docs/module2/travail-not%C3%A9-2/>travail noté 2</a>?</p></li><li><p>Expliquez en quoi le modèle de classification du travail 2 était un modèle
discriminatif, alors que ce modèle de langage est un modèle génératif?</p></li><li><p>Quelle est la conséquence du fait que le bigramme <code>le chat</code> apparaisse 5 fois
dans le corpus d&rsquo;entraînement (colonne <code>A</code>)?</p></li><li><p>Quelle est la conséquence du fait que le bigramme <code>la souris</code> apparaisse 3
fois, et en quoi cela diffère du bigramme de la question (5)?</p></li><li><p>Est-ce que la présence de certains bigrammes fait en sorte qu&rsquo;il est possible
de générer des séquences moins grammaticales? Lesquels en particulier?</p></li><li><p>Est-ce que la présence de certains bigrammes fait en sorte qu&rsquo;il est possible
de générer des séquences sémantiquement plus étranges? Lesquels en
particulier?</p></li><li><p>De quel type d&rsquo;apprentissage s&rsquo;agit-il ici : supervisé, non-supervisé ou
semi-supervisé? Expliquez en quoi ça l&rsquo;est.</p></li><li><p>Si on utilisait un modèle trigramme au lieu d&rsquo;un bigramme, qu&rsquo;est-ce qui
changerait? Quelles seraient les contraintes entraînées par l&rsquo;utilisation
d&rsquo;un modèle trigramme au lieu d&rsquo;un modèle bigramme?</p></li><li><p>Supposons que le modèle ait généré le mot <code>voit</code>, expliquez la conséquence
que le choix du prochain mot (celui suivant immédiatement <code>voit</code>) va avoir
sur la suite de la phrase générée.</p></li><li><p>Est-ce qu&rsquo;il y a une limite à la longueur de la phrase pouvant être générée
par le modèle?</p></li><li><p>Est-ce qu&rsquo;il est possible que le modèle génère un bigramme qui ne fait pas
partie des exemples qui ont servis à son entraînement?</p></li><li><p>Expliquez quelles sont les limites au niveau de la capacité de
généralisation de ce modèle. À quoi sont dues ces limites?</p></li><li><p>Expliquez comment on pourrait faire en sorte que le modèle puisse modéliser
et générer des phrases complètes (avec une majuscule et un point final).</p></li></ol></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><div class="flex flex-wrap justify-between"><a href=https://cjauvin.github.io/inf1901-teluq/docs/module4/03-3blue1brown/ class="flex align-center float-left book-icon"><img src=https://cjauvin.github.io/inf1901-teluq/svg/backward.svg alt=Previous title=3Blue1Brown>
<span>3Blue1Brown</span>
</a><a href=https://cjauvin.github.io/inf1901-teluq/docs/module5/ class="flex align-center float-right book-icon"><span>Module 5 - Autour de l'IA</span>
<img src=https://cjauvin.github.io/inf1901-teluq/svg/forward.svg alt=Next title="Module 5 - Autour de l'IA"></a></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#consignes>Consignes</a></li><li><a href=#entraînement-du-modèle>Entraînement du modèle</a></li><li><a href=#utilisation-du-modèle-inférence>Utilisation du modèle (inférence)</a></li><li><a href=#questions>Questions</a></li></ul></nav></div></aside></main></body></html>